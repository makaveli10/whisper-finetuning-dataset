file_name,sentence,verified
data/train/2_0.mp3,"Okay, so creating Debian-based embedded systems using Debian OS. My name is Chris and I'm",0,0
data/train/2_1.mp3,an engineer at Collabora. I work on creating custom distributions for our clients. Usually,0,0
data/train/2_2.mp3,"these custom distros end up running on embedded platforms, embedded little boards that customers",0,0
data/train/2_3.mp3,"have bought like Raspberry Pis, those sorts of development boards. But sometimes they",0,0
data/train/2_4.mp3,end up on customer-specific hardware. Occasionally they end up running in the cloud on a virtual,0,0
data/train/2_5.mp3,"machine. So really, the images that I create end up running kind of everywhere, really.",0,0
data/train/2_6.mp3,"I work on continuous integration and packaging of the customer software. So basically, customers",0,0
data/train/2_7.mp3,"normally don't care so much about packaging their software, they just want their software",0,0
data/train/2_8.mp3,to work. So we take the hassle out of that and package the software for them. We make,0,0
data/train/2_9.mp3,sure that their devices can be upgraded over the air. We also implement fail-safes so that,0,0
data/train/2_10.mp3,"if the over-the-air upgrade fails, the power's taken out of the power jack or the internet",0,0
data/train/2_11.mp3,"connection's gone. We mitigate these sort of problems. Also, I work on the tooling to",0,0
data/train/2_12.mp3,"make all of these things happen. So most recently, I've been working on Dev OS and Fake Machine.",0,0
data/train/2_13.mp3,"So hopefully, this presentation is going to give you a little bit of insight on what I've",0,0
data/train/2_14.mp3,"been working on over the past year or so. I'm also learning some Rust, which is proven",0,0
data/train/2_15.mp3,to be quite useful for some of my daily tasks. Some more scripts I've been writing in Python,0,0
data/train/2_16.mp3,"and Go in the past have now been written in Rust. Slowly but surely, I'm getting there",0,0
data/train/2_17.mp3,"and the future is bright. So today, I'm going to talk to you about what actually Dev OS",0,0
data/train/2_18.mp3,is and how it compares to other tools. I'm also going to go through how to use it and,0,0
data/train/2_19.mp3,"the future plans that we've got for the tooling. Hopefully, we'll get a chance for a question",0,0
data/train/2_20.mp3,"and answer session at the end, but please do download the slides and copy my email address",0,0
data/train/2_21.mp3,and feel free to email me if you have any questions that you feel weren't covered today.,0,0
data/train/2_22.mp3,"I'll do my best to get back to you. Also, I would suggest downloading the slides so",0,0
data/train/2_23.mp3,you can get access to some of the blue links that I've dotted around the presentation.,0,0
data/train/2_24.mp3,This should give you a little bit more context in places. So the link on this slide will,0,0
data/train/2_25.mp3,"show you the introduction to YAML, yet another markup language, which is extensively used",0,0
data/train/2_26.mp3,"throughout Dev OS and also lots of other continuous integration systems like GitHub Actions, GitLab",0,0
data/train/2_27.mp3,"CI. These all use YAML, so I'd highly recommend having a look. YAML is a fairly basic markup",0,0
data/train/2_28.mp3,language. You should be able to follow along with the examples and get a feel for how the,0,0
data/train/2_29.mp3,"markup language works, but there are some details which the tutorial goes into quite",0,0
data/train/2_30.mp3,"well, so I'd recommend checking that link out. So first, I'd like to explain what a",0,0
data/train/2_31.mp3,"GNU Linux distribution is. In my opinion, it's a collection of software packages developed",0,0
data/train/2_32.mp3,"by like-minded developers. These packages follow a set of guidelines to meet this distribution,",0,0
data/train/2_33.mp3,so all the packages end up working together quite well. You don't end up with too many,0,0
data/train/2_34.mp3,"breakages, hopefully, and the developers end up fixing bugs in the distribution and",0,0
data/train/2_35.mp3,passing the bugs upstream and releasing new versions of the upstream software in the distribution.,0,0
data/train/2_36.mp3,So each one of the distributions have different goals. So Debian is a distribution which uses,0,0
data/train/2_37.mp3,apt for its package management and dpackage. Red Hat use RPM and yum for their package,0,0
data/train/2_38.mp3,"management, so there are lots of choices and design decisions which each distribution makes,",0,0
data/train/2_39.mp3,"and everyone has their own preference. I mean, my preference personally is Debian. I've been",0,0
data/train/2_40.mp3,"working with Debian since the 2000s, so I'm very familiar with Debian, but at the same",0,0
data/train/2_41.mp3,"time, I don't really know a lot about Red Hat or Fedora, so I would suggest asking someone",0,0
data/train/2_42.mp3,"else about Red Hat Fedora, not me. But I think one thing that we can all agree on is the",0,0
data/train/2_43.mp3,usual trend at the moment is for embedded targets to run a custom image generated by,0,0
data/train/2_44.mp3,"something like Yocto or Buildroot rather than run a full distribution. Hopefully, with tools",0,0
data/train/2_45.mp3,"like DevOS, we can change that and let distributions run on embedded targets.",0,0
data/train/2_46.mp3,So why might you want to create your own distribution? So your project might have,0,0
data/train/2_47.mp3,"different targets, so your project might want to run on an embedded board or multiple types",0,0
data/train/2_48.mp3,"of embedded board. It might want to run on a PC, or it might want to run in the cloud,",0,0
data/train/2_49.mp3,"or it may even want to run a combination of those. And usually, you can buy, for instance,",0,0
data/train/2_50.mp3,hardware development kits. These are supplied with a general purpose distribution that the,0,0
data/train/2_51.mp3,"developers have made for that development kit. And usually, these are based on Debian or Ubuntu,",0,0
data/train/2_52.mp3,"and they're quite bad. I mean, they've got a lot of unnecessary, insecure, and outdated packages,",0,0
data/train/2_53.mp3,and they're incompatible with updating. And they've done a lot of hacks for that platform,0,0
data/train/2_54.mp3,"as well. So your own distribution would solve these issues quite nicely. From scratch, it's a",0,0
data/train/2_55.mp3,lot of hard work to maintain a distribution. So my suggestion is there's no need to reinvent the,0,0
data/train/2_56.mp3,"wheel, and you should rebase or base your distribution on a proven technology like Debian.",0,0
data/train/2_57.mp3,"So Yocto and Buildroot, usually the images are only for embedded platforms. I had our Yocto expert",0,0
data/train/2_58.mp3,"shout at me last time I said this, no, no, no, you can run Yocto images in the cloud now. But I would",0,0
data/train/2_59.mp3,likely say that it's a lot harder than you need to have a lot of specific knowledge of how to run,0,0
data/train/2_60.mp3,"these images in the cloud. They create a nice custom distribution or a custom image, but it can",0,0
data/train/2_61.mp3,become a maintenance nightmare when you want to update software or create packages for your own,0,0
data/train/2_62.mp3,"software. All the packages are compiled on your own machine, which some may say is a benefit,",0,0
data/train/2_63.mp3,but I personally think it is a negative. Having to recompile a window manager every time I want to,0,0
data/train/2_64.mp3,build a new image for different platforms is kind of not a benefit in my view. There's a high,0,0
data/train/2_65.mp3,learning curve. So my suggestion is why make things hard for yourself? My suggestion is to use,0,0
data/train/2_66.mp3,"Debian as a base for your image. So Debian is both traditionally seen as a desktop operating system,",0,0
data/train/2_67.mp3,"but recent years, a lot of effort has gone into enabling embedded targets and lots of different",0,0
data/train/2_68.mp3,embedded targets. I think this mainly started with the Raspberry Pi that really drove the embedded,0,0
data/train/2_69.mp3,"sort of world into some of the Debian developers. Debian was released in 1993, and it's widely used.",0,0
data/train/2_70.mp3,"And there are lots and lots of volunteers who shape Debian in form of Debian developers, Debian",0,0
data/train/2_71.mp3,"maintainers, and they follow a social contract called the Debian Free Software Guidelines. And",0,0
data/train/2_72.mp3,"they have social contracts as well, which basically means that all developers work to a common set of",0,0
data/train/2_73.mp3,rules. And they're free to change these rules so long as the changes make sense. I think that's a,0,0
data/train/2_74.mp3,great way of working. It's really community spirit. You're not being forced into doing things that you,0,0
data/train/2_75.mp3,don't want to do by large corporations. It's all owned by the community. So I think that's really,0,0
data/train/2_76.mp3,"nice. These developers have written over 50,0,000 packages and libraries, and you can easily install",0,0
data/train/2_77.mp3,"or upgrade these using apps. The community is great. Unfortunately, these mailing lists, but if",0,0
data/train/2_78.mp3,"you're used to using mailing lists, then this is really not a problem. There are lots of tutorials",0,0
data/train/2_79.mp3,"on the internet, and it's fairly easy to get started. We have stable and testing distributions, as",0,0
data/train/2_80.mp3,"well as unstable, which have bleeding-edge packages. Timely security updates go into the stable",0,0
data/train/2_81.mp3,"release, and unstable, or Seed as it's known, usually gets the latest bleeding-edge packages. And as",0,0
data/train/2_82.mp3,"I've already said, no one company leads the development or the direction of the project. The",0,0
data/train/2_83.mp3,"developers themselves lead the project, which in my view is very important. So using Debian as a base, in",0,0
data/train/2_84.mp3,"summary, lets you concentrate on the most important part of the project, your application. You haven't",0,0
data/train/2_85.mp3,got to worry about the base operating system behind it and all the things that happen there.,0,0
data/train/2_86.mp3,So some disadvantages with Debian. Debian only caters for systemd. This is changing. There are,0,0
data/train/2_87.mp3,"some changes in force to allow for other system managers, but I don't see this as a big disadvantage",0,0
data/train/2_88.mp3,"personally. Most of our projects use systemd, and use systemd very well. The other thing is",0,0
data/train/2_89.mp3,"Debian packages are compiled with Julibc, so this can be a problem for very small embedded targets,",0,0
data/train/2_90.mp3,"but typically most projects now have got a fair amount of RAM and a fairly big CPU. I mean, it",0,0
data/train/2_91.mp3,doesn't make a lot of sense in some cases to have anything smaller than a dual-core embedded,0,0
data/train/2_92.mp3,"processor, so I would suggest that these two disadvantages don't really matter so much these",0,0
data/train/2_93.mp3,"days. Debian was designed with desktop or server use in mind, but as I said originally, it is coming",0,0
data/train/2_94.mp3,"onto embedded targets, but it needs a little bit more work than if you were to install it on the",0,0
data/train/2_95.mp3,"desktop. So if you're installing on the desktop, you can easily just plug in a USB with Debian",0,0
data/train/2_96.mp3,"installed on the USB and install that to your hard drive quite easily. With embedded platforms,",0,0
data/train/2_97.mp3,typically you will run an image on an SD card. The Debian installer typically won't work for,0,0
data/train/2_98.mp3,"a custom distribution, so there's some challenges there, but DevOS actually helps with installing",0,0
data/train/2_99.mp3,"the system on an image, so hopefully by the end of this talk you'll understand a little bit more",0,0
data/train/2_100.mp3,"about that. Debian are a little bit conservative of new technologies, but again this isn't so bad.",0,0
data/train/2_101.mp3,I think that this is quite a good thing to be conservative of new things because,0,0
data/train/2_102.mp3,"sometimes new things aren't always good. There's limited enterprise support, but there is",0,0
data/train/2_103.mp3,"paid support by companies like Collabra to help customers with their projects,",0,0
data/train/2_104.mp3,"and Debian also has quite a slow release cycle, so stable upgrades happen every kind of two years,",0,0
data/train/2_105.mp3,"but that's not always a bad thing, and as I've already said, there are fresh packages in Unstable,",0,0
data/train/2_106.mp3,which suits most users. So how would you create a custom Debian image? So normally when you want to,0,0
data/train/2_107.mp3,"create a custom Debian image, you would create an image using DD. You'd basically flash the image",0,0
data/train/2_108.mp3,"with all zeros to begin with on your local hard drive. You'd insert a partition table using Fdisk,",0,0
data/train/2_109.mp3,"and format these partitions. You'd mount the partitions on a loop device, and then you can",0,0
data/train/2_110.mp3,"cheroot into the mounted image and deboot strap a basic Debian file system, install packages using",0,0
data/train/2_111.mp3,"apt, and then you can basically work on it as if it was a normal system on your hard drive by",0,0
data/train/2_112.mp3,"setting the hostname, setting up user accounts, configuration files, and then at the end of all",0,0
data/train/2_113.mp3,"of that you want to unmount the image, clean up the loop devices, compress your image, save the",0,0
data/train/2_114.mp3,"build logs, and then hopefully after that you've got a nice image. It's nice until the whole lot",0,0
data/train/2_115.mp3,"breaks, and also you have these problems where it works on your machine but it doesn't work in the",0,0
data/train/2_116.mp3,"continuous integration machine, or it doesn't work on other developers' machines. There are",0,0
data/train/2_117.mp3,lots of issues with this kind of script-based setup. There are lots of tools out there already,0,0
data/train/2_118.mp3,that follow this kind of routine. There's a presentation called The Many Methods to Build,0,0
data/train/2_119.mp3,"a Debian Image by Riku, which summarizes the most popular tools. Usually these other tools serve a",0,0
data/train/2_120.mp3,very specific purpose. Originally when I first started looking at Debian systems I was looking,0,0
data/train/2_121.mp3,"at a tool called Spindle which basically created Raspberry Pi images, but the images were very",0,0
data/train/2_122.mp3,specific just for Raspberry Pi. So at the time I was looking at creating a BeagleBone Black image,0,0
data/train/2_123.mp3,and I couldn't create an image using Spindle for that without a lot of hacking.,0,0
data/train/2_124.mp3,So these other tools also have random failures which we call it.,0,0
data/train/2_125.mp3,DevOS is inherently a lot more robust against these failures and it's also a lot more flexible,0,0
data/train/2_126.mp3,than these other tools that serve very specific purposes. DevOS generates your custom image from,0,0
data/train/2_127.mp3,"one configuration file which can be stored in version control, which is quite nice. We also",0,0
data/train/2_128.mp3,use GitLab continuous integration to build images as soon as they're pushed into the,0,0
data/train/2_129.mp3,version control. I'm going to go into a little bit of that in this presentation as well.,0,0
data/train/2_130.mp3,"Collaborate are constantly evolving and improving DevOS and Apertis, which is a project by",0,0
data/train/2_131.mp3,"Collaborate and Bosch, is continuously evolving DevOS as well because Apertis use DevOS to",0,0
data/train/2_132.mp3,generate the images for their boards. So that's very good. Basically I think you're going to get,0,0
data/train/2_133.mp3,started with DevOS quicker than some of these other tools as well. So the solution to one of,0,0
data/train/2_134.mp3,these problems is DevOS. Basically it uses a library called FakeMachine to create a virtual,0,0
data/train/2_135.mp3,machine on your computer. Disks are attached to the virtual machine so we don't use loop devices,0,0
data/train/2_136.mp3,and that's very good because these are very loop devices as we've discussed are very fragile.,0,0
data/train/2_137.mp3,We have a recipe file which contains actions or the steps to create your image,0,0
data/train/2_138.mp3,and these recipes are translated into commands which are run inside the VM,0,0
data/train/2_139.mp3,in this clean environment and the recipe actions abstract the changes and the configuration files,0,0
data/train/2_140.mp3,and the commands so basically you don't have to write so many commands in your build script.,0,0
data/train/2_141.mp3,When there's no action already created you can just run a shell command or a script inside,0,0
data/train/2_142.mp3,the FakeMachine which then you can change route into the disk image and do any changes,0,0
data/train/2_143.mp3,you want there. Easy cleanup if anything goes wrong you just kill the virtual machine,0,0
data/train/2_144.mp3,and this is quite nice because it doesn't break your host. Everything's reproducible on your,0,0
data/train/2_145.mp3,computer as well as in the CI system which all of these things I think make DevOS quite a nice,0,0
data/train/2_146.mp3,"solution for building your own images. So we've got lots of people using DevOS we've got Apertis,",0,0
data/train/2_147.mp3,"KernelCI, Redaxor, the Mobium project, Plasma Mobile, Gemion and also reproducible builds use",0,0
data/train/2_148.mp3,DevOS. This is just a short list here I'm not going to go into detail of all of them because,0,0
data/train/2_149.mp3,I don't think we've got the time today but please feel free to check these projects out they're,0,0
data/train/2_150.mp3,"very cool projects. So DevOS is a tool written in Go, you don't need to know Go to run DevOS,",0,0
data/train/2_151.mp3,you only need to know Go if you want to add features to DevOS. There is FakeMachine which is,0,0
data/train/2_152.mp3,a separate library and a standalone tool which Collaborative generated which creates virtual,0,0
data/train/2_153.mp3,machines. Packages for both FakeMachine and DevOS are in Debian stable. We try to update these,0,0
data/train/2_154.mp3,packages fairly quickly as well when new features are added. It's also available as a Docker container,0,0
data/train/2_155.mp3,so you can run it pretty much anywhere. We use a Docker container to run in the GitLab,0,0
data/train/2_156.mp3,continuous integration and also you can install from source and other operating systems,0,0
data/train/2_157.mp3,fairly easily too. So DevOS recipe is a YAML file which defines the steps to create your image.,0,0
data/train/2_158.mp3,As we've said already it's simple and can be version controlled and the recipe consists of,0,0
data/train/2_159.mp3,a header which has got the metadata for instance the image architecture and an array of actions,0,0
data/train/2_160.mp3,which are ran sequentially. Each of these actions has their own properties so the YAML file has,0,0
data/train/2_161.mp3,comments inside of it or you can add comments if you so wish. I'd highly recommend adding comments,0,0
data/train/2_162.mp3,to all code that you write. For me my memory is like a sieve so if I don't write comments in three,0,0
data/train/2_163.mp3,weeks time I won't know what the point of the comment of the code was. All of the recipes are,0,0
data/train/2_164.mp3,"pre-processed through the Go templating engine which allows you to have variables, if-else",0,0
data/train/2_165.mp3,statements and you can also include recipes and other recipes which is all very nice.,0,0
data/train/2_166.mp3,"So enough talk, here's a simple example. Again please copy these slides and copy the example.",0,0
data/train/2_167.mp3,This example as the comment says creates a tarball of a simple Debian operating system.,0,0
data/train/2_168.mp3,So basically you can run this on Debian using the steps I've given here. You basically want,0,0
data/train/2_169.mp3,to install Docker first and then run the Docker container and then you get this output here,0,0
data/train/2_170.mp3,of each action inside the recipe and at the end you get a tarball with the contents of a,0,0
data/train/2_171.mp3,operating system. So here again I've shown you the original recipe on the left hand side and,0,0
data/train/2_172.mp3,the output on the right hand side. You can see how each action relates to some commands. I had,0,0
data/train/2_173.mp3,to remove the command output because it doesn't actually fit on the screen but hopefully that,0,0
data/train/2_174.mp3,gives you a quick overview of how the actions relate to the output. You can also run this in,0,0
data/train/2_175.mp3,"GitLab CI using the Docker image. So as you can see here it's not much, it's about 12 lines of code",0,0
data/train/2_176.mp3,to actually run this in GitLab CI and GitLab CI is very helpful because it shows you whether,0,0
data/train/2_177.mp3,things pass or fail in the browser. Everyone on your team can see it. You can set jobs up to run,0,0
data/train/2_178.mp3,on our schedule so nightly. You can have email notifications when things don't work. It's all very nice.,0,0
data/train/2_179.mp3,So then WS has a bunch of actions which you can use to create your operating system.,0,0
data/train/2_180.mp3,So we've got the deboot strap action which sets a basic Debian system up in the file system.,0,0
data/train/2_181.mp3,We've got the apt action which installs packages. We've got the pack and unpack action which pack and unpack,0,0
data/train/2_182.mp3,"tarballs. Image partition uses some tools on the operating system to create an image,",0,0
data/train/2_183.mp3,"partition table, format file systems and it's very comprehensive the partition layouts that you can",0,0
data/train/2_184.mp3,create with this tool. I actually as a tip use WS recipes even not when creating Debian,0,0
data/train/2_185.mp3,systems so it's very flexible in that regard. You can use WS to generate a system or an image,0,0
data/train/2_186.mp3,which contains virtually anything in it. We've got file system deploy which actually copies,0,0
data/train/2_187.mp3,root file systems from a temporary directory into an image. We've got overlay,0,0
data/train/2_188.mp3,which copy files from your host machine into the container and inside the,0,0
data/train/2_189.mp3,target file system. We've got the raw action which writes images to a partition,0,0
data/train/2_190.mp3,so you can write things like boot loaders or pre-prepared images. So I use the raw action,0,0
data/train/2_191.mp3,as a tip to copy vendor provided root file systems into an image and then modify the,0,0
data/train/2_192.mp3,the image that they've given. The run action allows you to run scripts or commands,0,0
data/train/2_193.mp3,inside the virtual machine or inside the actual image that you're creating.,0,0
data/train/2_194.mp3,Then here is an example of variables so you can define variables and you can use the variables,0,0
data/train/2_195.mp3,inside the recipe. You can pass the values to these variables on the command line and you can,0,0
data/train/2_196.mp3,also do things like printf. There's an example there where we generate the file name based on,0,0
data/train/2_197.mp3,two other variables so that's quite nice. You've also got some defaults at the top so the default,0,0
data/train/2_198.mp3,are those two values. Also the scripting allows you to do if-else so you can pass in in this,0,0
data/train/2_199.mp3,example here you can install different packages based on what architecture you're running,0,0
data/train/2_200.mp3,which is quite useful. You can also run recipes inside recipes using the action,0,0
data/train/2_201.mp3,using the recipe action. You can also pass variables into these other actions,0,0
data/train/2_202.mp3,and the command the variables from the command line is also passed in so that allows you to,0,0
data/train/2_203.mp3,to abstract reusable things into a different action which is,0,0
data/train/2_204.mp3,into a different recipe sorry which is quite nice. We've got some more examples here we've got a,0,0
data/train/2_205.mp3,recent raspberry pi image which one of my colleagues Dennis has created.,0,0
data/train/2_206.mp3,That's a very basic image which just bootstraps a basic Debian image onto,0,0
data/train/2_207.mp3,onto an SD card for you to run. Also we have a Pertis which is as I've already said the,0,0
data/train/2_208.mp3,automotive operating system by Galabra. These recipes have got more scripting in them and if,0,0
data/train/2_209.mp3,statements there's an OSPAC image which basically includes everything to create the operating system,0,0
data/train/2_210.mp3,and then on top of that a Pertis have a kind of hardware pack if you like which,0,0
data/train/2_211.mp3,allows you to create raspberry pi image this example but there are other other example images,0,0
data/train/2_212.mp3,for other targets as well. So the future plans we've got for DevOS some of these actually,0,0
data/train/2_213.mp3,already finished. By the end of this year we wanted to have raspberry pi for example recipe,0,0
data/train/2_214.mp3,which we've now got. We wanted instead of fake machine just running under KVM for a virtual,0,0
data/train/2_215.mp3,machine we wanted to add user mode linux so we could build images without KVM and this works,0,0
data/train/2_216.mp3,quite nicely so you can build images inside things like github actions or inside cloud,0,0
data/train/2_217.mp3,workers that don't have access to GitLab sorry which don't have access to KVM. This is quite,0,0
data/train/2_218.mp3,useful because it by default most cloud images or cloud providers don't allow you access to run,0,0
data/train/2_219.mp3,nested virtualization. We want to have some more useful actions so you want to be able to install a,0,0
data/train/2_220.mp3,debian package from a file for instance. We want to have automated testing in place so that every,0,0
data/train/2_221.mp3,kind of push to DevOS doesn't break any recipes or break any customer projects really. Next year,0,0
data/train/2_222.mp3,we'd like to add some support for Arch Linux so basically running DevOS on Arch Linux. We'd like,0,0
data/train/2_223.mp3,to create some more recipe examples some documentation and some blog posts around the,0,0
data/train/2_224.mp3,changes we've done to DevOS so we hopefully we can market the sort of products or the free,0,0
data/train/2_225.mp3,open source technology to others who may not know about it. We'd also like to have automated,0,0
data/train/2_226.mp3,recipe builds the example recipes I've already mentioned building automatically on github actions,0,0
data/train/2_227.mp3,and if all that goes to plan we'd like to release version 1.1. So thank you and I'll,0,0
data/train/2_228.mp3,take any questions. Again if you didn't manage to ask any questions on the chat here please do,0,0
data/train/2_229.mp3,feel free to email me and hopefully we'll see each other again soon.,0,0
data/test/8_0.mp3,Hello. I'm Nicolas Dufresne. I've been at Collabra for over a decade. I'm now principal,0,0
data/test/8_1.mp3,engineer specializing in multimedia. And my main interest and work only today is on GStreamer,0,0
data/test/8_2.mp3,"multimedia framework, but I also contribute to the Linux kernel through the Linux media",0,0
data/test/8_3.mp3,"subsystem in order to bring new API and new hardware support, especially hardware accelerators,",0,0
data/test/8_4.mp3,"which is of very good interest. So speaking of new API, I'd like to tell you a bit of the story",0,0
data/test/8_5.mp3,"of the apparition of Codex in the Linux kernel. Codex support isn't new, but it took a lot of",0,0
data/test/8_6.mp3,"time to stabilize and improve. So everything started in 2011. So in 2011, Google partnered",0,0
data/test/8_7.mp3,with Samsung and Asus and actually produced the first ARM Chromebook. This Chromebook was based on,0,0
data/test/8_8.mp3,"Exynos 5 system on a chip, and it included an encoder called Multifunction Codec, the MFC",0,0
data/test/8_9.mp3,decoder. And this was actually the first Codec to be integrated into the mainline Linux.,0,0
data/test/8_10.mp3,"And this Codec landed right on the launch of this device. Now, this type of Codec",0,0
data/test/8_11.mp3,"that we later started calling Stateful Codec, there was no terminology back then,",0,0
data/test/8_12.mp3,"all it works is basically that it has a coprocessor, whether it's a DSP or custom",0,0
data/test/8_13.mp3,"processor or ARM processor, doesn't really matter, but it has a coprocessor that will",0,0
data/test/8_14.mp3,"handle and manage the bitstream, parse the bitstream, and feed the required information,",0,0
data/test/8_15.mp3,"which is Codec specific, to the accelerator. Of course, this is delivered to us as a black box,",0,0
data/test/8_16.mp3,so we're only modeling what our imagination can see here.,0,0
data/test/8_17.mp3,"Now, they needed to fit that into the kernel, they didn't really have a subsystem, so they",0,0
data/test/8_18.mp3,"decided to pick the v4l subsystem and create a new type of v4l device, the memory-to-memory device,",0,0
data/test/8_19.mp3,"or M2M as a short. And in order to do that, they've used two distinct concepts in v4l.",0,0
data/test/8_20.mp3,"v4l had actually devices that have queues, and those queues have specific properties.",0,0
data/test/8_21.mp3,"So, one of the queues was the capture queue used for cameras, and the other queue was the output",0,0
data/test/8_22.mp3,"queue, which back then was used for analog output mostly, but could be used also for SDI output,",0,0
data/test/8_23.mp3,"but it's a bit abandoned these days. So, they've decided to pick the capture as being the output",0,0
data/test/8_24.mp3,"of the codec, the decoded image, and then the output, and that's where it's a bit confusing,",0,0
data/test/8_25.mp3,"as being picked to be the input of your codec, so the encoded bitstream, the encoded data.",0,0
data/test/8_26.mp3,"Of course, this was not enough, they also added the concept of enter-queue-configuration,",0,0
data/test/8_27.mp3,"because the selection of the input data, the output data, is the same as the input data,",0,0
data/test/8_28.mp3,"so the selection of the codec will have an impact on which raw format you'll be able to support,",0,0
data/test/8_29.mp3,"especially that some of these accelerators, actually, they offer also",0,0
data/test/8_30.mp3,"color transformation, scaling, or rotation functionalities.",0,0
data/test/8_31.mp3,"Now, just quick pros and cons. This type of hardware is relatively simple to implement in",0,0
data/test/8_32.mp3,"you don't need any knowledge, very advanced knowledge of the codec itself, because everything,",0,0
data/test/8_33.mp3,"all the hard stuff is handled by the hardware, so you pass a bitstream, and you get images out.",0,0
data/test/8_34.mp3,"Now, the downside is that to drive these accelerators, you need a firmware, and why it's",0,0
data/test/8_35.mp3,"a downside is because most of these firmware, actually all of these firmwares, are proprietary",0,0
data/test/8_36.mp3,"and are blobs, basically, so it's a piece of software that you actually upload to the card,",0,0
data/test/8_37.mp3,"and you have no idea what it's doing, and this piece of software, as it manages your",0,0
data/test/8_38.mp3,"decoding session, may have some limitations, so there's a limit of resource on the chip to handle",0,0
data/test/8_39.mp3,"the stream, so even though you have very, very small stream, you might not be able to decode",0,0
data/test/8_40.mp3,more streams in parallel with this chip. We even have implementations which only support one or,0,0
data/test/8_41.mp3,"two streams, so it's much harder to multiplex, so that's it. We had codec. In 2014, we had the second",0,0
data/test/8_42.mp3,"stateful codec being added, the Coda driver, so it was added for platforms called imx.6 and imx.51,",0,0
data/test/8_43.mp3,"which was still Freescale, which was bought by NXP later, and Coda, actually, is the name of the chip",0,0
data/test/8_44.mp3,"brand as manufactured by Chips and Media, so it's not a Freescale design, it's an actual",0,0
data/test/8_45.mp3,"design that has been bought. Back in the days, we didn't have any information about this codec,",0,0
data/test/8_46.mp3,so this was all reverse engineered by Philippe Zabel and his team at PenguTronics.,0,0
data/test/8_47.mp3,"Now, things didn't stay there, and Google wanted to go further, and they decided to partner with",0,0
data/test/8_48.mp3,"a new chipset vendor, Rockchip, from China, and with them, they created the second generation of",0,0
data/test/8_49.mp3,"ARM Chromebook, much more powerful, but it also came with a much more complex-to-use codec.",0,0
data/test/8_50.mp3,"Back then, in 2015, it was thought to be the Rockchip VDPU hardware. They didn't really",0,0
data/test/8_51.mp3,"know anything about the hardware, except what they had as a reference. Now, this new chip,",0,0
data/test/8_52.mp3,"the main difference is that there's no more coprocessor on the chip, so the accelerators are",0,0
data/test/8_53.mp3,almost exposed as is. There's a bit of logic implemented in the hardware to make it possible,0,0
data/test/8_54.mp3,"to use, but they're there. Instead of just having to pass the bitstream, you also need to pass the",0,0
data/test/8_55.mp3,"references and all the codec parameters needed to drive this accelerator. The codec parameters,",0,0
data/test/8_56.mp3,"even though they're fairly standard, they need to be extracted from the bitstream, so they require",0,0
data/test/8_57.mp3,"deep parsing of the bitstream, and that's the easy part. You also need to understand",0,0
data/test/8_58.mp3,"the workflow, because some stuff is not included in the bitstream, some stuff is deduced",0,0
data/test/8_59.mp3,"by monitoring the flow, and it's the case for references and many of the parameters.",0,0
data/test/8_60.mp3,"Now, you may wonder, and you may have heard about GPU codec,",0,0
data/test/8_61.mp3,"and the fact that these are also lookalike of the stateless decoder. Indeed, that's correct.",0,0
data/test/8_62.mp3,"The GPU decoders, as found on Intel, AMD, and NVIDIA, are very similar. Instead of registers",0,0
data/test/8_63.mp3,"that you write into memory, they use actually a command stream. What happened is that the crafting",0,0
data/test/8_64.mp3,"of this command stream has been merged with the other commands on your GPU, and creating those",0,0
data/test/8_65.mp3,"command streams is something that has been decided to be done in user space, so it's hardware-specific",0,0
data/test/8_66.mp3,"code in user space. It's a driver, but in user space, and notably through a Mesa project.",0,0
data/test/8_67.mp3,"It would be pretty hard to implement a V4L driver for them, because we would have to",0,0
data/test/8_68.mp3,"copy some code from Mesa into the kernel, which is probably not where we want to go.",0,0
data/test/8_69.mp3,"In the end, what Mesa does is that it implements the command stream and expose well-known API,",0,0
data/test/8_70.mp3,"like Intel VA API, VDAPU, which is now deprecated, and NVDEC decoder. On Microsoft",0,0
data/test/8_71.mp3,"Windows, they also have DXVA2, which is their GPU codec accelerator interface.",0,0
data/test/8_72.mp3,Could we have done things differently? Could we have decided to expose these accelerators as a,0,0
data/test/8_73.mp3,"GPU? I believe we could, but there was a bit of an overhead of having to use one of those",0,0
data/test/8_74.mp3,high-level GPU-centric abstraction layers. How did they model this in the context? They decided,0,0
data/test/8_75.mp3,to build up on top of what was done for the stateful codec. They still have an M2M device,0,0
data/test/8_76.mp3,"with a capture and an output queue, but now they add a lot of controls, and those controls are",0,0
data/test/8_77.mp3,"bitstream-specific. Now, the problem is that you don't just set controls to be applied on the next",0,0
data/test/8_78.mp3,to-be-processed frame in the queue. You want to apply the control to a very specific frame in the,0,0
data/test/8_79.mp3,"bitstream. In order to do that, they created the request API, which is basically an object,",0,0
data/test/8_80.mp3,"a file descriptor, that you can pass when setting the controls and when queuing bitstream buffers.",0,0
data/test/8_81.mp3,"You could see it as if the controls and the buffers are now attached to the request,",0,0
data/test/8_82.mp3,"and then the request is queued, and the driver will process requests rather than processing buffers.",0,0
data/test/8_83.mp3,"This way, you can really associate the right parameters with the right",0,0
data/test/8_84.mp3,"buffer. On top of that, they decided to put this API in the media controller in order for that API",0,0
data/test/8_85.mp3,"in the future to be usable by cameras, and with the media controller came the topology.",0,0
data/test/8_86.mp3,The topology is kind of a really nice feature because there was a big problem of identification,0,0
data/test/8_87.mp3,"of your hardware, of your hardware driver, what your driver is doing actually with the other model.",0,0
data/test/8_88.mp3,The topology gives a very neat view of what your instance can do.,0,0
data/test/8_89.mp3,"Now, it will be really hard to understand all this",0,0
data/test/8_90.mp3,without going a little bit over some codex work. I've picked up H.264 and I'm going to,0,0
data/test/8_91.mp3,give you a little bit of information about H.264 itself. H.264 bitstream is split into,0,0
data/test/8_92.mp3,"NALUs, so Network Access Layer Unit, something like that, and they form a sequence. In this",0,0
data/test/8_93.mp3,"sequence, there's well-known types of NALU that will be found. Notably, the one that we really",0,0
data/test/8_94.mp3,"care about, the SPS, the Sequence Parameter Set, are part of the parameters we need to pass to the",0,0
data/test/8_95.mp3,"IP in order to decode frames. The PPS, the Picture Parameter Set. And then there's slices. Slices are",0,0
data/test/8_96.mp3,"visual bits of information, the bit that you actually decode in order to create an image.",0,0
data/test/8_97.mp3,"And in these slices, there's a header, and we need to parse this header in order to do the",0,0
data/test/8_98.mp3,"bitstream processing. And for some accelerators, like the Allwinner Coda, we need to actually",0,0
data/test/8_99.mp3,"program these headers into the hardware, as the hardware won't parse it. It will just skip over.",0,0
data/test/8_100.mp3,There's different type of slices. The I-slice and the IDR slices are slices that don't use,0,0
data/test/8_101.mp3,"reference, so it's per compression, a bit like your DPEGs or other images like this.",0,0
data/test/8_102.mp3,"And the DR and the IDR means that at this point, it's not allowed to actually, for the following",0,0
data/test/8_103.mp3,"frames, actually to use reference before this point in time. The P-slice are slices that actually",0,0
data/test/8_104.mp3,refer to frame that was presented in the past. And the B-slice actually refers to frame that was,0,0
data/test/8_105.mp3,presented in the past and that are going to be presented in the future.,0,0
data/test/8_106.mp3,I use the term presented because the decoding order will be different from the presentation,0,0
data/test/8_107.mp3,"order. There's a reordering of the queue. Now, these NALU comes in two forms, in two packing.",0,0
data/test/8_108.mp3,"One is the NXB NALU with a start code, which is nice for random access because you can actually",0,0
data/test/8_109.mp3,"locate the beginning of your NALU in the stream and start streaming. And there's another one,",0,0
data/test/8_110.mp3,"the AVCC header, which instead of encoding the start code, they actually allow encoding the size",0,0
data/test/8_111.mp3,of the NAL. So you would read the size and jump over if you don't care about this NAL.,0,0
data/test/8_112.mp3,"So it's much faster to navigate, but you need to receive the data aligned with the NAL.",0,0
data/test/8_113.mp3,"So for storage, we will mostly use AVCC. And for streaming, we will mostly use NALU in this case.",0,0
data/test/8_114.mp3,"Now, the decoding process isn't simple, and I'm just giving you an overview of that decoding",0,0
data/test/8_115.mp3,"process. And this represents what you need to implement in user space. Fortunately, all this",0,0
data/test/8_116.mp3,"stuff is now implemented in Chromium, FFmpeg, and GStreamer. And assuming you have the luxury",0,0
data/test/8_117.mp3,"to be able to use one of these three, you won't have to program it yourself again.",0,0
data/test/8_118.mp3,"So how does it go? So first, you need to locate and parse the NAL headers.",0,0
data/test/8_119.mp3,"Then, you need to parse all the non-VCL information. VCL is the visual coding,",0,0
data/test/8_120.mp3,"actually, the data that you're going to decode. So non-visual or informative NALs that are used",0,0
data/test/8_121.mp3,in the process. And you also need to parse the headers of the VCL NAL in order to retrieve,0,0
data/test/8_122.mp3,"some information there. With this information, you'll have to calculate the frame number",0,0
data/test/8_123.mp3,"and handle the case there would have been some gaps, which happens in lossy networks.",0,0
data/test/8_124.mp3,"This, of course, is a recipe. So it's described in prose in the specification, and you just",0,0
data/test/8_125.mp3,"implement code out of the text. You also have to calculate the picture order count, the PUC,",0,0
data/test/8_126.mp3,"and the picture number, which are numbers that will be used in some logic in the processing",0,0
data/test/8_127.mp3,"of decoding. So you need it for your code in user space, but the IP might need it for some logical...",0,0
data/test/8_128.mp3,"Now, there's two types of decoders. Some decoders will be frame-based, so you pass all the slices",0,0
data/test/8_129.mp3,"of a frame. So in this case, the decoder, the hardware, will have to parse the slice header,",0,0
data/test/8_130.mp3,"so you don't need to pass as much information. And there's those that don't do that, that will",0,0
data/test/8_131.mp3,"decode each slices separately. In that case, we need to prepare the reference list, as we will",0,0
data/test/8_132.mp3,have to provide a very specific ordered set of reference as described by the specification.,0,0
data/test/8_133.mp3,"At that point, you got pretty much all the information you need for the next decode",0,0
data/test/8_134.mp3,"operation. You can fill the SPS, PPS, decode param, slice parameters, and pass that into a",0,0
data/test/8_135.mp3,"V4L structure format and set that to controls. If you're slice-based, you need to apply another",0,0
data/test/8_136.mp3,"algorithm called the modification of reference list, which you pick from the reference that you",0,0
data/test/8_137.mp3,"created for the picture, and you transform them based on a per-slice modification. And finally,",0,0
data/test/8_138.mp3,"you should be able to decode a frame. When a frame is decoded, you do your DPB management. DPB",0,0
data/test/8_139.mp3,"is the picture buffer, the displayed picture buffer. This is used to store your decoded picture",0,0
data/test/8_140.mp3,"and to figure out actually which picture are now ready to be displayed, and which picture",0,0
data/test/8_141.mp3,"no longer have another picture that will have to be decoded, presented before it, because of the",0,0
data/test/8_142.mp3,"B-frames, the order of decoding can be complicated. So it's also a buffer to reorder your frames.",0,0
data/test/8_143.mp3,"On the V4L side, it's much simpler if we just look at driving the hardware itself.",0,0
data/test/8_144.mp3,"So on V4L's side, you need to allocate a request, you need to set all the parameters,",0,0
data/test/8_145.mp3,"you need to queue your bitstream buffers for that request, you set the parameters for that request",0,0
data/test/8_146.mp3,"also, and then you queue that request, and instead of waiting for a buffer to come out,",0,0
data/test/8_147.mp3,you actually wait for that request to complete. So you pull on the file descriptor of the request.,0,0
data/test/8_148.mp3,It's a much simpler process than the other accelerator.,0,0
data/test/8_149.mp3,"And things stay there, and time passed. In 2016, we had yet another stateful decoder",0,0
data/test/8_150.mp3,"from Mediatek, actually provided by Mediatek. It was a bit annoying because it was limited to tile",0,0
data/test/8_151.mp3,"output, which support is still not great in the V4L framework.",0,0
data/test/8_152.mp3,"Then the year after, the Qualcomm Venus driver was merged also, and it's by far today the",0,0
data/test/8_153.mp3,"most featureful codec, as it supports MPEG-4, MPEG-2, H.264, VC1, H.26...",0,0
data/test/8_154.mp3,"What did I say? Okay, H.263. There's a typo in the slide. VP8, VP9, and HEVC to decode.",0,0
data/test/8_155.mp3,"And assuming you got the latest Snapdragon, I think it's 855+, you're gonna have all these",0,0
data/test/8_156.mp3,"encoders too. So MPEG-4, H.263, H.264, VP8, and HEVC. I suspect they're most likely at VP9 also.",0,0
data/test/8_157.mp3,"So, as for our stateless codec implementation, development was pretty much stalled. In fact,",0,0
data/test/8_158.mp3,"it was not stalled, but it was blocked on multiple work in progress. So one of them was",0,0
data/test/8_159.mp3,the request API. So it was hard to finalize a request API. It was picked up and renamed to,0,0
data/test/8_160.mp3,"job API. People didn't like the name, so it was blocked on multiple work in progress.",0,0
data/test/8_161.mp3,"It was picked up and renamed to job API. People didn't like the name, so it came back to request",0,0
data/test/8_162.mp3,API. And it took a while before this was finalized. And it was a key feature in order to get this,0,0
data/test/8_163.mp3,"running. The other problem was that there was a very low knowledge of codec, how codec works in",0,0
data/test/8_164.mp3,"the Linux media community. So maintainers had to train themselves, find some times to understand",0,0
data/test/8_165.mp3,how codec works in order to review and make sure that the design was going to stay long enough.,0,0
data/test/8_166.mp3,"There was only one hardware running so far, the Rockchip 3288 VDPU. And there was just",0,0
data/test/8_167.mp3,no formal specification to help focus on how these decoders are going to be used.,0,0
data/test/8_168.mp3,"And this stayed there until 2018, where really everything started launching. So",0,0
data/test/8_169.mp3,"Bootlink actually started this, made a Kickstarter in order to finance the development of VPU support",0,0
data/test/8_170.mp3,"on all winner chipset. And with this effort, motivation came along. There was a lot of",0,0
data/test/8_171.mp3,"discussion in various workshops, and the request API was finalized. The MPEG-2 support landed in",0,0
data/test/8_172.mp3,staging. H.264 was in progress. And the targeted user space back then was a VA API driver. So,0,0
data/test/8_173.mp3,"basically, you would use your all winner VPU, just like you would use a VPU, an Intel VPU,",0,0
data/test/8_174.mp3,"as an example. It was a good fit, considering that Sidrus, the driver that they created here,",0,0
data/test/8_175.mp3,"actually is a slice space decoder, just like Intel produces.",0,0
data/test/8_176.mp3,"So in 2019, the crowdfunding was full steam. And basically, things started moving.",0,0
data/test/8_177.mp3,"I forgot to mention, the crowdfunding was being developed by Paul Koscialski, an intern at Bootlink,",0,0
data/test/8_178.mp3,and Maxime Ripard. So a formal specification was written. What's a formal specification?,0,0
data/test/8_179.mp3,"In the V4L, in the Linux media community, they try to document how a driver is supposed to be",0,0
data/test/8_180.mp3,"written using the functionality in V4L, and how it's supposed to work. This helps keeping",0,0
data/test/8_181.mp3,"drivers... I mean, it helps keeping the drivers more generic in order to run on various",0,0
data/test/8_182.mp3,"software without any difficulties. H.264, VP8, HEVC support was added with their controls.",0,0
data/test/8_183.mp3,All these controls are not officially stable yet. They're actually staging. So if you want to use,0,0
data/test/8_184.mp3,"them, you need to copy the others from the kernel, as they may have some modification later.",0,0
data/test/8_185.mp3,Then things started to follow on RK3288. The Collabra team actually started looking at finalizing,0,0
data/test/8_186.mp3,"Google upstreaming of that. And MPEG-2, H.264, VP8 was added. JPEG encoder was also added.",0,0
data/test/8_187.mp3,And something special happened.,0,0
data/test/8_188.mp3,"So at that time, my colleagues were a bit overwhelmed by all this work. They didn't",0,0
data/test/8_189.mp3,"know much about Bitstream. I was in multimedia. I had worked on the GStreamer parser a little bit,",0,0
data/test/8_190.mp3,so I already had a good base knowledge. So I came to help and understand and review all these API,0,0
data/test/8_191.mp3,"in order to make this... to make all this work, actually, and make this proper. And",0,0
data/test/8_192.mp3,"as I was seeking for documentation on the Rockchip side and for other hardware, I was also in",0,0
data/test/8_193.mp3,discussion with Chris Haley from Zodiac. Chris is well known for having pushed forward at Naviv,0,0
data/test/8_194.mp3,"reverse engineering projects, the GPU driver called V20, for V20 chip. And he was also in",0,0
data/test/8_195.mp3,"the... he was also behind CODA, pushing that CODA forward as he's using it at Zodiac in the",0,0
data/test/8_196.mp3,"infotainment system. And while I was discussing with him, he was presenting me his new iMX8M-based",0,0
data/test/8_197.mp3,"devices, which was the new generation of in-flight entertainment there.",0,0
data/test/8_198.mp3,"And he was also presenting me his new iMX8M-based devices, which was the new generation of in-flight",0,0
data/test/8_199.mp3,entertainment. And he knew back then that this new hardware from NXP didn't use the CODA chips,0,0
data/test/8_200.mp3,"to do the multimedia. And instead, they had picked a design from Hantro",0,0
data/test/8_201.mp3,"company that was called G1 and G2, two different cores.",0,0
data/test/8_202.mp3,So I was quite curious and I started searching for documentation. NXP is kind of nice because,0,0
data/test/8_203.mp3,you just need to exchange your email and you get the documentation. So I started comparing,0,0
data/test/8_204.mp3,"the documentation of RK3288 and the iMX8M, to my surprise, found out that they were not just",0,0
data/test/8_205.mp3,"similar, they were identical. The register set was binary compatible between the two devices.",0,0
data/test/8_206.mp3,"And then I came to my colleague and I'm like, hmm, I don't think this is a RockChip design.",0,0
data/test/8_207.mp3,I don't think this driver should be called RockChip anymore.,0,0
data/test/8_208.mp3,So just a little bit about Hantro and why we decided to rename this driver Hantro.,0,0
data/test/8_209.mp3,Hantro was a Finnish company that eventually got bought by Antu. Antu themselves got acquired by,0,0
data/test/8_210.mp3,"Google and within Google, Antu developed the well-known VP8 codec that was one of the first",0,0
data/test/8_211.mp3,"royalty-free viable codec out there. It was not the first, of course. And then came VP9,",0,0
data/test/8_212.mp3,which is highly used now on YouTube and everything on the web. Google didn't really,0,0
data/test/8_213.mp3,"want to keep that, but they did great, great work as the Hantro team actually made a VP9",0,0
data/test/8_214.mp3,design and that was made freely available to any silicon vendors. This business of hardware,0,0
data/test/8_215.mp3,"was then sold to Verisilicon, who was still doing new revision of this decoding hardware.",0,0
data/test/8_216.mp3,"What we wanted to avoid, and that was something I had learned about just a couple of weeks before",0,0
data/test/8_217.mp3,"we found that this hardware was not actually RockChip, was the story about STM Mac. So STM",0,0
data/test/8_218.mp3,"Mac is an Ethernet driver that is in the Linux kernel. And it is still called STM Mac, even though",0,0
data/test/8_219.mp3,"the hardware is actually DesignWare. And it's not just a DesignWare, it's the DesignWare,",0,0
data/test/8_220.mp3,"the one that is used on most SBC out there. So that's very confusing when you first see that,",0,0
data/test/8_221.mp3,"but STM Mac is actually DesignWare driver, generic driver used across multiple SOC.",0,0
data/test/8_222.mp3,And so we avoided to repeat a history mistake. The project continued and we finally got,0,0
data/test/8_223.mp3,"more support from the community with the folks from LibreElect and Kodi, who came along and",0,0
data/test/8_224.mp3,"started and implemented this FFmpeg backend. So when we started, we only had the VA driver,",0,0
data/test/8_225.mp3,"which was limited to Cedris support, or the Chromium browser, which wasn't limited, but",0,0
data/test/8_226.mp3,it's more complicated to do testing with a full-fledged browser. So they provided this,0,0
data/test/8_227.mp3,FFmpeg support and that actually boosted the development as we could do faster testing and,0,0
data/test/8_228.mp3,validation of our decoder. They also provided a lot of bug fixing in the driver in Cedris.,0,0
data/test/8_229.mp3,"They implemented interlaced content support, which we didn't have initially.",0,0
data/test/8_230.mp3,"And came 2020, everything was full steam. Support for the RockChip 3399 came in with the RKVDEC",0,0
data/test/8_231.mp3,"driver, which is this time a RockChip design. And something moved in GStreamer, so we gained",0,0
data/test/8_232.mp3,"generic base classes to do hardware acceleration decoding in GStreamer, something that FFmpeg had",0,0
data/test/8_233.mp3,"for years and years, which we didn't have in GStreamer. Instead, Intel, who was behind this",0,0
data/test/8_234.mp3,"development, decided to write some code highly specific to the API, and it was not possible to",0,0
data/test/8_235.mp3,"reuse this code. So Sung Ha, a GStreamer developer that was working at NavCorp back then, wanted to",0,0
data/test/8_236.mp3,"have DXVA2 support on Windows. And while doing it and while going through the reviews, he already",0,0
data/test/8_237.mp3,"had kind of split the Bitstream generic part and the DXVA part, so I've asked him kindly if he",0,0
data/test/8_238.mp3,"could split that into base classes, which he did. And later I took those base classes and I made a",0,0
data/test/8_239.mp3,"new library within GStreamer called libgst-codec, which depends, of course, on libgst-parsers.",0,0
data/test/8_240.mp3,And it actually forms a very neat base class that we can share among multiple implementations.,0,0
data/test/8_241.mp3,So we could easily see in the future to port actually the VA API stuff on these base classes,0,0
data/test/8_242.mp3,in order to share the Bitstream work and enhancements that we do.,0,0
data/test/8_243.mp3,"On top of that, he implemented stateless support for NVDeck, because NVDeck property library offers",0,0
data/test/8_244.mp3,"both a stateful and a stateless interface, and it provides a little lower latency when you use",0,0
data/test/8_245.mp3,"the stateless interface. And then, beginning of the year, I implemented GStreamer support",0,0
data/test/8_246.mp3,"for H.264 and VP8 decoder, and it actually landed upstream. I guess it's much easier when you're",0,0
data/test/8_247.mp3,the maintainer of such a subsystem in GStreamer. But it was a nice addition also to our testing,0,0
data/test/8_248.mp3,workflow as GStreamer opened up other ways of using and testing the hardware.,0,0
data/test/8_249.mp3,"All this was targeting, I mean, I was racing this, and I was targeting the Embedded World",0,0
data/test/8_250.mp3,"Conference, and I was supposed to do a demo there. And we actually managed to get this",0,0
data/test/8_251.mp3,all in time until COVID appeared and they cancelled the show.,0,0
data/test/8_252.mp3,So I never got to show the demo that we actually had prepared.,0,0
data/test/8_253.mp3,"And then, now that we had FFmpeg support, Chromium support, and GStreamer native support,",0,0
data/test/8_254.mp3,"it was commonly decided that there would be no more work done on the VA driver,",0,0
data/test/8_255.mp3,"as it was not very relevant anymore. There's, of course, a lot more to come in 2020 at 2m distance.",0,0
data/test/8_256.mp3,"Now, all this work enables Codec, the hardware decoding support on many interesting projects,",0,0
data/test/8_257.mp3,"and I only picked three of them, but there's more, of course. And interestingly, the MNT Reform",0,0
data/test/8_258.mp3,"laptop, which is a fully open-source and blob-free laptop running mainline Linux,",0,0
data/test/8_259.mp3,"is based on iMX8M, which has one of the supported decoders.",0,0
data/test/8_260.mp3,"In the middle that represents the Pine64 phone is an Allwinner64 chip, which is supported by",0,0
data/test/8_261.mp3,"Cedrus, and on the right, the Parism phone, the Librem5, running some GNOME stack, actually,",0,0
data/test/8_262.mp3,"and using GStreamer, actually, again, the ability to do hardware decoding. So quite a win.",0,0
data/test/8_263.mp3,"And now, it's going to be showtime.",0,0
data/test/8_264.mp3,"So, in order to demonstrate all this, I have chosen the LibreComputer Tritium,",0,0
data/test/8_265.mp3,because I really like what LibreComputer do. They provide a wide variety of chips that have,0,0
data/test/8_266.mp3,"the potential to be fully supported mainline, or are already fully supported mainline,",0,0
data/test/8_267.mp3,"in very simple packages like this. In this case, it's the Allwinner H3, and we're going to",0,0
data/test/8_268.mp3,"Allwinner H3, and we're going to demonstrate the CODA driver. In order to do that,",0,0
data/test/8_269.mp3,"I brought a little HDMI recorder from a company called Inogenie, one of the rare",0,0
data/test/8_270.mp3,"French-Canadian hardware companies I know. So, I'm going to plug HDMI in there.",0,0
data/test/8_271.mp3,"As I'm doing TFTP NFS booting, I'm going to put Ethernet, and finally, I'm going to boot it up.",0,0
data/test/8_272.mp3,"Oh, I'm going to show you the console, and I'm going to boot it up straight",0,0
data/test/8_273.mp3,"from my laptop power, and hopefully, that's going to work.",0,0
data/test/8_274.mp3,That's going to work.,0,0
data/test/8_275.mp3,"Oh, I've also connected the little keyboard, so I can actually log in and type. So, now it's",0,0
data/test/8_276.mp3,"booting. So, in this case, my NFS root is Fedora running in the background. It's running",0,0
data/test/8_277.mp3,"the head of Linux TV 3 with one of the patches I've submitted upstream. So, I'm going to log in.",0,0
data/test/8_278.mp3,"Voila. And I'm also going to run the latest GStreamer, actually, from yesterday.",0,0
data/test/8_279.mp3,"And I'm going to use it, what we call uninstall. So, I'm using GST build to build the integrity",0,0
data/test/8_280.mp3,"of GStreamer, to cross build the integrity of GStreamer for the platform. And this command,",0,0
data/test/8_281.mp3,"GST uninstall.py, will actually set up an environment so the plugin can be used in",0,0
data/test/8_282.mp3,"place without being spread out. It takes a little while because files are, there's a lot of path,",0,0
data/test/8_283.mp3,"and the path are getting big, but it will get there, and NFS is not helping, of course.",0,0
data/test/8_284.mp3,"So, now the, as a media player, because I don't have any graphical setup in there,",0,0
data/test/8_285.mp3,"I'm going to use GST play with KMS sync, and that's going to go on the video overlay plane.",0,0
data/test/8_286.mp3,But that plane is normally in the background. It's an underlay on this device and on most,0,0
data/test/8_287.mp3,"modern devices. But this hardware has this nice capability that you can change the Z order. So,",0,0
data/test/8_288.mp3,I'm setting Z pass to two to bring it up in front so you can actually see the video.,0,0
data/test/8_289.mp3,"And in the video itself, it's coming, pre-rolling, I'm actually displaying,",0,0
data/test/8_290.mp3,"let me pause here, the demo that we had prepared for Embedded World 2020. On the left,",0,0
data/test/8_291.mp3,"that's the monitor of the streaming server, which provides streaming transcodes in various formats,",0,0
data/test/8_292.mp3,"SRT, REST, and HLS. I'm not going to go into these, that's not the goal of the day.",0,0
data/test/8_293.mp3,"And on that screen, it's actually an IMX 8M evaluation kit running the demo. And then in the",0,0
data/test/8_294.mp3,"back, this little device here, is the Zodiac, it's the upcoming, actually, Zodiac entertainment",0,0
data/test/8_295.mp3,system for planes that is under development. And we decided to demo some touchscreen capabilities,0,0
data/test/8_296.mp3,and some underlays capabilities that is made possible. It's actually a mix of underlays and,0,0
data/test/8_297.mp3,GPU rendering on this device with smooth hardware accelerated decoding. And that's it for the demo.,0,0
data/test/8_298.mp3,"Hope you enjoyed. And on that, if you have any questions, you can place your question into the",0,0
data/test/8_299.mp3,"Inspo system and share with us. We will try to, I will try to insert as many as possible.",0,0
data/test/8_300.mp3,"Thank you for watching. Thanks for Collabra for making this presentation possible, and enjoy your summer.",0,0
data/test/8_301.mp3,you,0,0
data/train/1_0.mp3,"Hello everyone, my name is André Almeida, and I'm based in Brazil, and I'm a Kernel",0,0
data/train/1_1.mp3,"engineer at Collabra, an open source consultancy.",0,0
data/train/1_2.mp3,So today I want to share some tips and tricks from my Kernel development workflow that I,0,0
data/train/1_3.mp3,have in Arch Linux.,0,0
data/train/1_4.mp3,"And this is an overview of the things I'm going to show here, it's kind of a tutorial.",0,0
data/train/1_5.mp3,"And first of all, I use Arch Linux for both professional and personal use.",0,0
data/train/1_6.mp3,"For professional use, I found very handy to have a lot of very up-to-date packages, and",0,0
data/train/1_7.mp3,"as part of Arch philosophy, they are very close to mainline, so maintainers rarely apply",0,0
data/train/1_8.mp3,packs to each.,0,0
data/train/1_9.mp3,"And for instance, if I want to boot a custom Kernel, I don't need to change anything in",0,0
data/train/1_10.mp3,"the user space, everything will be ready to run my custom Kernel from mainline.",0,0
data/train/1_11.mp3,"And also, in this tutorial, I'll be showing how to use a virtual machine, because booting",0,0
data/train/1_12.mp3,"your own custom Kernel requires some time, and it's very painful to reboot your machine",0,0
data/train/1_13.mp3,just to check if your print is working.,0,0
data/train/1_14.mp3,"So also, I found very useful to have a different root FS, so I can do some experimental changes",0,0
data/train/1_15.mp3,"on all the stack, and I do not risk breaking my system.",0,0
data/train/1_16.mp3,"But if you want to use the same root FS of your installation on your testing, I recommend",0,0
data/train/1_17.mp3,"you checking the tool called Virtme, that is a wrapper around QEMU.",0,0
data/train/1_18.mp3,"And one more thing that I found very useful from Arch Linux is the Keep It Simple philosophy,",0,0
data/train/1_19.mp3,"and on my workflow, I try to apply this principle as well.",0,0
data/train/1_20.mp3,"So for my workflow, I just need two additional tools, that is the Arch Install Scripts, that",0,0
data/train/1_21.mp3,will provide the same scripts that you use on installation disk to install a new Arch,0,0
data/train/1_22.mp3,"Linux, and QEMU, that will provide the virtualization.",0,0
data/train/1_23.mp3,"And first of all, we need somewhere to store our root FS, and for this, I create a file",0,0
data/train/1_24.mp3,"of 5 Gb, I use Stuncrate, because in that way, I can have a spare file that will grow",0,0
data/train/1_25.mp3,"as need, it won't be using 5 Gb from storage.",0,0
data/train/1_26.mp3,"After that, I format this file to have the XT4 file system, and then I just mount this",0,0
data/train/1_27.mp3,file in a directory.,0,0
data/train/1_28.mp3,"After that, we can use the backstrap, that is the same script that we use in an Arch",0,0
data/train/1_29.mp3,"Linux installation, to create all the directories and install some basic software there.",0,0
data/train/1_30.mp3,"If your system is up to date, you can use the flag ""-c"", so instead of downloading the",0,0
data/train/1_31.mp3,"package again, you just use the cache from the host system.",0,0
data/train/1_32.mp3,"And after that, your root FS is complete in less than 2 minutes.",0,0
data/train/1_33.mp3,"Also this is useful to install an editor, like Vim, or in the DHCP client as well.",0,0
data/train/1_34.mp3,"And using backstrap and the cache flag, you won't need to download anything from the internet,",0,0
data/train/1_35.mp3,so it's a very easy and fast setup.,0,0
data/train/1_36.mp3,"And since the root FS is mounted, we can easily copy our SSH key there, and also we can use",0,0
data/train/1_37.mp3,"chroot to change the root password, and if you are always going to log in as root, you",0,0
data/train/1_38.mp3,"can change the system de-configuration, so you can always auto-login in the root user.",0,0
data/train/1_39.mp3,"Those steps will help us in the future, to make the use of the virtual machine easier.",0,0
data/train/1_40.mp3,"And now, for using QEMU, these are the flags that I use.",0,0
data/train/1_41.mp3,"The first flag is ""-hda"", that is to tell QEMU where is my disk, and then I use the",0,0
data/train/1_42.mp3,kernel flag to specify the path of my compiled kernel.,0,0
data/train/1_43.mp3,"In this talk, I'm not covering how to compile your own custom kernel, but if you want, you",0,0
data/train/1_44.mp3,"can also use this flag with your current installed kernel of your system, that is probably located",0,0
data/train/1_45.mp3,somewhere in the boot directory.,0,0
data/train/1_46.mp3,"And also, I use the append flag to use some kernel parameters, for instance, the root",0,0
data/train/1_47.mp3,"parameter tells the kernel where it can find the root, in which disk is the root FS, so",0,0
data/train/1_48.mp3,"here is the first disk, the ""-hda"", we send also the parameter with write, because we",0,0
data/train/1_49.mp3,"want to change the root FS, and with console.tti.so, you can tell the kernel where it should display",0,0
data/train/1_50.mp3,the output and the shell when it boots.,0,0
data/train/1_51.mp3,"Some useful flags as well, is the flag ""-m"", so you can specify how much memory you want",0,0
data/train/1_52.mp3,to give to your guest.,0,0
data/train/1_53.mp3,"Enable KVM will make a huge difference on your performance, and remember to enable virtualization",0,0
data/train/1_54.mp3,"on your BIOS menu, on your motherboard.",0,0
data/train/1_55.mp3,"And also, I like to use with the flag no-graph, so KVM will just run as a console application",0,0
data/train/1_56.mp3,"like Vim, and also use the ""-smp"", you can specify how many cores you want to give to",0,0
data/train/1_57.mp3,your guest.,0,0
data/train/1_58.mp3,"If you want to use networking inside your machine, for instance, if you want to use",0,0
data/train/1_59.mp3,"GitClone or use Pacman to get a new software, you can easily enable it by just starting",0,0
data/train/1_60.mp3,"the ACP client that you installed here, I'm using the ACPCD for that.",0,0
data/train/1_61.mp3,So copying and pasting files isn't a very efficient way to share some files with the,0,0
data/train/1_62.mp3,"guest, so what I do is I create a shared folder.",0,0
data/train/1_63.mp3,"In order to do that, you need to be sure that your kernel has some modules enabled, like",0,0
data/train/1_64.mp3,mainly in modules that are related to the 9np sharing protocol.,0,0
data/train/1_65.mp3,"And after that, in the king of flags, I will add two devices, a file system device and",0,0
data/train/1_66.mp3,then a virtio 9p device.,0,0
data/train/1_67.mp3,"So you use this flag to choose which directory you want to share, in this example, I'm sharing",0,0
data/train/1_68.mp3,a directory named files inside my home directory of the user.,0,0
data/train/1_69.mp3,And the name of the virtual device will be shared folder.,0,0
data/train/1_70.mp3,"And then, inside the guest fstab file, you just need to add this line for the shared",0,0
data/train/1_71.mp3,folder device and specifying where do you want the multi point to be inside your guest.,0,0
data/train/1_72.mp3,"During your testing, you may be required to use some graphical applications, and I know",0,0
data/train/1_73.mp3,two ways of doing that.,0,0
data/train/1_74.mp3,"My favorite one is the first I'm going to show, that is the ssh-forge, but you can also",0,0
data/train/1_75.mp3,use the king display.,0,0
data/train/1_76.mp3,"So in order to use the ssh-forge, first you need to install the OpenSSD server on your",0,0
data/train/1_77.mp3,guest and initiate the dynamo.,0,0
data/train/1_78.mp3,You can find it on the OpenSSH package.,0,0
data/train/1_79.mp3,"And then you change some configuration on the ssh configuration file, namely you permit",0,0
data/train/1_80.mp3,the root login and also you say yes for x11 forwarding.,0,0
data/train/1_81.mp3,"For the chemoflags, you need to create a basic network card, and here we forward the port,",0,0
data/train/1_82.mp3,"you need to forward some ports, so you don't mess with the host ports.",0,0
data/train/1_83.mp3,"Here I'm forwarding the port 1337 to the port 22, so basically this is the setup, and",0,0
data/train/1_84.mp3,"then if you run ssh-xroot at localhost, and then you specify your port, and just by doing",0,0
data/train/1_85.mp3,"that on your guest machine, you will be able to run graphical applications.",0,0
data/train/1_86.mp3,"Here's an example, on the left side I have my host, the guest machine, and then on the",0,0
data/train/1_87.mp3,"right side I will use ssh, and then after doing that I can open the xloc graphical application.",0,0
data/train/1_88.mp3,"And now if you want a more complete graphical solution, you can run a whole compositor inside",0,0
data/train/1_89.mp3,your virtual machine.,0,0
data/train/1_90.mp3,"For that, the first thing you do is to remove the no-graphic-output option on chemoflags,",0,0
data/train/1_91.mp3,"and then after that you need to install some kind of compositor, here I'm using Weston",0,0
data/train/1_92.mp3,"because it's very lightweight, so I installed the package of XWayland and Weston.",0,0
data/train/1_93.mp3,"And then after that, you need to configure your Weston to run on XWayland, so you need",0,0
data/train/1_94.mp3,"to create this file on your home folder, and say xlab xwayland equals true, then you",0,0
data/train/1_95.mp3,"just run Weston on the command line, and the Weston environment will appear, you can use",0,0
data/train/1_96.mp3,"your mouse to open the terminal, and inside there you can call the graphical application",0,0
data/train/1_97.mp3,that you want.,0,0
data/train/1_98.mp3,"And when you are done, you just hold ctrl, alt and backspace and Weston will close.",0,0
data/train/1_99.mp3,"And this is a very basic setup using QEMU display, here you won't have support for clipboard,",0,0
data/train/1_100.mp3,"for sharing the same clipboard, or multi-monitor support, if you want to do that I recommend",0,0
data/train/1_101.mp3,"you to use the Virtumanager, that is a frontend for QEMU with LibreVirge, and then you can",0,0
data/train/1_102.mp3,have a very nice graphical experience.,0,0
data/train/1_103.mp3,"Ok and that's it, this is how I spawn new virtual machines, if I need to do some testing,",0,0
data/train/1_104.mp3,"and also sharing files with my virtual machine, running graphical applications, and as you",0,0
data/train/1_105.mp3,"can see, it requires almost no new program, everything is command line applications, so",0,0
data/train/1_106.mp3,"it's very easy to create some batch scripts, here is the link for a git repository where",0,0
data/train/1_107.mp3,"I store my scripts, and also here is a link of our blog post at the Colabra website, where",0,0
data/train/1_108.mp3,you can find a more detailed explanation of my talk.,0,0
data/train/1_109.mp3,"And thanks for watching, and now I would like to hear if you also have some tips of kernel",0,0
data/train/1_110.mp3,development workflow.,0,0
data/train/1_111.mp3,Thank you.,0,0
data/train/4_0.mp3,"Hello, everyone. My name is George, and I'm a senior software engineer at Collabora. Today,",0,0
data/train/4_1.mp3,"I am going to talk to you about video support in AGL, taking a look at the various use cases",0,0
data/train/4_2.mp3,"for having video in a car, looking at the requirements that these use cases have, and",0,0
data/train/4_3.mp3,presenting potential software solutions from the viewpoint of AGL. Let's start by taking,0,0
data/train/4_4.mp3,"a look at the use cases. So, in modern cars, the need for dealing with video is more and",0,0
data/train/4_5.mp3,"more growing, and some use cases have to do with using cameras. A popular feature, for",0,0
data/train/4_6.mp3,"example, is to have dashboard cameras, cameras that record what is in front of the car in",0,0
data/train/4_7.mp3,the street. Or another popular feature is to install cameras at the back of the car,0,0
data/train/4_8.mp3,"and use it for rear-view display, showing to the driver what is behind the car, useful",0,0
data/train/4_9.mp3,"when going in reverse. Another modern use case has to do with AI processing. So, some",0,0
data/train/4_10.mp3,"cars install cameras to, for example, monitor the driver's condition. Or another use case",0,0
data/train/4_11.mp3,is to install cameras to monitor the surroundings of the car and implement autonomous driving.,0,0
data/train/4_12.mp3,"Another use case has to do with displaying video. So, of course, when capturing feed from the back",0,0
data/train/4_13.mp3,"of the car, we need to display it somewhere for the driver to be able to see it. And this is",0,0
data/train/4_14.mp3,"currently done, for example, with mirrors that have this integrated display, rear-view mirrors,",0,0
data/train/4_15.mp3,"or displays in the dashboard of the car. And then there is, of course, the use case of providing",0,0
data/train/4_16.mp3,"entertainment for the passengers. So, some cars install, for example, rear-seat displays that rear",0,0
data/train/4_17.mp3,passengers can use to display video content. And then we have things that are going on in the,0,0
data/train/4_18.mp3,"background. So, for instance, recording video, maybe from the dashboard camera, that's the most",0,0
data/train/4_19.mp3,common case to record the video from the dashboard camera. Or another use case has to do with,0,0
data/train/4_20.mp3,"processing. As I said, some cars implement AI processing for autonomous driving or for monitoring",0,0
data/train/4_21.mp3,"the driver and maybe other things. And another thing that is done with video is to stream it,",0,0
data/train/4_22.mp3,"stream it to the rear seats, for example, or stream it to the network or stream it from the network to",0,0
data/train/4_23.mp3,"get video content from an external source. So, let's take a look at the requirements. First of all,",0,0
data/train/4_24.mp3,"safety. We cannot implement anything that is not safe for the passengers. So, that's the top priority.",0,0
data/train/4_25.mp3,Then a very important issue in the context of the car is how to control all these video streams. Since we have,0,0
data/train/4_26.mp3,"many different components dealing with video, cameras, displays, processing nodes, and we also have",0,0
data/train/4_27.mp3,"streams going to or from the network, all of these need to be controlled centrally and they need to be",0,0
data/train/4_28.mp3,secured so that nothing malicious can happen. No malicious application can take control of something or do,0,0
data/train/4_29.mp3,something that is not intended. And then we also need to deal with the fact that all processing must be done in,0,0
data/train/4_30.mp3,"real time. We are capturing live video, we are displaying live video, and we're processing live video. So,",0,0
data/train/4_31.mp3,"anything we do, it must be able to be done in real time. And then we also need to make sure that we leverage the",0,0
data/train/4_32.mp3,hardware appropriately for efficiency and for safety. We need to be able to use dedicated hardware for dedicated,0,0
data/train/4_33.mp3,"purposes. And we need to be able to split the work across nodes in the car. Finally, when it comes to entertainment, we",0,0
data/train/4_34.mp3,need to be able to deal with digital rights management. We need to be able to use modules that decode DRM protected,0,0
data/train/4_35.mp3,"content in a safe way and respecting the DRM standards. So, where does AGL fit in this? AGL is a software system that can",0,0
data/train/4_36.mp3,"be present in multiple places in the car, right? It implements the operating system of the various components. And it",0,0
data/train/4_37.mp3,"may be running in multiple CPUs and multiple nodes at the same time, implementing different things in each one of them.",0,0
data/train/4_38.mp3,"So, one of the things that it may implement is some central system management node. It may implement the entertainment",0,0
data/train/4_39.mp3,"system, it may implement software that runs on dedicated displays, like the rear view mirror or the rear seat displays. It may",0,0
data/train/4_40.mp3,"implement software that runs on the cameras. And it's actually a very common thing for network cameras, not car cameras, but",0,0
data/train/4_41.mp3,network security cameras to be running Linux-based systems. And that would probably make sense also for cameras running in a,0,0
data/train/4_42.mp3,"car. And AGL may also be used in processing software, in implementing the nodes that process data and provide analysis of the",0,0
data/train/4_43.mp3,"video feeds or to implement recording and things like that. So, let's assume that we want to implement such a system with AGL. Let's",0,0
data/train/4_44.mp3,take a look from the perspective of the system running AGL and look at what the apps have available beneath them to deal with video,0,0
data/train/4_45.mp3,"input, output and processing. On the input and output side, well, right away applications can access devices that are directly",0,0
data/train/4_46.mp3,"connected to the CPU they are running on using Video for Linux, which is the standard Linux kernel API for dealing with video",0,0
data/train/4_47.mp3,"devices. And nowadays, there's also another project called LibCamera, which is trying to bring modern camera features into Linux, both in",0,0
data/train/4_48.mp3,the kernel and in the user space. Something that Video for Linux is not able to deliver appropriately. Then we have network,0,0
data/train/4_49.mp3,"streams. So, video content can be input or output from the in-car network or from the internet. And yeah, we have the standard network",0,0
data/train/4_50.mp3,"APIs to deal with that, or proprietary APIs in the case of proprietary networks or proprietary devices that do not follow the standards",0,0
data/train/4_51.mp3,"and do not use Video for Linux. Although that's not recommended. And then for processing, we have, we may have software processing",0,0
data/train/4_52.mp3,components that take video feeds from the kernel and process them and output them somewhere else. Or we may have hardware video processing,0,0
data/train/4_53.mp3,units that we access again through Video for Linux. Or we may have network components that we send the video to and we get some results back or,0,0
data/train/4_54.mp3,"we don't get results back, we just send it and if something else happens there. And then for display, we have Wayland, the standard display",0,0
data/train/4_55.mp3,API for displaying things in our local display. And then we may again be using the network sending something for display to another node in,0,0
data/train/4_56.mp3,"the car. Or we may be using hardware display overlays, which may be done through Wayland or through some other APIs. I've seen some devices",0,0
data/train/4_57.mp3,"using, for example, Video for Linux devices for overlays, or proprietary APIs. Although that's all not so recommended nowadays, the standard",0,0
data/train/4_58.mp3,"approach is to integrate that with Wayland. As you can see, there's a lot going on in the system. And it becomes more and more complex when you",0,0
data/train/4_59.mp3,"start combining multiple nodes in the car. So you may have an application that requires cooperation of multiple AGL and non-AGL systems, streaming",0,0
data/train/4_60.mp3,"video across multiple points in the car from the camera to a processing unit to a display, for example. So when it comes to this, it starts becoming",0,0
data/train/4_61.mp3,"quite complex. And the need is to have a standard set of APIs and tools to deal with all of these. From the viewpoint of the application, the",0,0
data/train/4_62.mp3,standard software to use for implementing multimedia software is TreeStreamer. TreeStreamer is the de facto open source industry,0,0
data/train/4_63.mp3,"standard for building multimedia software. It comes with a wide range of plugins for all kinds of input, output, and processing of all kinds of",0,0
data/train/4_64.mp3,"media, audio, video, and others. And it basically can bridge all of the APIs that I mentioned earlier. So it bridges Video for Linux, Sleep Camera,",0,0
data/train/4_65.mp3,"software processing components, Wayland, and proprietary APIs, and many, many other things that you may need in order to get the work done. So it basically makes",0,0
data/train/4_66.mp3,"the job easier for applications. It heavily lifts all the application level needs, leading to the applications to do just what they need to do and not deal with the",0,0
data/train/4_67.mp3,"multimedia data. And not to mention that it's highly extensible and customizable. So if something cannot be done at the moment, it's possible to extend it, add some plugins, and make it",0,0
data/train/4_68.mp3,talk to your device or your software component.,0,0
data/train/4_69.mp3,"And from the viewpoint of the system, where we may have multiple applications, trying to get access to a single device, or trying to share content between them, or where we have remote streams coming and going to from the",0,0
data/train/4_70.mp3,"network, the solution for managing all of these streams is Pipewire. Pipewire can be described as a stream exchange framework that allows interconnecting applications and network nodes, allowing them to share devices and share streams in a secure",0,0
data/train/4_71.mp3,"way, and applying policy that secures what applications can and cannot do. Pipewire allows isolating applications from each other and from devices. It was actually built with containers in mind. So it was built to be able to",0,0
data/train/4_72.mp3,"to make applications access a device securely without actually having direct access to the device. The device may be visible from one container and the application in another container, and it gets secure access through the Pipewire system.",0,0
data/train/4_73.mp3,"Or similarly, it can be done with applications in different containers, sharing a stream,",0,0
data/train/4_74.mp3,from one application to the other.,0,0
data/train/4_75.mp3,And this allows actually,0,0
data/train/4_76.mp3,"implementing more smaller applications, smaller and self-contained applications that do a small task each. So for example, you may want to have a system that captures video from a camera, and then displays it in the screen and records it. And these are three separate functions that can be used to do that.",0,0
data/train/4_77.mp3,"So it can be in different applications and actually in different containers, sharing the stream through Pipewire.",0,0
data/train/4_78.mp3,"Pipewire is also very efficient. It has low-level real-time processing capabilities, and it allows leveraging the hardware to its full extent",0,0
data/train/4_79.mp3,by using,0,0
data/train/4_80.mp3,"hardware buffers. So it can make use of hardware buffers to pass a stream from one device to another through a series of applications that do something with the stream without actually copying the data to the CPU memory,",0,0
data/train/4_81.mp3,if not necessary.,0,0
data/train/4_82.mp3,"Now, Pipewire, you already know that Pipewire is currently used to implement the audio system in AGL. Actually, both Pipewire and GStreamer are used in audio.",0,0
data/train/4_83.mp3,"There are similarities with the audio system. Actually, it's essentially the same system. The principles are not different. The only thing that differs is the kind of data that exists in the buffers. In one case, it's audio. In the other case, it's video.",0,0
data/train/4_84.mp3,"Everything else stays the same. So input, processing, output in multiple streams, local streams, network streams, streams coming from the network, I mean, from the internet or going to the internet, things like that, and",0,0
data/train/4_85.mp3,applying policy to all of those streams. This is all the same as with audio.,0,0
data/train/4_86.mp3,So reusing the infrastructure that is currently in place for audio makes sense to implement a video system.,0,0
data/train/4_87.mp3,"But first, we need to define our goals.",0,0
data/train/4_88.mp3,Suppose we want to do an AGL demo with some video features. Video is a very broad term. There's a lot of things that we can do with video. So the very first thing we need to do is to define our goals.,0,0
data/train/4_89.mp3,Define what exactly we want to show and we want to support as a community.,0,0
data/train/4_90.mp3,"And also, we need to narrow down the scope, what the features exactly are, and what are the features that we want to show in the AGL demo.",0,0
data/train/4_91.mp3,"And also, we need to narrow down the scope, what the features exactly will be, and what the supported hardware will be, because it's very different to work, for example, with a desktop USB camera.",0,0
data/train/4_92.mp3,"That is, it's very easy to work with in a demo, but it's very different than using an automotive-grade network camera.",0,0
data/train/4_93.mp3,"Next thing, we need to implement a demo application and add some features that are currently missing from Pipewire and Wireplumber.",0,0
data/train/4_94.mp3,Both Pipewire and Wireplumber have been designed for being able to deal with video data.,0,0
data/train/4_95.mp3,"And with all these use cases that I mentioned today, they have all been integrated in the design of Pipewire and Wireplumber.",0,0
data/train/4_96.mp3,"The thing is, of course, that not all of it is implemented.",0,0
data/train/4_97.mp3,"We currently support video on the desktop, so on the desktop we can do sharing of cameras",0,0
data/train/4_98.mp3,"with video for Linux, that is captured through video for Linux from the system and then shared",0,0
data/train/4_99.mp3,"to applications. And we can also do sharing of video between applications, which is currently",0,0
data/train/4_100.mp3,used for screencasting. So the typical scenario is that the Wayland compositor that draws,0,0
data/train/4_101.mp3,the screen captures the video from the screen and then uses Pipewire to send it,0,0
data/train/4_102.mp3,to the application that implements the network streaming.,0,0
data/train/4_103.mp3,"Now, finally, we need to ensure that we have all the necessary JuStreamer features integrated",0,0
data/train/4_104.mp3,and anything else that may be missing from the Yocto build system and things like that.,0,0
data/train/4_105.mp3,So that was all from me today. Thank you very much for attending my talk and I hope to be able to see,0,0
data/train/4_106.mp3,"you all again soon, sometime later this year or next year. Thank you very much.",0,0
data/train/3_0.mp3,"Hello, everyone.",0,0
data/train/3_1.mp3,So today I'm going to tell you the story of an open source network protocol and how we,0,0
data/train/3_2.mp3,brought SRT from a proprietary software to an open source success.,0,0
data/train/3_3.mp3,So who am I?,0,0
data/train/3_4.mp3,My name is Olivier Cahet.,0,0
data/train/3_5.mp3,"I'm the multimedia domain lead at Collabra, where I've worked since 2007.",0,0
data/train/3_6.mp3,"But I've also been an open source developer since 1999, first working on a GNOME.",0,0
data/train/3_7.mp3,"And since I've been an active developer of the distro community, I'm one of the core",0,0
data/train/3_8.mp3,maintainers.,0,0
data/train/3_9.mp3,And this is something I've been doing for over a decade now.,0,0
data/train/3_10.mp3,What are we going to talk today?,0,0
data/train/3_11.mp3,Something called SRT.,0,0
data/train/3_12.mp3,So SRT stands for Secure Reliable Transport.,0,0
data/train/3_13.mp3,And it's a generic protocol to send streams reliably over the internet.,0,0
data/train/3_14.mp3,"It was designed to transport MPEG transport streams with low latency, but good quality",0,0
data/train/3_15.mp3,"with encryption for security, and it's really been designed for use by broadcasters.",0,0
data/train/3_16.mp3,"So SRT, it's a protocol, but it's also a library implementing it.",0,0
data/train/3_17.mp3,"And I would say it's first and foremost a library, right?",0,0
data/train/3_18.mp3,It was created as software before actually being defined as a protocol in English.,0,0
data/train/3_19.mp3,"This library is now open source, and this is what we help bring to the community.",0,0
data/train/3_20.mp3,"It's multi-platform, Linux, Windows, macOS, Android, iOS, tvOS, all of the major platforms",0,0
data/train/3_21.mp3,are supported.,0,0
data/train/3_22.mp3,"So where do we start, right?",0,0
data/train/3_23.mp3,SRT originally was developed by a company called HiVision.,0,0
data/train/3_24.mp3,They developed it as a proprietary protocol.,0,0
data/train/3_25.mp3,It was a differentiating feature of their products compared to the competition.,0,0
data/train/3_26.mp3,And they had deployed it almost across their entire product line.,0,0
data/train/3_27.mp3,"So if you used, a couple years ago, if you use HiVision products, you could send SRT",0,0
data/train/3_28.mp3,"from one management to another, but nothing else, obviously, because it was proprietary",0,0
data/train/3_29.mp3,to their company.,0,0
data/train/3_30.mp3,"So who are the players here, right?",0,0
data/train/3_31.mp3,The first player is HiVision.,0,0
data/train/3_32.mp3,So HiVision created SRT.,0,0
data/train/3_33.mp3,"And they're a good company, they have a very solid engineering team.",0,0
data/train/3_34.mp3,"But like most software companies, they're not really into open source, right?",0,0
data/train/3_35.mp3,"They use a lot of open source, they have a lot of their products, which are actually",0,0
data/train/3_36.mp3,"running Linux inside, and have a lot of open source software inside of them.",0,0
data/train/3_37.mp3,"But everything that they did themselves, they had the very traditional mindset that it has",0,0
data/train/3_38.mp3,to bring like value.,0,0
data/train/3_39.mp3,"And you know, the open source is not going to get any value, etc, etc.",0,0
data/train/3_40.mp3,So they didn't really know how to do open source.,0,0
data/train/3_41.mp3,"On the other hand, there's us, we're Collabra, we're an open source consultancy.",0,0
data/train/3_42.mp3,"Everyone at Collabra is an open source developer, we all have open source expertise.",0,0
data/train/3_43.mp3,And we've been doing multimedia almost since the beginning of the company.,0,0
data/train/3_44.mp3,So we helped HiVision make SRT into an open source project and open source successful,0,0
data/train/3_45.mp3,project.,0,0
data/train/3_46.mp3,"And I'm going to tell you this story, right?",0,0
data/train/3_47.mp3,How we and HiVision together made that SRT into a really successful open source project.,0,0
data/train/3_48.mp3,"So before we start the project, we have to go through a couple steps, right?",0,0
data/train/3_49.mp3,"So the first step is asking ourselves, why are we doing this?",0,0
data/train/3_50.mp3,"For us, as open source people, we think this is the most self-evident thing in the world.",0,0
data/train/3_51.mp3,"If you do something, it's going to be open source.",0,0
data/train/3_52.mp3,"But for many companies, they need a justification, it's not the default yet.",0,0
data/train/3_53.mp3,"And for HiVision, the main reason they wanted to make SRT open source at first was to have",0,0
data/train/3_54.mp3,adoption.,0,0
data/train/3_55.mp3,They wanted video over the internet to work and to work reliably and to work interoperably,0,0
data/train/3_56.mp3,amongst all the devices that you can buy from different vendors.,0,0
data/train/3_57.mp3,So that their customers and all the users don't have to have devices from one vendor,0,0
data/train/3_58.mp3,that they can mix and match.,0,0
data/train/3_59.mp3,But that they would have interoperability and have good quality of transmission.,0,0
data/train/3_60.mp3,They also wanted to raise their profile.,0,0
data/train/3_61.mp3,So they wanted to raise the strength of the HiVision brand.,0,0
data/train/3_62.mp3,"And they thought that by developing a protocol and a system that everyone would use, that",0,0
data/train/3_63.mp3,would make their brand much more known.,0,0
data/train/3_64.mp3,"And they wanted to make the ecosystem more open, right?",0,0
data/train/3_65.mp3,So increase interoperability there.,0,0
data/train/3_66.mp3,One of the things that you also have to ask yourself when you develop an open source project,0,0
data/train/3_67.mp3,"and what are non-goals, right?",0,0
data/train/3_68.mp3,What's not an actual goal here?,0,0
data/train/3_69.mp3,That's almost as important as knowing what your goals are.,0,0
data/train/3_70.mp3,"And in this case, one thing that was not a goal was to increase contributions.",0,0
data/train/3_71.mp3,They felt that they had the development in the end quite solidly.,0,0
data/train/3_72.mp3,So they were not trying to get like more developers for the product.,0,0
data/train/3_73.mp3,They were really trying to get people to actually use it.,0,0
data/train/3_74.mp3,"Then we looked, what else is there?",0,0
data/train/3_75.mp3,What's the competition?,0,0
data/train/3_76.mp3,Is there any open source alternative?,0,0
data/train/3_77.mp3,And we looked and we couldn't find anything else that was really at the feature set that,0,0
data/train/3_78.mp3,the broadcast industry needed.,0,0
data/train/3_79.mp3,"There are things like WebRTC that are developed for low latency, but didn't have the kind",0,0
data/train/3_80.mp3,of quality and the simplicity that they need for broadcast users.,0,0
data/train/3_81.mp3,But there were a number of proprietary solutions down there.,0,0
data/train/3_82.mp3,"Among them, Zixin and Aspera, which come as SDKs, but their actual product is a service.",0,0
data/train/3_83.mp3,"So the SDK is free, like money free, but not open source.",0,0
data/train/3_84.mp3,"But to actually use it, you need to pay these companies for the service to transfer the",0,0
data/train/3_85.mp3,streams.,0,0
data/train/3_86.mp3,"And then there were a bunch of vendor specialized protocols, like High Vision and SRT, but a",0,0
data/train/3_87.mp3,number of their competitors had similar features and functionalities with different homemade,0,0
data/train/3_88.mp3,protocols that were all incompatible with each other.,0,0
data/train/3_89.mp3,So there was really nothing out there that was like a direct competition.,0,0
data/train/3_90.mp3,"So as I said, almost everyone in the market had a similar solution.",0,0
data/train/3_91.mp3,"And in a way, SRT and all of the others kind of work the same.",0,0
data/train/3_92.mp3,"The underlying principles are the same, it's retransmissions, maybe forward or recorrection.",0,0
data/train/3_93.mp3,There's like no great magic there.,0,0
data/train/3_94.mp3,So SRT's big differentiator that we saw was that it would be open source.,0,0
data/train/3_95.mp3,That means it's easier to integrate it.,0,0
data/train/3_96.mp3,You don't have to ask for permission.,0,0
data/train/3_97.mp3,"But also you can use it for a thing that it was not originally designed for, right?",0,0
data/train/3_98.mp3,"Since it's open source, it will be open source.",0,0
data/train/3_99.mp3,"You can actually do whatever you want with it, use it for things that original developers",0,0
data/train/3_100.mp3,"did not think of, which is often much more difficult with proprietary software.",0,0
data/train/3_101.mp3,So SRT is a network protocol.,0,0
data/train/3_102.mp3,"And when people think network protocols and open, they think open standards, right?",0,0
data/train/3_103.mp3,"So we asked ourselves, maybe there's no software, but maybe there exists a standard out there",0,0
data/train/3_104.mp3,that's open that we could just use instead of having to create a different new software.,0,0
data/train/3_105.mp3,"And for video transmission, a lot of the low latency protocols out there are based on RTP.",0,0
data/train/3_106.mp3,"It's possible to do everything that SRT does with RTP-based protocols, but there was no",0,0
data/train/3_107.mp3,grouping of RTP specifications that people could agree on and that would just give the,0,0
data/train/3_108.mp3,required functionalities for broadcast without bringing much more complexity.,0,0
data/train/3_109.mp3,"In many ways, we kind of concluded that RTP-based stacks were not there for what they needed.",0,0
data/train/3_110.mp3,"So the next question is, why publish an open source project, right?",0,0
data/train/3_111.mp3,"Why not just create a standard, get around there with other companies and say, hey, we're",0,0
data/train/3_112.mp3,just going to write a document and everyone can implement it.,0,0
data/train/3_113.mp3,There's multiple reasons for that.,0,0
data/train/3_114.mp3,And one of this is to have basically something that is usable on day one.,0,0
data/train/3_115.mp3,"And by having a shared implementation that's open source, then everyone can cooperate on",0,0
data/train/3_116.mp3,it.,0,0
data/train/3_117.mp3,"And it also means that you have good interoperability from day one, right?",0,0
data/train/3_118.mp3,"Because it's the same code, right?",0,0
data/train/3_119.mp3,So it will interoperate with itself.,0,0
data/train/3_120.mp3,"And also encourages people who want to enhance it to actually work together instead of, you",0,0
data/train/3_121.mp3,"know, if you make your own implementation, then there will be a lot of pressure from",0,0
data/train/3_122.mp3,"management to create value by having something a bit different from the center, a bit improved",0,0
data/train/3_123.mp3,"that you can go around and say, hey, you can interoperate with anyone else.",0,0
data/train/3_124.mp3,"But if you use our product on both sides, it's going to be so much better.",0,0
data/train/3_125.mp3,"In that case, we wanted everyone to really have the highest level of interoperability",0,0
data/train/3_126.mp3,to not have two grades.,0,0
data/train/3_127.mp3,Like open source grade and then the better proprietary grade.,0,0
data/train/3_128.mp3,That was kind of an empty goal here.,0,0
data/train/3_129.mp3,"Then it's a project, right?",0,0
data/train/3_130.mp3,"Open sourcing something, creating an open source project is a project in itself.",0,0
data/train/3_131.mp3,And a project needs a timeline.,0,0
data/train/3_132.mp3,Our timeline here was quite short at the beginning.,0,0
data/train/3_133.mp3,"So we were aiming to release SRT by the NAB conference in April, which is the big conference",0,0
data/train/3_134.mp3,in the broadcast industry in the U.S.,0,0
data/train/3_135.mp3,And we started this project in February.,0,0
data/train/3_136.mp3,So we had only two months.,0,0
data/train/3_137.mp3,It was quite a short timeline.,0,0
data/train/3_138.mp3,"And then we gave ourselves some time after that, right?",0,0
data/train/3_139.mp3,"We said after the initial launch, if we don't get some tractions within 18 months, then",0,0
data/train/3_140.mp3,it's not going to work too bad.,0,0
data/train/3_141.mp3,"And the second deadline was after launch, if after three years, we would like have a",0,0
data/train/3_142.mp3,"checkpoint and say, has this been a success or a failure, right?",0,0
data/train/3_143.mp3,"If it has not been a success in three years, it's probably not going to succeed.",0,0
data/train/3_144.mp3,"But one of the other things that was very important is that we said, you know, this",0,0
data/train/3_145.mp3,might not happen on day one.,0,0
data/train/3_146.mp3,You have to be able to be in it for the long run.,0,0
data/train/3_147.mp3,"If you want adoption, you have to let people know that, you know, you're in it and you're",0,0
data/train/3_148.mp3,"going to maintain it for years, right?",0,0
data/train/3_149.mp3,That it's not just going to be a thing that you throw over the wall.,0,0
data/train/3_150.mp3,"So for an open source project, one of the most important things to make it successful",0,0
data/train/3_151.mp3,is to have a governance model.,0,0
data/train/3_152.mp3,So who are the stakeholders in this governance model?,0,0
data/train/3_153.mp3,"One of the important ones are the developer, right?",0,0
data/train/3_154.mp3,"As this is software, developers are really a key constituency.",0,0
data/train/3_155.mp3,"But since this is software that's really designed for business use, enterprise use, the management",0,0
data/train/3_156.mp3,of these developers are also a key constituency.,0,0
data/train/3_157.mp3,Their bosses are very important too.,0,0
data/train/3_158.mp3,"And then we need to think also, who are the users?",0,0
data/train/3_159.mp3,"Since this is really a library, the users are actually other developers, right?",0,0
data/train/3_160.mp3,They're developers that write applications or products and that will use this library,0,0
data/train/3_161.mp3,in their product.,0,0
data/train/3_162.mp3,"And these are mostly corporate developers, right?",0,0
data/train/3_163.mp3,These are not hobbyists.,0,0
data/train/3_164.mp3,That's our key target.,0,0
data/train/3_165.mp3,"So now that we know who the main stakeholders are, we also have to think what other roles",0,0
data/train/3_166.mp3,"are in this project, right?",0,0
data/train/3_167.mp3,"To create a successful project, you need many different things.",0,0
data/train/3_168.mp3,You need people who will write documentation.,0,0
data/train/3_169.mp3,"You will need to help the users actually use it because remember, adoption was our goal.",0,0
data/train/3_170.mp3,"So we thought that helping users is a really, really important part.",0,0
data/train/3_171.mp3,"You need someone to set the direction, both the technical direction and the non-technical,",0,0
data/train/3_172.mp3,more on the business side of the project.,0,0
data/train/3_173.mp3,You need to do marketing so that people actually know about this and will adopt it.,0,0
data/train/3_174.mp3,And then you need to write code at the end.,0,0
data/train/3_175.mp3,Next question really is how much control are you ready to give up?,0,0
data/train/3_176.mp3,Open-sourcing something always means that you're going to give up some control.,0,0
data/train/3_177.mp3,And the amount of control that you give up really is balanced with what your other goals,0,0
data/train/3_178.mp3,are.,0,0
data/train/3_179.mp3,"In this case, the goal was adoption.",0,0
data/train/3_180.mp3,And so we don't need to seize too much control because we don't actually require other developers,0,0
data/train/3_181.mp3,to join or something like that.,0,0
data/train/3_182.mp3,We just want people to use it.,0,0
data/train/3_183.mp3,So we can really not have a model where we have complete external governance.,0,0
data/train/3_184.mp3,We can keep the governance very much where it was originally.,0,0
data/train/3_185.mp3,"So we need also a decision-making process, right?",0,0
data/train/3_186.mp3,"The decision-making process in different projects vary a lot, both for technical and",0,0
data/train/3_187.mp3,non-technical decisions.,0,0
data/train/3_188.mp3,It could be a board that can be elected or appointed.,0,0
data/train/3_189.mp3,"You could have one person deciding, like a dictator, a benevolent dictator, like Linus.",0,0
data/train/3_190.mp3,Or you can have something much more ad hoc.,0,0
data/train/3_191.mp3,This is not a huge project.,0,0
data/train/3_192.mp3,"So maybe if something very structured is too heavy, you might want to have something much",0,0
data/train/3_193.mp3,"more ad hoc, something in between.",0,0
data/train/3_194.mp3,"And since this is really not that big of a project, maybe you don't even need a real",0,0
data/train/3_195.mp3,"structure, right?",0,0
data/train/3_196.mp3,You might really go with something very with the flow.,0,0
data/train/3_197.mp3,"Since it's open source, and one of the things that kind of binds open source communities",0,0
data/train/3_198.mp3,"is the license, we thought that the choice of the right license was very important.",0,0
data/train/3_199.mp3,"So licenses can go, you know, from permissive licenses, MIT, BSD style, all the way to very",0,0
data/train/3_200.mp3,"strong copyleft licenses, like the GPLv3 or AGPLv3, or somewhere in between.",0,0
data/train/3_201.mp3,"One of our goals here was adoption, and one of the key places where we wanted it to be",0,0
data/train/3_202.mp3,adopted was in mobile applications.,0,0
data/train/3_203.mp3,So it was very important that whatever license we choose would not be a problem for app store,0,0
data/train/3_204.mp3,users.,0,0
data/train/3_205.mp3,But we also wanted to kind of discourage proprietary forks to have really interoperability at the,0,0
data/train/3_206.mp3,highest level.,0,0
data/train/3_207.mp3,So we tried to find something that was able to satisfy both goals.,0,0
data/train/3_208.mp3,"And for this project, we ended up choosing the MPL, because of its different clauses",0,0
data/train/3_209.mp3,that really make it easy for both sides.,0,0
data/train/3_210.mp3,"So now we've taken care of like the people aspect, and the governance aspect, now we",0,0
data/train/3_211.mp3,need to take technical steps to actually make it a good open source project.,0,0
data/train/3_212.mp3,Many projects that operate and originate from the proprietary world are often developed,0,0
data/train/3_213.mp3,"in the idea that there's only like a very small group of people who actually matter,",0,0
data/train/3_214.mp3,and that it doesn't have to follow standards that everyone else can follow.,0,0
data/train/3_215.mp3,"But it's important, if you want to open up something, that everything is clear and easy",0,0
data/train/3_216.mp3,for you as for everyone.,0,0
data/train/3_217.mp3,One of the first things that people do when they get an open source project is to try,0,0
data/train/3_218.mp3,to compile it.,0,0
data/train/3_219.mp3,"Many projects that originate from the corporate world, sometimes you just stuck at that step.",0,0
data/train/3_220.mp3,"What you really want is a build system that people already know, that is standardized",0,0
data/train/3_221.mp3,and that is high quality.,0,0
data/train/3_222.mp3,"There's many different good high quality open source build systems, things like CMake, Autotools,",0,0
data/train/3_223.mp3,"Meson, and there's a couple more.",0,0
data/train/3_224.mp3,"But I would not go with something exotic, really.",0,0
data/train/3_225.mp3,"You want something that is common for the language or platform that you're using, and",0,0
data/train/3_226.mp3,that other people will know.,0,0
data/train/3_227.mp3,"In this case, it was already CMake, so we were lucky.",0,0
data/train/3_228.mp3,"A lot of corporate projects I said have like really bad things, sometimes just random make",0,0
data/train/3_229.mp3,"files, or maybe very complex make files that rely on a complex infrastructure that tie",0,0
data/train/3_230.mp3,up with the company's internal build systems.,0,0
data/train/3_231.mp3,"And that's really, that's bad.",0,0
data/train/3_232.mp3,And what's even worse is just a bunch of shell scripts.,0,0
data/train/3_233.mp3,"So if you have that, you have to delete everything and restart with a standard one, right?",0,0
data/train/3_234.mp3,No one wants to see your internal build systems.,0,0
data/train/3_235.mp3,"Then once you have a building, then you need a place for people to cooperate.",0,0
data/train/3_236.mp3,"Cooperation requires different tools, right?",0,0
data/train/3_237.mp3,"Issue tracking, you need the source code hosting, you bring something like a wiki or somewhere",0,0
data/train/3_238.mp3,"where you can put text and documentation, build instruction, et cetera, all these kind",0,0
data/train/3_239.mp3,of things.,0,0
data/train/3_240.mp3,"These days, by far, the best way to do it is to use one of the GitHub or GitLab, right?",0,0
data/train/3_241.mp3,They've really cornered the market.,0,0
data/train/3_242.mp3,My personal preference is GitLab because it's open source.,0,0
data/train/3_243.mp3,"But in this case, we went with GitHub because that's what they were already using.",0,0
data/train/3_244.mp3,Then we need a way for people to talk to each other.,0,0
data/train/3_245.mp3,"To really support users, I feel that you want both something like a mailing list that",0,0
data/train/3_246.mp3,is slower and more longer text and a chat system like RSC or Slack.,0,0
data/train/3_247.mp3,"In this case, we have Slack channels where people can go and discuss whatever is happening",0,0
data/train/3_248.mp3,"with SRT, get help with installing it, using it, developing it, et cetera.",0,0
data/train/3_249.mp3,All the developers are there.,0,0
data/train/3_250.mp3,So it's a really good way to actually communicate.,0,0
data/train/3_251.mp3,So how did we select these tools?,0,0
data/train/3_252.mp3,One of the kind of important things is that these have to be tools that are familiar both,0,0
data/train/3_253.mp3,"to the existing developers so that they're not gonna waste too much time with them, but",0,0
data/train/3_254.mp3,also to potential contributors and potential users.,0,0
data/train/3_255.mp3,So the advantage of using very standardized tools is that everyone already knows them,0,0
data/train/3_256.mp3,and you don't waste time learning them and they don't become a bearer.,0,0
data/train/3_257.mp3,So the goal really is to reduce the barrier to entry and by using tools that are well-known,0,0
data/train/3_258.mp3,"and well-established, the project doesn't become about the build tools or about the",0,0
data/train/3_259.mp3,"collaboration tools, but really about the project itself.",0,0
data/train/3_260.mp3,The next step is that we need to market it.,0,0
data/train/3_261.mp3,We have a good project.,0,0
data/train/3_262.mp3,We have a good governance.,0,0
data/train/3_263.mp3,We have good source code.,0,0
data/train/3_264.mp3,Now we need to let everyone else know about it.,0,0
data/train/3_265.mp3,"Because this is a library, an immediate transport library, the way that people actually use",0,0
data/train/3_266.mp3,"this is often that they will use it through something else, a bigger library, either something",0,0
data/train/3_267.mp3,"like FFmpeg or GStreamer that will provide the encoding, the decoding, all of the other",0,0
data/train/3_268.mp3,steps that we need in a media pipeline.,0,0
data/train/3_269.mp3,So one of the first things that we did when we decided to make this open source was to,0,0
data/train/3_270.mp3,figure out which are the important other libraries that the issues integrate with and go upstream,0,0
data/train/3_271.mp3,and send them patches offering them the integration with LibSRT.,0,0
data/train/3_272.mp3,"Since LibSRT had been open source by that point, it was much easier for them to accept",0,0
data/train/3_273.mp3,integration patches.,0,0
data/train/3_274.mp3,So we quickly had it integrated in both FFmpeg and GStreamer.,0,0
data/train/3_275.mp3,And another thing that we ask is what do people use to test in your industry?,0,0
data/train/3_276.mp3,How do they test if a stream works?,0,0
data/train/3_277.mp3,What tool do they use?,0,0
data/train/3_278.mp3,"And they said, well, they're not special, they just use VLC like everyone else.",0,0
data/train/3_279.mp3,So one of the things that we did very early on was to submit patches to the VLC community,0,0
data/train/3_280.mp3,to add support for SRT so that you could just type SRT URL in VLC and it just works.,0,0
data/train/3_281.mp3,"And all of these communities, VLC, GStreamer, FFmpeg were very helpful and we could get",0,0
data/train/3_282.mp3,our patches integrated really quickly.,0,0
data/train/3_283.mp3,"I was surprised how easy it was, considering it's a completely new protocol.",0,0
data/train/3_284.mp3,"Very quickly, we had SRT support in all three.",0,0
data/train/3_285.mp3,"And a bit later, we also had it integrated in OBS Studio, which is a great way to create",0,0
data/train/3_286.mp3,"content, create a live stream, and send it to an SRT receiver.",0,0
data/train/3_287.mp3,"So now that we had it integrated, easy to use, sometimes as easy as just putting the",0,0
data/train/3_288.mp3,"URL in, then we had to create awareness.",0,0
data/train/3_289.mp3,So there's two parts of creating awareness.,0,0
data/train/3_290.mp3,One is for open source developers.,0,0
data/train/3_291.mp3,So part of it was to talk to developers of other relevant projects that we've already,0,0
data/train/3_292.mp3,"talked about and make them aware of SRT, what's its strengths, what's its weaknesses, what",0,0
data/train/3_293.mp3,"it's for, what it's not for, so that they can do marketing for us in a way.",0,0
data/train/3_294.mp3,"And the other important group we wanted to talk to is business people, right?",0,0
data/train/3_295.mp3,"Since we're seeing that most of the target users here are corporations, they're people",0,0
data/train/3_296.mp3,"building products, we decided to create a business alliance.",0,0
data/train/3_297.mp3,"So that's an alliance of companies that use SRT, promote SRT, build products around SRT.",0,0
data/train/3_298.mp3,And this has been a really important element of the effort.,0,0
data/train/3_299.mp3,So has it been a success?,0,0
data/train/3_300.mp3,"Well, the answer is yes, right?",0,0
data/train/3_301.mp3,"So I've done the presentation similar to this one a couple months ago, and I was seeing",0,0
data/train/3_302.mp3,there were over 250 members in the alliance.,0,0
data/train/3_303.mp3,Today I was told there's over 400.,0,0
data/train/3_304.mp3,Last time I said there were 88 companies shipping products.,0,0
data/train/3_305.mp3,"Now there's 129, if I counted correctly on the website.",0,0
data/train/3_306.mp3,"And according to GitHub, there's 67 contributors.",0,0
data/train/3_307.mp3,"So even though the goal was really not to gather contributors, we gathered contributors",0,0
data/train/3_308.mp3,"anyway because if you have something that people actually use, they will contribute",0,0
data/train/3_309.mp3,to it.,0,0
data/train/3_310.mp3,"So that was really, really successful.",0,0
data/train/3_311.mp3,I was really impressed at how quickly this picked up.,0,0
data/train/3_312.mp3,"When we announced it, within a couple of weeks, companies were lining up to join the alliance.",0,0
data/train/3_313.mp3,They really brought something to their industry which was lacking.,0,0
data/train/3_314.mp3,"There was really, like, a need for this.",0,0
data/train/3_315.mp3,And immediately we had a lot of updates.,0,0
data/train/3_316.mp3,"So it's been a really, really great success for High Vision and also for open source.",0,0
data/train/3_317.mp3,So thank you.,0,0
data/train/3_318.mp3,"If you have any questions, you can ask me on Slack of the conference.",0,0
data/train/3_319.mp3,Or you can always reach me directly.,0,0
data/train/3_320.mp3,I'm all over the internet.,0,0
data/train/3_321.mp3,So Google my name and you will find me easily.,0,0
data/train/3_322.mp3,So thank you very much and have a good afternoon.,0,0
data/train/5_0.mp3,"Hello, folks, and welcome to my OpenXR masterclass.",0,0
data/train/5_1.mp3,"The plan for the talk today is to spend a few moments introducing myself, introducing",0,0
data/train/5_2.mp3,"OpenXR, and looking at OpenXR as a standard in context, what it is and isn't.",0,0
data/train/5_3.mp3,Then we'll take a deep dive into OpenXR application structure and API usage.,0,0
data/train/5_4.mp3,And we should have time for question and answer at the end.,0,0
data/train/5_5.mp3,My name is Ryan Pavlik. I've been working in the VR realm since around 2009.,0,0
data/train/5_6.mp3,I've been involved with the OpenXR Working Group since the first official meeting in 2017.,0,0
data/train/5_7.mp3,I was elected Specification Editor for the OpenXR Working Group in 2019.,0,0
data/train/5_8.mp3,"My job currently is as a Principal Software Engineer at Collabora, where I work on the",0,0
data/train/5_9.mp3,"XR team and work as a developer on Monado, which is our OpenXR runtime.",0,0
data/train/5_10.mp3,So what is OpenXR?,0,0
data/train/5_11.mp3,"Well, OpenXR is a royalty-free open standard that provides high-performance access to augmented",0,0
data/train/5_12.mp3,"reality and virtual reality, so AR and VR, or XR collectively, platforms and devices.",0,0
data/train/5_13.mp3,"The provisional release, 0.90, was released at the Game Developers Conference 2019.",0,0
data/train/5_14.mp3,"In order to publicly show progress and seek feedback, we released version 1.0 of the specification",0,0
data/train/5_15.mp3,at SIGGRAPH in 2019.,0,0
data/train/5_16.mp3,The 1.0 release defines an interface between an engine or application and a runtime and,0,0
data/train/5_17.mp3,the required behavior of a runtime.,0,0
data/train/5_18.mp3,It does not control the interaction of a runtime and underlying devices.,0,0
data/train/5_19.mp3,I'll get to that in a moment.,0,0
data/train/5_20.mp3,"Like many Khronos standards, conformance tests are a part of the package.",0,0
data/train/5_21.mp3,Runtime conformance tests and Adopter Program are forthcoming.,0,0
data/train/5_22.mp3,That's one of the main focuses of the working group at this time.,0,0
data/train/5_23.mp3,"As I mentioned, the 1.0 specification includes the interface to the application with the",0,0
data/train/5_24.mp3,compatibility promise that comes with 1.0.,0,0
data/train/5_25.mp3,So now is the time to start building applications on top of OpenXR.,0,0
data/train/5_26.mp3,1.0.x patch releases are minor changes that fix spec bugs or add extensions.,0,0
data/train/5_27.mp3,These are typically released on Fridays.,0,0
data/train/5_28.mp3,My general rule of thumb is that if there's a specification change or extension changes,0,0
data/train/5_29.mp3,"that are in the Khronos private GitLab instance for a given week, I will typically cut a patch",0,0
data/train/5_30.mp3,release for that week.,0,0
data/train/5_31.mp3,"So the time between patch releases can be variable, but I work to get whatever the working",0,0
data/train/5_32.mp3,group has put together out as quickly as possible.,0,0
data/train/5_33.mp3,"Now if you go to the Khronos website or look around at some articles, you might see mention",0,0
data/train/5_34.mp3,"of a different diagram that has a device layer, which would allow a single runtime to connect",0,0
data/train/5_35.mp3,to multiple XR devices.,0,0
data/train/5_36.mp3,The diagram at the right is a more accurate description of the current 1.0 ecosystem.,0,0
data/train/5_37.mp3,There's no standardized interface between runtimes and XR devices.,0,0
data/train/5_38.mp3,"There's no device plugins, but runtimes may support one device or more than one.",0,0
data/train/5_39.mp3,"And importantly, the interface between an application and the runtime is standardized,",0,0
data/train/5_40.mp3,so you can use your applications across multiple runtimes and thus multiple devices.,0,0
data/train/5_41.mp3,There's no public estimated time to have the device layer as in the statement of work and,0,0
data/train/5_42.mp3,the marketing materials ready.,0,0
data/train/5_43.mp3,"As I mentioned earlier, the main focus of the working group at this point is finishing",0,0
data/train/5_44.mp3,up the conformance tests.,0,0
data/train/5_45.mp3,We're also very interested in promoting uptake and adoption of the new standard.,0,0
data/train/5_46.mp3,Khronos is a nonprofit industry consortium that brings together the major players in,0,0
data/train/5_47.mp3,technology fields to put together independent open standards.,0,0
data/train/5_48.mp3,"These standards started with OpenGL, they took over for the ARB.",0,0
data/train/5_49.mp3,The collection of standards has now expanded widely.,0,0
data/train/5_50.mp3,A commonality between many of the standards is that extensions are a key part of the design.,0,0
data/train/5_51.mp3,"There's a core API, and then there are extensions that can be added at an independent pace and",0,0
data/train/5_52.mp3,implemented by one or many vendors that allow new features or vendor-specific features to,0,0
data/train/5_53.mp3,be lit up selectively on systems that can handle them without impacting the portability,0,0
data/train/5_54.mp3,of software.,0,0
data/train/5_55.mp3,"Like all Khronos API standards, conforming runtimes that run the conformance test and",0,0
data/train/5_56.mp3,pass it and complete the other requirements of the conformance and adoption program receive,0,0
data/train/5_57.mp3,patent protection and trademark licenses per the IP framework.,0,0
data/train/5_58.mp3,Take a look at these slides.,0,0
data/train/5_59.mp3,That is linked.,0,0
data/train/5_60.mp3,"I am not a lawyer, but this framework makes Khronos the place where the big players in",0,0
data/train/5_61.mp3,"industry in these very highly competitive tech fields can safely get together, talk",0,0
data/train/5_62.mp3,"about things, and come up with standards that will work across all of them.",0,0
data/train/5_63.mp3,"Like other Khronos standards, OpenXR is royalty-free.",0,0
data/train/5_64.mp3,"In terms of relatives of OpenXR, the conventions and style and even some of the nitty-gritty",0,0
data/train/5_65.mp3,such as the tools used by the working group are strongly influenced by Vulkan.,0,0
data/train/5_66.mp3,"Vulkan is a low-level, high-performance rendering and computation API primarily for use on GPUs.",0,0
data/train/5_67.mp3,We have a mostly shared toolchain for generating specifications.,0,0
data/train/5_68.mp3,We have similar development and release practices.,0,0
data/train/5_69.mp3,"Like Vulkan, we have a loader with support for API layers, which let you hook any function",0,0
data/train/5_70.mp3,"in the API in a controlled, understandable way.",0,0
data/train/5_71.mp3,"However, just because OpenXR takes a lot of its practices from Vulkan does not mean that",0,0
data/train/5_72.mp3,it's exactly like Vulkan.,0,0
data/train/5_73.mp3,"OpenXR is rendering API neutral, so despite the fact that there are some Khronos rendering",0,0
data/train/5_74.mp3,"APIs, OpenGL, OpenGL ES, Vulkan, there are also non-Khronos rendering APIs, the Direct3D",0,0
data/train/5_75.mp3,"family, that are also supported by OpenXR.",0,0
data/train/5_76.mp3,All graphics API support are in extensions.,0,0
data/train/5_77.mp3,"All these extensions are designed to work similarly, despite the fact they're working",0,0
data/train/5_78.mp3,with different rendering APIs.,0,0
data/train/5_79.mp3,One major design difference between OpenXR and Vulkan is that OpenXR is a lower-frequency,0,0
data/train/5_80.mp3,"API, so you're not executing hundreds or thousands of OpenXR calls per frame.",0,0
data/train/5_81.mp3,You might have a handful of calls.,0,0
data/train/5_82.mp3,Eliminating all argument-checking overhead is not necessarily required for performance,0,0
data/train/5_83.mp3,in OpenXR.,0,0
data/train/5_84.mp3,"As a result, runtimes for OpenXR are required to detect nearly all invalid usage and return",0,0
data/train/5_85.mp3,an error code.,0,0
data/train/5_86.mp3,"In Vulkan, there's valid usage that is only checked by the validation layers, and if you",0,0
data/train/5_87.mp3,"pass invalid usage, there may be undefined behavior or unspecified behavior by the driver.",0,0
data/train/5_88.mp3,"Whereas in OpenXR, we have a validation layer, it provides useful information, but most invalid",0,0
data/train/5_89.mp3,"usage also has an error code that would get returned, and that is required by the specification",0,0
data/train/5_90.mp3,for the runtime to return.,0,0
data/train/5_91.mp3,"Of course, there is some risk of undefined behavior because it's a C API, but this minimal",0,0
data/train/5_92.mp3,risk can be reduced by a language projection or wrapper that makes it more difficult to,0,0
data/train/5_93.mp3,misuse pointers in a way that would break things.,0,0
data/train/5_94.mp3,"Additionally, OpenXR is a much smaller spec.",0,0
data/train/5_95.mp3,It's only about 300 pages in PDF format.,0,0
data/train/5_96.mp3,We've also learned some lessons from Vulkan.,0,0
data/train/5_97.mp3,We've talked with the folks on the Vulkan working group and asked them what lessons,0,0
data/train/5_98.mp3,they wish they had learned.,0,0
data/train/5_99.mp3,"In our case, one of those is that the loader, which is responsible for finding the runtime",0,0
data/train/5_100.mp3,"and getting function pointers, our loader ships with applications and not the system",0,0
data/train/5_101.mp3,or the driver on Windows.,0,0
data/train/5_102.mp3,"On Linux, it's tentatively system-wide because there are distribution-specific ways of controlling",0,0
data/train/5_103.mp3,ownership of the loader.,0,0
data/train/5_104.mp3,"As of recording this on April 14th, here's the current availability of OpenXR runtimes.",0,0
data/train/5_105.mp3,The Microsoft OpenXR runtime is available for both Windows MR HMDs as well as the HoloLens,0,0
data/train/5_106.mp3,2.,0,0
data/train/5_107.mp3,"Additionally, the Windows MR runtime does work with the Windows MR simulator mode, so",0,0
data/train/5_108.mp3,you don't need hardware in order to run that OpenXR runtime.,0,0
data/train/5_109.mp3,"Oculus has a runtime that they're prototyping in the public test channel, and an SDK for",0,0
data/train/5_110.mp3,"that desktop runtime is forthcoming, per their announcement at roughly what would have been",0,0
data/train/5_111.mp3,GDC time 2020.,0,0
data/train/5_112.mp3,"And recently, the Oculus Mobile OpenXR SDK, so that would be for Quest primarily, is publicly",0,0
data/train/5_113.mp3,available in a preview form.,0,0
data/train/5_114.mp3,"If you are using Linux, you can use the Monado runtime, which is an open-source project led",0,0
data/train/5_115.mp3,by my team at Collabra.,0,0
data/train/5_116.mp3,It works on multiple different devices and is in active development.,0,0
data/train/5_117.mp3,"Note that because conformance tests are not yet finalized and published, and therefore",0,0
data/train/5_118.mp3,"there are no conformance results, these are all technically preview implementations, but",0,0
data/train/5_119.mp3,these should be useful in order to get you started developing with OpenXR.,0,0
data/train/5_120.mp3,This is the structure of an OpenXR app.,0,0
data/train/5_121.mp3,We'll go into all of these in more detail.,0,0
data/train/5_122.mp3,You first get started by configuring and creating your instance.,0,0
data/train/5_123.mp3,"Next, you find out where and how to run.",0,0
data/train/5_124.mp3,This involves looking up a system ID atom and using the view configuration type enum.,0,0
data/train/5_125.mp3,"Then, you set up your interaction.",0,0
data/train/5_126.mp3,"In OpenXR, this is done using action sets and actions.",0,0
data/train/5_127.mp3,"Finally, the last setup step is preparing the immersive experience by creating your",0,0
data/train/5_128.mp3,"session, attaching action sets, creating reference and action spaces, and creating your swap",0,0
data/train/5_129.mp3,chain.,0,0
data/train/5_130.mp3,"Then, the frame loop handling input and events is the body of your application.",0,0
data/train/5_131.mp3,There are a number of object or handle types in OpenXR that are important.,0,0
data/train/5_132.mp3,These are the main handle types and shows as well which handle types are their parent.,0,0
data/train/5_133.mp3,"In OpenXR, destroying a handle parent also destroys that handle.",0,0
data/train/5_134.mp3,"If you destroy a session, that also destroys those associated spaces and swap chains.",0,0
data/train/5_135.mp3,"If you destroy the instance, that destroys all of these handles since they're all derived",0,0
data/train/5_136.mp3,from the instance.,0,0
data/train/5_137.mp3,"In addition to handles, there are two additional types known as atoms.",0,0
data/train/5_138.mp3,They're not objects.,0,0
data/train/5_139.mp3,They don't have an explicit lifetime.,0,0
data/train/5_140.mp3,They're just coded numbers that represent some fixed thing in the runtime.,0,0
data/train/5_141.mp3,The one you'll work with the most is a path.,0,0
data/train/5_142.mp3,An XR path is a number that corresponds within that instance to a string representing a semantic,0,0
data/train/5_143.mp3,path.,0,0
data/train/5_144.mp3,"When you create an instance, you first need to choose which extensions you want, very",0,0
data/train/5_145.mp3,similar to how Vulkan works.,0,0
data/train/5_146.mp3,"In order to make an OpenXR application, you need at least one extension enabled, and that's",0,0
data/train/5_147.mp3,a graphics binding extension.,0,0
data/train/5_148.mp3,You can determine which extensions are all available on the system that you're using,0,0
data/train/5_149.mp3,by using XR enumerate instance extension properties.,0,0
data/train/5_150.mp3,"However, if you don't have any optional extension usage and you can either run with the extensions",0,0
data/train/5_151.mp3,"you know how to use or not run at all, you can just proceed to create the instance and",0,0
data/train/5_152.mp3,ask for the extensions you need.,0,0
data/train/5_153.mp3,"There's also a facility for API layers, as I mentioned earlier.",0,0
data/train/5_154.mp3,These can be configured outside of your application through environment variables or similar to,0,0
data/train/5_155.mp3,make the loader automatically load them.,0,0
data/train/5_156.mp3,"However, if your application wants to load them, you can enumerate which ones are available",0,0
data/train/5_157.mp3,before you create an instance.,0,0
data/train/5_158.mp3,"Similar to Vulkan, there's an application info struct that you should fill out with",0,0
data/train/5_159.mp3,your application name and engine name and version so that runtimes can identify your,0,0
data/train/5_160.mp3,application.,0,0
data/train/5_161.mp3,"Then finally, XRCreateInstance takes that information and hands you an instance handle.",0,0
data/train/5_162.mp3,You can use XRGetSystem to find your desired form factor.,0,0
data/train/5_163.mp3,"OpenXR 1.0 natively supports without extensions stereo head-mounted displays, as well as handheld",0,0
data/train/5_164.mp3,mono magic window style augmented reality.,0,0
data/train/5_165.mp3,"But not all runtimes will support both of these form factors of devices, so part of",0,0
data/train/5_166.mp3,the startup process is asking if there is a system of the form factor you wish available.,0,0
data/train/5_167.mp3,"The form factor that you ask for might be available, in which case you'd get a system",0,0
data/train/5_168.mp3,ID.,0,0
data/train/5_169.mp3,It might be never available if the device that you're using can't do the form factor,0,0
data/train/5_170.mp3,"that you ask for, or it might be temporarily unavailable if it's perhaps not plugged in",0,0
data/train/5_171.mp3,"or if it needs to transition to a different mode in order to be used in that way, if you",0,0
data/train/5_172.mp3,have a device that can be used in multiple fashions.,0,0
data/train/5_173.mp3,"Once you have a system, then you set up your view configuration.",0,0
data/train/5_174.mp3,"This is where mono, stereo, or even more views come in.",0,0
data/train/5_175.mp3,"If you support more than one view configuration, you can use XREnumerateViewConfigurations",0,0
data/train/5_176.mp3,to find out which ones the system you've chosen supports to make your determination of which,0,0
data/train/5_177.mp3,one you're going to render using.,0,0
data/train/5_178.mp3,"No matter which view configuration you use, you will then call EnumerateViewConfigurationViews",0,0
data/train/5_179.mp3,to get the correct number of views for your view configuration.,0,0
data/train/5_180.mp3,Each view configuration has a fixed number of views.,0,0
data/train/5_181.mp3,Mono has one.,0,0
data/train/5_182.mp3,Stereo has two.,0,0
data/train/5_183.mp3,"If you're using one of the vendor extensions, the XRVarioQuadViews, that has four, and so",0,0
data/train/5_184.mp3,on.,0,0
data/train/5_185.mp3,These are well known in the specification.,0,0
data/train/5_186.mp3,"Now that you have an instance, you can get your interaction set up, your action set and",0,0
data/train/5_187.mp3,actions.,0,0
data/train/5_188.mp3,"Action sets are a group of related actions for a context, environment, and so on.",0,0
data/train/5_189.mp3,"You might have an action set called Menu, or one called Gameplay, one called Driving.",0,0
data/train/5_190.mp3,You can have one or more action sets active at a single time.,0,0
data/train/5_191.mp3,So you don't need to have a GameWithCar action set.,0,0
data/train/5_192.mp3,You can just have Game and then the additional actions in Car.,0,0
data/train/5_193.mp3,An action is a semantic or meaningful bit of interaction.,0,0
data/train/5_194.mp3,It's something that you do.,0,0
data/train/5_195.mp3,OpenXR focuses on the actions that a user takes in your application instead of on the,0,0
data/train/5_196.mp3,buttons and controllers that are used to perform those actions.,0,0
data/train/5_197.mp3,This is an important part of the hardware independence.,0,0
data/train/5_198.mp3,There are several different types of actions.,0,0
data/train/5_199.mp3,Action is essentially a button action.,0,0
data/train/5_200.mp3,It has either on or off.,0,0
data/train/5_201.mp3,There are float actions.,0,0
data/train/5_202.mp3,Floats are things like an analog trigger.,0,0
data/train/5_203.mp3,"Vector2 are two-dimensional floats, things like a thumbstick or trackpad.",0,0
data/train/5_204.mp3,Pose is a special kind of action.,0,0
data/train/5_205.mp3,That's a tracked object.,0,0
data/train/5_206.mp3,So frequently these represent hands.,0,0
data/train/5_207.mp3,"And then haptic actions are an output action, allowing you to provide rumble feedback to",0,0
data/train/5_208.mp3,the user.,0,0
data/train/5_209.mp3,All these actions are created using XRCreateAction.,0,0
data/train/5_210.mp3,"Once you've established which logical actions a user of your application will make, you'd",0,0
data/train/5_211.mp3,like to customize how they actually perform those actions for the hardware that you're,0,0
data/train/5_212.mp3,used to and that you're testing on.,0,0
data/train/5_213.mp3,This is where interaction profiles and suggested bindings come in.,0,0
data/train/5_214.mp3,"For each controller type that you've tested, there will be an interaction profile.",0,0
data/train/5_215.mp3,"These are listed in the specification, and they cover a number of well-known devices.",0,0
data/train/5_216.mp3,Additional interaction profiles will be added through extensions.,0,0
data/train/5_217.mp3,"Then for each interaction profile, you submit pairs of actions and suggested bindings.",0,0
data/train/5_218.mp3,These are the logical part of the controller that you'd like to use to drive that action.,0,0
data/train/5_219.mp3,You can suggest multiple bindings per action in a call.,0,0
data/train/5_220.mp3,"For instance, both your left and right hands and your left and right controller could both",0,0
data/train/5_221.mp3,trigger action GrabObject.,0,0
data/train/5_222.mp3,"The binding path that you'd like to suggest is an XRPathAtom, which represents a string",0,0
data/train/5_223.mp3,like UserHandWriteInputSelectClick.,0,0
data/train/5_224.mp3,These are hierarchical strings.,0,0
data/train/5_225.mp3,Here you can see that we are referring to the Select button on what's being held in,0,0
data/train/5_226.mp3,the right hand and the click of that Select button.,0,0
data/train/5_227.mp3,"For the last two components, there are naming conventions and standardized names that are",0,0
data/train/5_228.mp3,detailed in the specification.,0,0
data/train/5_229.mp3,All these paths are listed in the interaction profile definitions in the specification.,0,0
data/train/5_230.mp3,"To make this a bit more concrete, I've gone through the sample HelloXR application that's",0,0
data/train/5_231.mp3,in the OpenXR SDK source and compiled the actions and bindings that are used there.,0,0
data/train/5_232.mp3,The InitializeActionsMember function is where these get set up if you want to look at the,0,0
data/train/5_233.mp3,source code on your own later.,0,0
data/train/5_234.mp3,All these actions are in a single action set because the application is very simple.,0,0
data/train/5_235.mp3,And all of these actions are specified for both the left and right hands.,0,0
data/train/5_236.mp3,This uses the concept of subaction paths.,0,0
data/train/5_237.mp3,"You can ignore this for the most part until later, but as soon as you want to be able",0,0
data/train/5_238.mp3,"to perform an action with two hands but know which one hand actually did it, that's how",0,0
data/train/5_239.mp3,you use subaction paths.,0,0
data/train/5_240.mp3,"It's similar to the SteamVR input concept of RestrictToDevice, if you're familiar with",0,0
data/train/5_241.mp3,that at all.,0,0
data/train/5_242.mp3,So the four actions represent a variety of action types.,0,0
data/train/5_243.mp3,"We have GrabObject, HandPose, QuitSession, and VibrateHand.",0,0
data/train/5_244.mp3,"So after creating that action set and those four actions, it's time to suggest bindings.",0,0
data/train/5_245.mp3,There are a number of calls in HelloXR to suggest bindings.,0,0
data/train/5_246.mp3,I've picked a few of them for three different interaction profiles to illustrate some points.,0,0
data/train/5_247.mp3,This first one uses the interaction profile KHRSimpleController.,0,0
data/train/5_248.mp3,This is not corresponding to any particular specific piece of hardware.,0,0
data/train/5_249.mp3,It's a generic lowest common denominator sort of device that can be mapped to a wide variety,0,0
data/train/5_250.mp3,of hardware.,0,0
data/train/5_251.mp3,There are a few things to notice here.,0,0
data/train/5_252.mp3,"Overall, as you'll see as a pattern, the suggested binding path for the interaction profile,",0,0
data/train/5_253.mp3,"if it's under UserHandLeft, then it goes to the subaction path of UserHandLeft, and similarly",0,0
data/train/5_254.mp3,for UserHandRight.,0,0
data/train/5_255.mp3,One point about the SimpleController is that its select input is Boolean.,0,0
data/train/5_256.mp3,It only has on or off.,0,0
data/train/5_257.mp3,It has a click.,0,0
data/train/5_258.mp3,"So we're binding GrabObject, which is a float input, to UserHandLeftInputSelectClick, which",0,0
data/train/5_259.mp3,is Boolean.,0,0
data/train/5_260.mp3,This is fine.,0,0
data/train/5_261.mp3,The runtime will automatically convert that Boolean value to a float 1 or 0.,0,0
data/train/5_262.mp3,There are conversion rules that are described in the specification for these common SimpleCases.,0,0
data/train/5_263.mp3,The second example is the HTC Vive controller.,0,0
data/train/5_264.mp3,Here you can see that we've bound the GrabObject action to a different path.,0,0
data/train/5_265.mp3,"That's because the Vive controller has those grip or squeeze buttons on the side, rather",0,0
data/train/5_266.mp3,than a button simply labeled Select.,0,0
data/train/5_267.mp3,"So the squeeze button, which is still a Boolean, like the SimpleController, is now being suggested",0,0
data/train/5_268.mp3,as our binding for GrabObject.,0,0
data/train/5_269.mp3,"Just as before, the Boolean will be converted to a float.",0,0
data/train/5_270.mp3,And the last example of the suggested bindings is the Oculus Touch controller.,0,0
data/train/5_271.mp3,Now there's a couple things here that are different.,0,0
data/train/5_272.mp3,The Oculus Touch controller has a float squeeze input.,0,0
data/train/5_273.mp3,It can say a floating value between 0 and 1 of how much you're squeezing.,0,0
data/train/5_274.mp3,"So here, the GrabObject action will get something that's not just limited to 0 or 1, but in",0,0
data/train/5_275.mp3,that entire range.,0,0
data/train/5_276.mp3,"Additionally, only the left controller has a menu button.",0,0
data/train/5_277.mp3,"So in this case, we're only suggesting a binding for the left hand for Quit Session, which",0,0
data/train/5_278.mp3,uses the menu button.,0,0
data/train/5_279.mp3,"User hand right, we're not suggesting a binding, and that's OK.",0,0
data/train/5_280.mp3,The next major handle to create is your session.,0,0
data/train/5_281.mp3,You'll first want to get your graphics binding ready.,0,0
data/train/5_282.mp3,"So depending on which graphics API you use, there will be a Get Something Graphics Requirements",0,0
data/train/5_283.mp3,call that's specified by that extension.,0,0
data/train/5_284.mp3,You need to call that before calling Create Session.,0,0
data/train/5_285.mp3,"This provides useful information, how you configure your rendering in order to get the",0,0
data/train/5_286.mp3,rendered content onto the display.,0,0
data/train/5_287.mp3,You then create a graphics binding struct.,0,0
data/train/5_288.mp3,"These are also specified by the graphics binding extensions, and they're all chained",0,0
data/train/5_289.mp3,on via the next pointer on XR Session Create Info.,0,0
data/train/5_290.mp3,"I haven't talked about the next pointer too much, but similar to Vulkan, OpenXR structures",0,0
data/train/5_291.mp3,contain a type field as well as a void pointer that allows you to chain additional structures,0,0
data/train/5_292.mp3,on in a regular way.,0,0
data/train/5_293.mp3,"This is mostly used for extension functionality, but there are a few cases in the core specification",0,0
data/train/5_294.mp3,"where the next pointer is also used, and this is one of them.",0,0
data/train/5_295.mp3,"When you go to create a session with XR Create Session, that requires your system ID from",0,0
data/train/5_296.mp3,earlier.,0,0
data/train/5_297.mp3,"And once you have that session, you then need to attach your action sets to it to commit",0,0
data/train/5_298.mp3,"to the runtime saying, I'm all done setting up my actions and action sets and suggested",0,0
data/train/5_299.mp3,bindings.,0,0
data/train/5_300.mp3,"I'm going to use them with this session, and I'm not going to change them anymore.",0,0
data/train/5_301.mp3,This does make your actions and action sets immutable.,0,0
data/train/5_302.mp3,"You can't modify them after this point, and there's a special error code that you'd get",0,0
data/train/5_303.mp3,if you tried to do that.,0,0
data/train/5_304.mp3,"If you happen to be writing an editor for a game engine, the solution for doing this",0,0
data/train/5_305.mp3,"if you are editing your actions, is that each time you need to tear down the session, the",0,0
data/train/5_306.mp3,"actions and action sets, and then recreate them in order to modify them.",0,0
data/train/5_307.mp3,"This seems a bit like a pain, but there's an important reason for it.",0,0
data/train/5_308.mp3,"There's a reason that the action setup is done all up front, and it has to do with rebinding.",0,0
data/train/5_309.mp3,We want to be able to provide the user with the maximum ability to configure how they're,0,0
data/train/5_310.mp3,interacting with their application right away.,0,0
data/train/5_311.mp3,"So when they launch your application, and it turns out there's no suggested bindings",0,0
data/train/5_312.mp3,"for the hardware that they have, the runtime can pop up a UI that provides them the ability",0,0
data/train/5_313.mp3,to map your specified actions to the hardware that they have available.,0,0
data/train/5_314.mp3,This happens behind the scenes and goes unnoticed by your application.,0,0
data/train/5_315.mp3,"If you were able to add actions and action sets later on during execution, not up front,",0,0
data/train/5_316.mp3,it would then interrupt the flow of your application if rebinding needed to be done a second time.,0,0
data/train/5_317.mp3,"Additionally, if a runtime supports sharing bindings between users, you'd be able to compose",0,0
data/train/5_318.mp3,a binding that supports all actions only if action setup is all done at once.,0,0
data/train/5_319.mp3,"Otherwise, if there's an action or action set that's only used in the last scene or two of your game,",0,0
data/train/5_320.mp3,"for instance, then a community-created and shared binding might very well be incomplete",0,0
data/train/5_321.mp3,"if that scene was not yet reached or was on a path that wasn't reached,",0,0
data/train/5_322.mp3,making it less useful in general.,0,0
data/train/5_323.mp3,"To interact with tracked objects, you use XR space handles.",0,0
data/train/5_324.mp3,There are multiple ways to get these handles.,0,0
data/train/5_325.mp3,Several spaces are known as reference spaces.,0,0
data/train/5_326.mp3,You access these using your XR session and an enum.,0,0
data/train/5_327.mp3,"Three of these are local space, view space, and stage space.",0,0
data/train/5_328.mp3,There are additional ones added in extensions.,0,0
data/train/5_329.mp3,Stage space can be considered a bounded standing area play environment.,0,0
data/train/5_330.mp3,Local space is seated.,0,0
data/train/5_331.mp3,And view space is essentially head space if you need to play something that's headlocked.,0,0
data/train/5_332.mp3,"To get an XR space from these enums, you use XR create reference space.",0,0
data/train/5_333.mp3,Another kind of space is an action space.,0,0
data/train/5_334.mp3,"To create these, you use your XR session and a pose action.",0,0
data/train/5_335.mp3,"The result is an XR space just the same as with create reference space,",0,0
data/train/5_336.mp3,so they are both examined the same way.,0,0
data/train/5_337.mp3,"For both of these types of spaces, session is the parent handle.",0,0
data/train/5_338.mp3,"Additionally, for both of these space types,",0,0
data/train/5_339.mp3,you can specify an additional fixed transform at handle creation time.,0,0
data/train/5_340.mp3,XR locate space is the call used to find the transform from one space to another.,0,0
data/train/5_341.mp3,Note that you never just find the pose of a space.,0,0
data/train/5_342.mp3,You always find a space with respect to another space.,0,0
data/train/5_343.mp3,You don't track your hand.,0,0
data/train/5_344.mp3,You track your hand relative to local space or stage space.,0,0
data/train/5_345.mp3,"To render, you'll need to create a swap chain.",0,0
data/train/5_346.mp3,You'll obtain your graphics API specific formats through XR enumerate swap chain formats.,0,0
data/train/5_347.mp3,You'll call XR create swap chain one or more times.,0,0
data/train/5_348.mp3,"Once you've created a swap chain,",0,0
data/train/5_349.mp3,you'll access the graphics API specific handles or references,0,0
data/train/5_350.mp3,to the swap chain images using XR enumerate swap chain images.,0,0
data/train/5_351.mp3,This is a slightly unusual call.,0,0
data/train/5_352.mp3,You'll pass an array of extension defined structures.,0,0
data/train/5_353.mp3,You'll want to save the information that comes back from this call to use every frame.,0,0
data/train/5_354.mp3,It specifies in a graphics API specific way where to render your image to.,0,0
data/train/5_355.mp3,"Within the frame loop, there are three functions with frame in the name",0,0
data/train/5_356.mp3,that control the lifecycle of a frame.,0,0
data/train/5_357.mp3,XR wait frame is a scheduling call.,0,0
data/train/5_358.mp3,It blocks until the runtime determines you can proceed with head pose dependent simulation,0,0
data/train/5_359.mp3,and rendering.,0,0
data/train/5_360.mp3,XR begin frame is executed by your application to mark the start of rendering,0,0
data/train/5_361.mp3,or GPU usage for that frame.,0,0
data/train/5_362.mp3,And XR end frame submits the frame for display.,0,0
data/train/5_363.mp3,"XR begin frame and end frame calls must be ordered as if they were single threaded,",0,0
data/train/5_364.mp3,although they may be called from any thread.,0,0
data/train/5_365.mp3,You'll populate the XR end frame info display time using the output of XR wait frame.,0,0
data/train/5_366.mp3,"XR wait frame tells you when the next predicted display time is,",0,0
data/train/5_367.mp3,and you'll use this in all your calculations and all your space locations.,0,0
data/train/5_368.mp3,"If your application is using pipelined or multi-threaded rendering,",0,0
data/train/5_369.mp3,there are some more detailed timing requirements that are important to know.,0,0
data/train/5_370.mp3,"You can have at most one simultaneous XR wait frame call being executed at a time,",0,0
data/train/5_371.mp3,and each XR wait frame must eventually be matched with a unique XR begin frame.,0,0
data/train/5_372.mp3,They come in pairs.,0,0
data/train/5_373.mp3,"Each wait frame has a begin frame, and every begin frame has a wait frame.",0,0
data/train/5_374.mp3,"Additionally, any XR wait frame call will block in the runtime",0,0
data/train/5_375.mp3,until the previous frame's XR begin frame has been made.,0,0
data/train/5_376.mp3,"Between begin and end frame, once it's time to actually render,",0,0
data/train/5_377.mp3,you'll need to use the swap chain that you created earlier.,0,0
data/train/5_378.mp3,"XR acquire swap chain image does not give you permission to write to the image,",0,0
data/train/5_379.mp3,but it does get the index of the swap chain.,0,0
data/train/5_380.mp3,XR wait swap chain image must be called before writing to that image.,0,0
data/train/5_381.mp3,It's typically called immediately after acquire.,0,0
data/train/5_382.mp3,"However, you may, as an optimization,",0,0
data/train/5_383.mp3,look up or create your command buffers using just the index from acquire swap chain image,0,0
data/train/5_384.mp3,before blocking on the compositor releasing the image for writing to your application.,0,0
data/train/5_385.mp3,XR release swap chain image is what you call when you're all done rendering,0,0
data/train/5_386.mp3,right before calling XR end frame.,0,0
data/train/5_387.mp3,XR end frame implicitly uses the most recently released swap chain image,0,0
data/train/5_388.mp3,for displaying to the device.,0,0
data/train/5_389.mp3,"When you're doing your rendering, you need to render for the predicted display time",0,0
data/train/5_390.mp3,and for the pose that the head is anticipated to be at at that time.,0,0
data/train/5_391.mp3,XR locate views is how you look up that information.,0,0
data/train/5_392.mp3,It works very similarly to XR locate space.,0,0
data/train/5_393.mp3,"Now that we have an application that can render,",0,0
data/train/5_394.mp3,we probably should look into getting input to make it interactive.,0,0
data/train/5_395.mp3,XR sync actions should be called once per simulation frame in your application.,0,0
data/train/5_396.mp3,It specifies which action sets should be active for that frame,0,0
data/train/5_397.mp3,and updates all non-pose input data in those active action sets.,0,0
data/train/5_398.mp3,"After you sync actions, then get the data.",0,0
data/train/5_399.mp3,Any action set that is attached but not specified in the most recent XR sync actions call,0,0
data/train/5_400.mp3,will have the actions return not active.,0,0
data/train/5_401.mp3,Actions additionally might not get data if your session is not focused for privacy and security purposes.,0,0
data/train/5_402.mp3,"To get action data from actions, you'll use XR get action state calls.",0,0
data/train/5_403.mp3,There's one for each type of action.,0,0
data/train/5_404.mp3,Pose actions are a little bit different.,0,0
data/train/5_405.mp3,"They continue updating all the time, not just at XR sync actions time,",0,0
data/train/5_406.mp3,because tracking is latency and time sensitive.,0,0
data/train/5_407.mp3,"To get the data from a pose action, you'll usually just create an XR space for it",0,0
data/train/5_408.mp3,and then use XR locate space.,0,0
data/train/5_409.mp3,"Only the active, inactive state of a pose action is controlled by XR sync actions.",0,0
data/train/5_410.mp3,"Typically, you'll process most of your input either before you call XR wait frame and XR begin frame,",0,0
data/train/5_411.mp3,or after XR end frame.,0,0
data/train/5_412.mp3,There is a per instance event queue that contains a range of events.,0,0
data/train/5_413.mp3,"This queue must be polled on a regular basis, typically once a simulation frame is a good idea.",0,0
data/train/5_414.mp3,XR poll events requires an instance.,0,0
data/train/5_415.mp3,"However, many events only happen during a session.",0,0
data/train/5_416.mp3,"These events can describe changes to the active interaction profile,",0,0
data/train/5_417.mp3,"continuity of reference spaces in tracking, changes in the session state, and other things.",0,0
data/train/5_418.mp3,"You provide an XR event data buffer to XR poll events,",0,0
data/train/5_419.mp3,and the runtime populates it with an event of some other type.,0,0
data/train/5_420.mp3,"You have to make sure you set the type to XR type event data buffer,",0,0
data/train/5_421.mp3,"and then when you get it back from that call, check that type value and reinterpret that structure accordingly.",0,0
data/train/5_422.mp3,Thanks for your time.,0,0
data/train/5_423.mp3,Hopefully you found this introduction to OpenXR and exploration of the structure of an OpenXR application to be helpful.,0,0
data/train/5_424.mp3,I've put a number of resources on this slide that you can follow for additional information.,0,0
data/train/5_425.mp3,"If I'm not available for questions at the time that you're watching this,",0,0
data/train/5_426.mp3,please feel free to drop by one of the community locations for the OpenXR group and leave a note there with your question.,0,0
data/train/5_427.mp3,I or someone else in the community will be happy to respond.,0,0
data/train/5_428.mp3,Thank you.,0,0
data/train/7_0.mp3,"Hi, thanks for joining us at the Automotive Linux Summit 2021. We're here to talk today",0,0
data/train/7_1.mp3,"about how to build out sustainable platforms, and in particular, how we can drive a wider",0,0
data/train/7_2.mp3,"adoption of testing, QA, and CI throughout upstream open source projects, so we can really",0,0
data/train/7_3.mp3,drive the adoption of open source and get what vendors actually distribute to users,0,0
data/train/7_4.mp3,"to be much, much closer to the actual projects themselves.",0,0
data/train/7_5.mp3,"So my name's Daniel Stone, I'm the graphics lead at Collabra, covering projects such as",0,0
data/train/7_6.mp3,"Mesa, Wayland, Western, and the FreeDesktop.org ecosystem.",0,0
data/train/7_7.mp3,"Hello everyone, my name is Guillaume Tucker, and I also work at Collabra. I've been leading",0,0
data/train/7_8.mp3,"the KernelCI project in general, and also I've been working on it as part of Collabra",0,0
data/train/7_9.mp3,"for the past three, four years. I'm currently also chair of the advisory board for the",0,0
data/train/7_10.mp3,Linux Foundation project.,0,0
data/train/7_11.mp3,"So today we're going to cover a few areas. In particular, we're going to start with the",0,0
data/train/7_12.mp3,"existing ecosystem that we have with upstream open source projects, which projects are interesting",0,0
data/train/7_13.mp3,to us. The challenges we've faced as we've driven heavily the adoption of these more,0,0
data/train/7_14.mp3,rigorous testing and CI and QA procedures throughout them. The results of those efforts,0,0
data/train/7_15.mp3,"as well, you know, the testing frameworks we've been able to build out in each project,",0,0
data/train/7_16.mp3,"the results we've had from those, and what we've learned along the way really in terms",0,0
data/train/7_17.mp3,"of things like process, adoption, socializing, and then finally how we can build out from",0,0
data/train/7_18.mp3,the slightly more siloed testing frameworks that we have at the moment to having something,0,0
data/train/7_19.mp3,a little bit more coherent and shared between all the different projects.,0,0
data/train/7_20.mp3,The main challenge we have is the sort of disconnect between the two different models.,0,0
data/train/7_21.mp3,"In a traditional product development model, the products are really worked on in almost",0,0
data/train/7_22.mp3,a waterfall fashion where they're fully tested at each step along the way. Everyone has a clear,0,0
data/train/7_23.mp3,"idea of what the goals and the metrics and the acceptance criteria are, and there are various",0,0
data/train/7_24.mp3,"sort of gating processes along that. If you compare to traditional open source projects,",0,0
data/train/7_25.mp3,it's been very much a commons project with not necessarily a shared vision or a shared,0,0
data/train/7_26.mp3,set of priorities or even the ability to break those kind of deadlocks and the disagreements and,0,0
data/train/7_27.mp3,try and enforce some kind of priorities. Testing of upstream work often fell into a bit of a gap,0,0
data/train/7_28.mp3,"where it wasn't really native to the projects themselves, and the users didn't necessarily see",0,0
data/train/7_29.mp3,the need for upstream testing because they already had all of their own testing on downstream,0,0
data/train/7_30.mp3,"branches and what they shipped and their own QA departments that they would almost take over,",0,0
data/train/7_31.mp3,but with all of the cost falling on the vendor and none of the benefit being delivered to all,0,0
data/train/7_32.mp3,of the other users of the upstream projects. But we do believe it's possible to bridge this gap.,0,0
data/train/7_33.mp3,Today we'll be talking about a lot of the work we've done throughout various projects to,0,0
data/train/7_34.mp3,bring this more native testing and CI and just take it into the process for all of these projects.,0,0
data/train/7_35.mp3,"So the projects we've been working with include the Linux kernel itself,",0,0
data/train/7_36.mp3,"Mesa, which is the de facto standard for open source graphics drivers and acceleration,",0,0
data/train/7_37.mp3,"Waveland and Western, the again de facto standard window and display system under Linux,",0,0
data/train/7_38.mp3,and GStreamer for multimedia support as well.,0,0
data/train/7_39.mp3,"So starting with a Linux kernel, we'll go through how the kernel development workflow typically",0,0
data/train/7_40.mp3,"works. So first of all you have developers sending patches via mailing lists, then maintainers apply",0,0
data/train/7_41.mp3,"patches after some review on their own branches, on their own Git trees, and then some of them",0,0
data/train/7_42.mp3,"might have a branch that they share to be tested with Linux Next or with various CI systems,",0,0
data/train/7_43.mp3,and eventually the maintainer branch will get merged into another maintainer branch until it,0,0
data/train/7_44.mp3,"gets merged into Linux Torvastream, which can take up to three months. There's a merge window",0,0
data/train/7_45.mp3,"every three months for merging all the new changes. So in the workflow I just explained,",0,0
data/train/7_46.mp3,"I didn't mention testing anywhere, so that depends on how each subsystem actually functions.",0,0
data/train/7_47.mp3,"Some subsystems will do all their testing directly when people submit some changes,",0,0
data/train/7_48.mp3,"other subsystems rely on the maintainers to run their own tests, so they would have their own",0,0
data/train/7_49.mp3,"manual workflows, or maybe some automated workflows, but none of that is really systemic.",0,0
data/train/7_50.mp3,So you have a collection of test systems available that will test a mainline kernel and a variety of,0,0
data/train/7_51.mp3,"of Git branches available. So one of them is KernelCI, which has now become a project of",0,0
data/train/7_52.mp3,"the Linux Foundation, as it has kind of been chosen as the main project for testing the",0,0
data/train/7_53.mp3,"upstream Linux kernel. So it's focusing on what we call post-merge testing, so it's after a patch",0,0
data/train/7_54.mp3,"has been applied to a branch. So it's monitoring a number of Git branches, and as soon as it detects",0,0
data/train/7_55.mp3,"a new revision, it will test it, build it, and send some reports. We can see that gradually more",0,0
data/train/7_56.mp3,and more subsystems and maintainers are starting to engage with KernelCI and rely on the results,0,0
data/train/7_57.mp3,"that it's producing. On this slide you can see a diagram, like a big picture diagram, of how",0,0
data/train/7_58.mp3,currently test-driven kernel development kind of looks like. So you have a crowd of,0,0
data/train/7_59.mp3,"people versus like the ecosystem, you have, well, different types of developers, you have OEMs, you",0,0
data/train/7_60.mp3,"have also maintainers, so they all contribute to the kernel source code itself by Git branches.",0,0
data/train/7_61.mp3,"They also contribute to some tests, so LTP, KSL, TestK unit are the main examples for upstream",0,0
data/train/7_62.mp3,"oriented test suites. And then KernelCI will build some kernels, and also build the test suites,",0,0
data/train/7_63.mp3,"and then run the tests against the kernels, and share the results, and then report the results",0,0
data/train/7_64.mp3,"via emails or a web dashboard to the developers, and that's how the loop is closed.",0,0
data/train/7_65.mp3,To understand a bit better what the developers actually need in order for KernelCI to be,0,0
data/train/7_66.mp3,"more widely used, we've run a survey in 2020, we called it the community survey, there's a blog",0,0
data/train/7_67.mp3,"post available on kernelci.org website if you want to read the whole report, but here there's a small",0,0
data/train/7_68.mp3,"summary of the main takeaways from that survey. So we need to, ideally we would need to test",0,0
data/train/7_69.mp3,"patches before they get applied, so like pre-merge if you want to call it like this,",0,0
data/train/7_70.mp3,"because then you get really short feedback circuit, so when someone sends some patch on",0,0
data/train/7_71.mp3,"a mailing list, you could get a reply really quickly whether it's breaking anything or not.",0,0
data/train/7_72.mp3,"That's really important, you know, based on the results from the survey.",0,0
data/train/7_73.mp3,"And then for things that are run post-merge, it seems like what makes a lot more sense is",0,0
data/train/7_74.mp3,"to run really long tests that maintainers don't have the time to run, or you know,",0,0
data/train/7_75.mp3,"things that are difficult to run by hand. Especially say on stable kernels, when there's",0,0
data/train/7_76.mp3,"normally like one release per week, it should be okay to have like tests that take 24 hours for",0,0
data/train/7_77.mp3,example. And then the third thing is improving the web dashboard. So we have currently one,0,0
data/train/7_78.mp3,"dashboard on kernelci.org, it's been there for several years and it's showing the results,",0,0
data/train/7_79.mp3,but there's many things that could be done to really improve it so that more users would be,0,0
data/train/7_80.mp3,"using it. And we're collecting user stories, well we're kind of collecting feedback, ideas and",0,0
data/train/7_81.mp3,"suggestions from anyone who would want to have, you know, what would be your ideal web dashboard.",0,0
data/train/7_82.mp3,We're starting to derive from that a set of requirements to start really designing a better,0,0
data/train/7_83.mp3,dashboard. This is driven by the Linux Foundation KernelCI project at the moment.,0,0
data/train/7_84.mp3,We're hoping to see some concrete results in 2022.,0,0
data/train/7_85.mp3,"So KernelCI runs a number of, well it builds some kernels and then runs some tests,",0,0
data/train/7_86.mp3,mostly functional tests. Initially it was doing only boot testing to check whether,0,0
data/train/7_87.mp3,"a platform would boot at all. Now we've started running more and more functional tests,",0,0
data/train/7_88.mp3,"things like IGT to test DRM KMS, as well as some GPUs as well now, and classic test suites like",0,0
data/train/7_89.mp3,"Linux Test Project LTP, and KSelfTest and KUnit which come with the kernel source tree itself.",0,0
data/train/7_90.mp3,So we're running about 15% of what LTP provides and KSelfTest provides. We're not really running,0,0
data/train/7_91.mp3,"KUnit yet, but that's coming soon and we've been working with the KUnit maintainers to get this",0,0
data/train/7_92.mp3,"enabled in KernelCI. So that's what we call the native tests, they are all orchestrated by",0,0
data/train/7_93.mp3,"KernelCI itself. Now in addition to these tests, we can look at KernelCI from a functionality",0,0
data/train/7_94.mp3,"point of view. So what does it do? So first it monitors a number of trees, there's about 100",0,0
data/train/7_95.mp3,"good branches that are monitored from individual maintainers, you know subsystems,",0,0
data/train/7_96.mp3,"architecture subsystems, and then you have bigger, well Mainline and Linux Next are integration",0,0
data/train/7_97.mp3,"branches, and stable, all the stable and long-term stable branches, as well as some branches for",0,0
data/train/7_98.mp3,"member companies of the project like CIP, and we're starting to look at Chrome OS kernels as well.",0,0
data/train/7_99.mp3,And one really interesting feature of KernelCI is the ability to track regressions when a test,0,0
data/train/7_100.mp3,"has been passing in previous revisions of a kernel, and one day it starts failing for an individual",0,0
data/train/7_101.mp3,"specific test case, as soon as it starts failing it's detected as a regression.",0,0
data/train/7_102.mp3,"And typically automatically there will be bisections started for that, which will",0,0
data/train/7_103.mp3,try to find the commit between the last good revision and the first bad revision to understand,0,0
data/train/7_104.mp3,which commit actually caused the problem. And this is particularly useful on Linux Next where,0,0
data/train/7_105.mp3,you have a lot of changes from one day to the next. And thanks to this we're finding a lot of,0,0
data/train/7_106.mp3,"issues in reporting, we can report the issues directly to the developers, because if you know",0,0
data/train/7_107.mp3,"who, you know, if you know the author of the commit you can send the message to the author",0,0
data/train/7_108.mp3,"and related maintainers, and people around the maintainers related to the code that was changed",0,0
data/train/7_109.mp3,by the patch itself. Then another big aspect of KernelCI which is a bit more recent is kcidb.,0,0
data/train/7_110.mp3,So this is only a database that's meant to collect results from any CI system that's running kernel,0,0
data/train/7_111.mp3,"tests. So the native tests, like I explained in previous slide, the native tests are collected",0,0
data/train/7_112.mp3,"there, but we're also collecting results from other test systems. And if you have your own test",0,0
data/train/7_113.mp3,"system you can also, you know, anybody can submit test results there. So the idea is to avoid, to",0,0
data/train/7_114.mp3,reduce duplication. And in principle a new web dashboard will be showing this information which,0,0
data/train/7_115.mp3,is like a superset of what you see right now on kernelci.org. By opposition to the native tests,0,0
data/train/7_116.mp3,"you have like the non-kernelci tests, things that are run outside of kernelci, the tests that are",0,0
data/train/7_117.mp3,"orchestrated directly by KernelCI, such as zeroday and syscaller, fuzzingbot, and redhats cki,",0,0
data/train/7_118.mp3,"and several tools from Lenaro as well. There's Lenaro Kernel Functional Tests, LKFT, and TuckSuite",0,0
data/train/7_119.mp3,"which is more like a service. Everybody could subscribe to it to build kernels and start,",0,0
data/train/7_120.mp3,"they also start to support running tests. And the result of all these, and a few more actually,",0,0
data/train/7_121.mp3,"from ARM and gen2 kernelci and a few more, all these results are currently being contributed",0,0
data/train/7_122.mp3,"to kcidb. Actually it's not all of syscaller, but some of, because that's a huge data set,",0,0
data/train/7_123.mp3,"but some of the syscaller results are being contributed to kcidb. And it's, that's growing,",0,0
data/train/7_124.mp3,there's a weekly report on the kernelci mailing list you can see to have status of all the,0,0
data/train/7_125.mp3,"different contributors. Mesa's kind of an interesting contrast to this I think, because",0,0
data/train/7_126.mp3,"it is, well it's the de facto standard for open source GPU drivers on Linux. So we're talking",0,0
data/train/7_127.mp3,"OpenGL, OpenGL ES, Vulkan, everything you need for both games, accelerated desktops, you name it.",0,0
data/train/7_128.mp3,"And it's much more limited in scope than the kernel. So of the drivers we have, we have",0,0
data/train/7_129.mp3,"eight different hardware vendors, obviously all with their own, you know, big generational or",0,0
data/train/7_130.mp3,smaller generational bumps. And then we also have layered and virtualized drivers in our software,0,0
data/train/7_131.mp3,reference driver. It's a much smaller development community in Mesa compared to the kernel.,0,0
data/train/7_132.mp3,And these teams are often not directly supported by the hardware vendor. It runs the entire spectrum,0,0
data/train/7_133.mp3,from the hardware vendor has teams of people directly working on Mesa and producing their,0,0
data/train/7_134.mp3,driver as a first class output. A bunch in the middle where the vendor will assist and support,0,0
data/train/7_135.mp3,"the development team, but the development is being done externally to the hardware vendor.",0,0
data/train/7_136.mp3,Right the way through to completely reverse engineered efforts where the vendor has no,0,0
data/train/7_137.mp3,involvement at all. So one challenge we've had is really in bringing Mesa up from this kind of,0,0
data/train/7_138.mp3,"scrappy underdog where you're happy that it works to now where we have, we've gone from,",0,0
data/train/7_139.mp3,"you know, one driver that's been conformant for the past few years up to several drivers",0,0
data/train/7_140.mp3,having gone through the official Khronos conformance testing. And that's been something,0,0
data/train/7_141.mp3,we've really needed to back up with some really extensive testing to make sure that we stay,0,0
data/train/7_142.mp3,"conformant. You know, it's a really, it's a really sort of hard one battle and, you know, we don't",0,0
data/train/7_143.mp3,want to be slipping back. And we also don't want to lose the development velocity that we've been,0,0
data/train/7_144.mp3,able to have within Mesa. And this can be quite difficult because as Mesa is relatively understaffed,0,0
data/train/7_145.mp3,"as a project compared to something like the kernel, the development community can tend to naturally",0,0
data/train/7_146.mp3,"silo a little bit. Even though people will work on the core of Mesa itself, of course,",0,0
data/train/7_147.mp3,often their first target is a particular driver. And so their attention might be taken away by,0,0
data/train/7_148.mp3,new hardware support or particular feature enablement or anything else which makes it,0,0
data/train/7_149.mp3,"difficult to have kind of a shared global overview of Mesa as a whole rather than,",0,0
data/train/7_150.mp3,"you know, your own driver world. But luckily the one thing we have got that's been",0,0
data/train/7_151.mp3,kind of a gift is Khronos has over the past few years made its conformance test suites publicly,0,0
data/train/7_152.mp3,available. So it's no longer just Khronos members who can run the official OpenGL and Vulkan,0,0
data/train/7_153.mp3,"conformance test suites, but they're available to the whole public and we're able to run those",0,0
data/train/7_154.mp3,"in public and distribute those now, which has really been a godsend. So having that",0,0
data/train/7_155.mp3,"large amount of API coverage for the official conformance testing is great and running those,",0,0
data/train/7_156.mp3,"you know, that is the Khronos conformance process essentially is running those. So",0,0
data/train/7_157.mp3,you know where your driver stands if you're able to run those.,0,0
data/train/7_158.mp3,"In addition to that, we also have other test suites such as Piglet, which are kind of built",0,0
data/train/7_159.mp3,from the reverse direction. So the conformance test suites have been built out by the API designers in,0,0
data/train/7_160.mp3,"parallel with the API being designed, and it's really focused on that. Whereas Piglet has just",0,0
data/train/7_161.mp3,"been incrementally built out by Mesa developers who will find a bug, realize that this could be",0,0
data/train/7_162.mp3,"particularly common or crippling or what have you, and then they'll put in a Piglet test for",0,0
data/train/7_163.mp3,"that to make sure that you don't regress. And yeah, it's possible to do this with",0,0
data/train/7_164.mp3,"both actual hardware GPU drivers, but also it's completely possible to just test the",0,0
data/train/7_165.mp3,"reference software driver we have, which has no hardware dependencies, but will just run on",0,0
data/train/7_166.mp3,"any CPU with an LLVM backend. So doing that is a really nice sort of little quiver in our bow,",0,0
data/train/7_167.mp3,"I suppose, to be able to test the core of Mesa without needing dedicated hardware.",0,0
data/train/7_168.mp3,"So the testing that we do have in Mesa, that covers several generations of all of AMD GPUs,",0,0
data/train/7_169.mp3,"the Mali GPUs, Broadcom's video core in the Raspberry Pi, all of the Intel GPUs,",0,0
data/train/7_170.mp3,"the Qualcomm Adreno that comes in their Snapdragon SoCs, and also the Virosilicon or",0,0
data/train/7_171.mp3,"Vivante GPUs, which tend to come in processors like NXP. And all of these have achieved,",0,0
data/train/7_172.mp3,"at least for some hardware generations or some API versions, official Khronos conformance. So",0,0
data/train/7_173.mp3,"again, we're very keen to make sure that we keep that and we don't regress backwards",0,0
data/train/7_174.mp3,"so we do quite extensive testing of those. And the interesting contrast to the kernel, I think,",0,0
data/train/7_175.mp3,"is that we have a slightly more traditional for open source, I suppose, pre-merge testing process,",0,0
data/train/7_176.mp3,which is blocking. So when you submit a merge request and it's been reviewed and it's good to,0,0
data/train/7_177.mp3,"go, you assign it to a very cold and unfeeling bot who will go and run a ton of tests and merge if",0,0
data/train/7_178.mp3,they all succeed or tell you that something went wrong if any of them failed. So in order to support,0,0
data/train/7_179.mp3,"that process without everything collapsing, we want every merge pipeline to turn around in",0,0
data/train/7_180.mp3,"15 to perhaps 20 minutes in Extremis. But that has to cover running, you know, some",0,0
data/train/7_181.mp3,"generations of GPU will run over 300,0,000 individual tests for every MR",0,0
data/train/7_182.mp3,"between all the different various test suites. So in order to do that, we had to build out a",0,0
data/train/7_183.mp3,"custom test runner framework. But it's not just conformance tests that we run, but we also have",0,0
data/train/7_184.mp3,"traces from real life workloads, captures from games or desktop clients or any of these where",0,0
data/train/7_185.mp3,we take the GL and Vulkan command streams that they actually emit and we replay those,0,0
data/train/7_186.mp3,and make sure that the output isn't changing. Or at least not changing in a way that's seen as bad,0,0
data/train/7_187.mp3,"because OpenGL isn't pixel precise, nor is Vulkan. So you might have minor differences here and there",0,0
data/train/7_188.mp3,and we have some tools which allow us to visualize the differences and see what the change is to,0,0
data/train/7_189.mp3,"see if it's an acceptable change. But yeah, all of this has to come within this relatively",0,0
data/train/7_190.mp3,"short time window. And it's something that we have to get right, essentially, because,",0,0
data/train/7_191.mp3,"you know, rather than being a more advisory post merge thing where code gets pushed out",0,0
data/train/7_192.mp3,"into the wild, and then later on, you get an email telling you that it broke something.",0,0
data/train/7_193.mp3,"And if a test fails, then your merge request won't get merged.",0,0
data/train/7_194.mp3,"It turns out that having flaky tests, which block people's MRs is a pretty good way to",0,0
data/train/7_195.mp3,get developers to tell you what they really feel about your test suite.,0,0
data/train/7_196.mp3,"And if we look at other projects, so Wayland and Western were very early adopters of CI",0,0
data/train/7_197.mp3,"and having GitLab on freedesktop.org. But for the longest time, they didn't get too far beyond",0,0
data/train/7_198.mp3,build testing. That's because one of the challenges we have in Wayland is the lack of,0,0
data/train/7_199.mp3,an official universal conformance test suite. So we have all of the tests on the server side,0,0
data/train/7_200.mp3,inside Western that we've written for ourselves as we've developed it. But we don't have a similar,0,0
data/train/7_201.mp3,"target like we do with the Khronos APIs to be able to work towards and give us a yes, no answer.",0,0
data/train/7_202.mp3,"But even so, we're making use of we actually test Western by starting up a new virtual machine",0,0
data/train/7_203.mp3,"with a clean known kernel and a virtual KMS driver, which just simulates a display controller.",0,0
data/train/7_204.mp3,"And that gets us a lot of what we want, because we're able to exercise a lot of different paths",0,0
data/train/7_205.mp3,within our backends and make sure that they run about as well as you can when you're working,0,0
data/train/7_206.mp3,"with a virtual driver rather than a real hardware driver. But yeah, that's where we are now for",0,0
data/train/7_207.mp3,"Wayland and Western. The backend testing, testing things like rendering correctness and internal",0,0
data/train/7_208.mp3,"consistency. But these are really home-built tests. GStreamer, on the other hand, for multimedia,",0,0
data/train/7_209.mp3,it's got a very well-established set of tests which have almost always been there for both,0,0
data/train/7_210.mp3,for its individual modules and also for end-to-end functional and integration testing.,0,0
data/train/7_211.mp3,So GST validate is a suite which checks the modules and makes sure that they behave according,0,0
data/train/7_212.mp3,"to the GStreamer API contract. So in isolation, they look like they do what they should.",0,0
data/train/7_213.mp3,"And then Serbro is a monster integration test suite, which does real end-to-end testing,",0,0
data/train/7_214.mp3,"putting through various workloads, again, that they've captured as they've gone on, and places",0,0
data/train/7_215.mp3,where they found bugs. And then it's been added to the test suite to make sure that all of those,0,0
data/train/7_216.mp3,"corner cases work. And that's been a part of GStreamer upstream for a good couple of years now,",0,0
data/train/7_217.mp3,"again, concurrent with the move to GitLab on Freedustop.org. But this is all happening",0,0
data/train/7_218.mp3,as software-based testing. So it will run in containers and virtual machines on general,0,0
data/train/7_219.mp3,"purpose hosts. And we're not yet able to test how GStreamer behaves, again, with different",0,0
data/train/7_220.mp3,"hardware drivers, say, for video for Linux, or also for sound, or",0,0
data/train/7_221.mp3,any of those other inflection points.,0,0
data/train/7_222.mp3,Now we've looked at how the kernel is being tested upstream and how graphics and,0,0
data/train/7_223.mp3,"YLAN and GStreamer are being tested upstream, we can start thinking about general concepts around",0,0
data/train/7_224.mp3,what does it take to move an open-source project to being really test-driven.,0,0
data/train/7_225.mp3,"You can see, like we said at the beginning, commercial products, fully integrated products,",0,0
data/train/7_226.mp3,"are tested very thoroughly, and they have control over their own universe. So there's no real",0,0
data/train/7_227.mp3,"barrier in terms of people adopting it, because it's a team working on it. So they all basically",0,0
data/train/7_228.mp3,"adopt the workflow and the automated testing, because that's just the way they do it, and have",0,0
data/train/7_229.mp3,"complete freedom over how they do this. For an open-source project, you have contributors from",0,0
data/train/7_230.mp3,"many different horizons. So they might all have different views about how to work. Also, you could",0,0
data/train/7_231.mp3,"have, in a large project like Linux kernel, different parts of the kernel will need different",0,0
data/train/7_232.mp3,"types of workflows, some parts will be changing very quickly, other parts will need to be really",0,0
data/train/7_233.mp3,"stable. So in the same way that open-source code is really coming from, like, built by the ground",0,0
data/train/7_234.mp3,"up, so people contribute code, and that's how it happens. Nobody's planning what's really going to",0,0
data/train/7_235.mp3,"happen for the Linux kernel in the next few years, or even the next few months. So it's in the same",0,0
data/train/7_236.mp3,"way that the changes are not really imposed. Of course, things are being designed, but nobody",0,0
data/train/7_237.mp3,"is, like, nobody has a master plan and decides exactly how things are going to",0,0
data/train/7_238.mp3,"unfold. So it's the same thing for testing. Basically, like, people send code and request",0,0
data/train/7_239.mp3,"for comments on the mailing list about code changes. For testing, people can provide tools",0,0
data/train/7_240.mp3,"and suggest ways of doing things. And as people see that there's value in it, and that it's",0,0
data/train/7_241.mp3,"something that they can adopt, and gradually it will be adopted.",0,0
data/train/7_242.mp3,"So basically, this is what, you can see this happening already, like we've explained with",0,0
data/train/7_243.mp3,"KernelCI, when some maintainers are starting to engage and look at the results. And maybe",0,0
data/train/7_244.mp3,"if KernelCI doesn't work, they have their own, or if it doesn't provide the results that they're",0,0
data/train/7_245.mp3,"looking for, they have their own manual test and they can still carry on. Like for stable",0,0
data/train/7_246.mp3,"kernels, typically KernelCI would be sending results for each stable kernel. So if the",0,0
data/train/7_247.mp3,"results are there and some problems were detected by KernelCI, something will get done about it.",0,0
data/train/7_248.mp3,"Some people will try to fix them. But if for some reason KernelCI disappeared, the stable",0,0
data/train/7_249.mp3,"kernel would still be released. It's just, maybe some bugs will not be known and they'll be found",0,0
data/train/7_250.mp3,"later. That's currently how things work. So maybe with time, it's a bit like a clutch mechanism,",0,0
data/train/7_251.mp3,"maybe after a while, if we all spin at the same speed, then we can really engage. And then the",0,0
data/train/7_252.mp3,"test system will be working hand in hand with the kernel. So this has already happened with Mesa-CI,",0,0
data/train/7_253.mp3,"like Daniel just explained. And of course, sometimes you have a few sparkles in",0,0
data/train/7_254.mp3,"a clutch system, so it's not always easy to get it completely right without any smoke",0,0
data/train/7_255.mp3,"coming out of it. But that's, it's really a price worth paying basically. Because now,",0,0
data/train/7_256.mp3,"you know, when a change comes in, it has to pass the tests. And that's really where you want to be.",0,0
data/train/7_257.mp3,"So like I've just explained, you have some tools available. So KernelCI is one of them",0,0
data/train/7_258.mp3,"for the kernel, but also there's ZeroDay will be sending you emails. And SysBot will be doing",0,0
data/train/7_259.mp3,"this as well, you know, fuzzing syscalls in the kernel to try to find corner cases that nobody",0,0
data/train/7_260.mp3,"else has found before. So these are available. And of course, they send results by email. And",0,0
data/train/7_261.mp3,"if people don't like the emails, that happens sometimes, it's like, this report is not useful,",0,0
data/train/7_262.mp3,"people will reply and then things will get adjusted. And yeah, for Mesa and Wayland and",0,0
data/train/7_263.mp3,"GStreamer, maybe it's a little bit easier to have things enforced. It's a bit like,",0,0
data/train/7_264.mp3,"maybe like a subsystem in the kernel, if you have a small enough subsystem,",0,0
data/train/7_265.mp3,"then it could operate in its own autonomy, basically, and then decide to accept a test",0,0
data/train/7_266.mp3,"or workflow, test-driven workflow. So that's kind of the step-by-step process that we have",0,0
data/train/7_267.mp3,"to go through. Yes, Daniel? I think that's a really good parallel. I mean, I always thought",0,0
data/train/7_268.mp3,"the problem with the kernel wasn't that it had no master plan, but that it had like hundreds of them",0,0
data/train/7_269.mp3,"at any given time, right? Whereas, yeah, just, I think having that smaller scope makes it much",0,0
data/train/7_270.mp3,easier for us. So now we can see some numbers to have an idea of the dimension of what is being,0,0
data/train/7_271.mp3,"done on the kernel side, at least from kernel-CI point of view. I haven't put stats about bisections,",0,0
data/train/7_272.mp3,"but every week there's one, two or three bisections that lead to actual bug fixes,",0,0
data/train/7_273.mp3,"and that's growing. So this is, you know, some metric that will be producing some stats at some",0,0
data/train/7_274.mp3,"point about that. You can already see the number of tests being run. So on Linux Next, which has",0,0
data/train/7_275.mp3,"the biggest coverage, there's about 12,0,000 individual test cases run every day, because",0,0
data/train/7_276.mp3,that's for every revision of Linux Next. And that is growing as we keep adding new tests and new,0,0
data/train/7_277.mp3,"platforms, and we have also new test labs joining that quickly increased the test coverage.",0,0
data/train/7_278.mp3,"On the second graph, you can see the kcidb number of builds. So this is all the builds from",0,0
data/train/7_279.mp3,"from the native kernel-CI builds, but also here in this graph, you will see",0,0
data/train/7_280.mp3,builds submitted by LKFT and all the other submitters to kcidb. So TuckSuite and also CKI,0,0
data/train/7_281.mp3,"from Red Hat, and also some builds from ARM. So this is, you know, it's gradually getting to the",0,0
data/train/7_282.mp3,"point where you see the actual number of people testing the upstream Linux kernel. Well, this is",0,0
data/train/7_283.mp3,"for all the revisions, so we get about 20,0,000 builds. So for each build you have maybe",0,0
data/train/7_284.mp3,"maybe a thousand, two thousand tests. We don't have all the tests yet in kcidb, but that gives",0,0
data/train/7_285.mp3,"an idea of the size. And of course, maybe as we can see, we can start seeing the results put",0,0
data/train/7_286.mp3,together. Maybe some duplication will be removed after a while if we all keep building the same,0,0
data/train/7_287.mp3,"kernels. Maybe we can reuse each other's kernels. We can, we'll see how that works, how that will",0,0
data/train/7_288.mp3,"work out over time. And similarly for Mesa, I mean, you can see some, a nice shiny graph there",0,0
data/train/7_289.mp3,"with, I think, a pretty interesting pattern in the number of tests versus",0,0
data/train/7_290.mp3,the number of commits or the number of merge requests that were made to Mesa.,0,0
data/train/7_291.mp3,"It's definitely an iterative story, essentially, of building out test coverage as wide as we can.",0,0
data/train/7_292.mp3,"And then, you know, for what that gives us, it turns out sometimes that's a bit overkill.",0,0
data/train/7_293.mp3,"So one of the traditional patterns is that we'd introduce the first version of,",0,0
data/train/7_294.mp3,the first iteration of testing for a particular hardware generation.,0,0
data/train/7_295.mp3,And we'd have a lot of those tests run just to shake it out and to get it completely stable,0,0
data/train/7_296.mp3,"and find out where all the issues are before we stepped it back. So, for example, if you submit",0,0
data/train/7_297.mp3,"a merge request, which only modifies the AMD driver, then it's not going to run any of the",0,0
data/train/7_298.mp3,"tests on PanFrost for the ARM Mali or the Frodrino driver for Qualcomm, because we know that there's",0,0
data/train/7_299.mp3,going to be no impact. Whereas if you submit a job which touches core code or submit a merge,0,0
data/train/7_300.mp3,"request which touches core code, you can see up to 155 jobs per merge request just touching a full",0,0
data/train/7_301.mp3,"extent of everything we can test. And yeah, they're not entirely correlated,",0,0
data/train/7_302.mp3,"these graphs, because they're somewhat independent. We do do manual test runs outside of the merge",0,0
data/train/7_303.mp3,request context. Sometimes you have core changes which are much more difficult and finicky. So,0,0
data/train/7_304.mp3,"they require a fair few passes through the automated testing before they can be merged,",0,0
data/train/7_305.mp3,just because no one can have 30 different generations of GPU available to them on their,0,0
data/train/7_306.mp3,"desk. You can also see one particular spike, which was one of the least fun months of my life,",0,0
data/train/7_307.mp3,"when we had a lot of infrastructure issues on FreeDesktop. Not really related to the test system,",0,0
data/train/7_308.mp3,"but more about things like networking, where the tests were so unreliable that",0,0
data/train/7_309.mp3,we just had to keep running them over and over until they did eventually pass.,0,0
data/train/7_310.mp3,That one was interesting. It definitely taught us some lessons about things like,0,0
data/train/7_311.mp3,"making sure you have not only really good monitoring for false positives, but something",0,0
data/train/7_312.mp3,"that's quite dynamic and really easy to modify, so you can pick those up and you don't push the",0,0
data/train/7_313.mp3,burden back to developers to deal with themselves. One of the things we found out is that,0,0
data/train/7_314.mp3,"beyond a certain point of unreliability, some developers will just smash retry every single",0,0
data/train/7_315.mp3,"time a test fails, even if it's failing because their code doesn't compile. So there's definitely,",0,0
data/train/7_316.mp3,"you know, coming back to Guillaume's point about being iterative and building confidence,",0,0
data/train/7_317.mp3,which KernelCI certainly does. There's a lot of shadow testing in the background,0,0
data/train/7_318.mp3,"that you don't see. That's one thing we picked up from Mesa as well, is that",0,0
data/train/7_319.mp3,it's really important to deliver the results as accurately as possible so people not only,0,0
data/train/7_320.mp3,"get confidence in it, but they're also able to buy into it a bit more. So, you know,",0,0
data/train/7_321.mp3,testing becomes something that the whole community cares about rather than having,0,0
data/train/7_322.mp3,"developers and people who do test stuff, which is never a particularly nice dynamic to be in.",0,0
data/train/7_323.mp3,"So yeah, now we've talked about what we've been doing in our individual projects,",0,0
data/train/7_324.mp3,"and a lot of the challenges we've had there, how we've resolved them, you know, the ways that",0,0
data/train/7_325.mp3,that we have brought testing to those projects. One really big thing that's coming up for us is,0,0
data/train/7_326.mp3,bringing those all together and having them be more integrated and less siloed.,0,0
data/train/7_327.mp3,"So, for example, for all of our Mesa testing, which we do on hardware, we pin a really specific",0,0
data/train/7_328.mp3,"kernel version. It's the only way to make Mesa testing tractable, because otherwise,",0,0
data/train/7_329.mp3,"you know, we'd just be subject to a million things which are outside of our control.",0,0
data/train/7_330.mp3,"But it's still really useful to have. I mean, kernel CI can test all of the kernel aspects,",0,0
data/train/7_331.mp3,"but it would be really useful for maintainers to know that, you know, their changes broke",0,0
data/train/7_332.mp3,"actual running user space workloads like Mesa or like GStreamer for media to code,",0,0
data/train/7_333.mp3,"and being able to have that fast integrated feedback. And this is true everywhere. Conversely,",0,0
data/train/7_334.mp3,"Western pins a version of Mesa, and kernel CI pins known versions of user space components just to",0,0
data/train/7_335.mp3,"keep the whole stack tractable. So, one thing we've been looking at and working on is being",0,0
data/train/7_336.mp3,"able to share our workloads, our definitions, and the ways we parameterize them as well.",0,0
data/train/7_337.mp3,"So, we can bring in more integrated testing and be able to at least work on sort of fragments of",0,0
data/train/7_338.mp3,"the tests. So, you know, for example, we couldn't run the entire conformance test suites for every",0,0
data/train/7_339.mp3,"GPU, for every kernel revision, because there are just too many of them. But what we can do is run",0,0
data/train/7_340.mp3,"a smaller, more targeted subset, and at least have a bit of confidence that things are roughly",0,0
data/train/7_341.mp3,"working as they should with new kernel versions. And that's something that helps us all. You know,",0,0
data/train/7_342.mp3,it lets people know about regressions sooner. It makes sure that those regressions don't hit,0,0
data/train/7_343.mp3,"actual released kernels or Mesa versions or anything, but they're discovered before they",0,0
data/train/7_344.mp3,"can be found by users. So, just cuts out that manual feedback loop.",0,0
data/train/7_345.mp3,"And one thing we've found with Mesa is having that testing, even in Western with more limited",0,0
data/train/7_346.mp3,"testing there, it's let us move a lot more fearlessly. We can be much less cautious about",0,0
data/train/7_347.mp3,"making sure that we don't break things. There's a lot less manual testing, which takes up the",0,0
data/train/7_348.mp3,developer's time. But you can do your code review and be sure that something else is going to pick,0,0
data/train/7_349.mp3,"up the more visible aspects of correctness. And that would be really great if, you know,",0,0
data/train/7_350.mp3,"the kernel would be able to move quicker without having to worry too much about Mesa,",0,0
data/train/7_351.mp3,and Mesa and Wayland didn't have to be terrified of upgrading the kernel because,0,0
data/train/7_352.mp3,"who knows what might break. So, that's something that we're looking forward to",0,0
data/train/7_353.mp3,having much more integration with as time passes.,0,0
data/train/7_354.mp3,"And so, even if you're not participating in upstream open source projects, this is still",0,0
data/train/7_355.mp3,"meaningful to you. Because as we were saying at the beginning, you know, the upstream QA and CI",0,0
data/train/7_356.mp3,has only really been meaningful to the upstream projects themselves. Because there's often been,0,0
data/train/7_357.mp3,"such a distance between those projects and the vendors in terms of the time to deploy new versions,",0,0
data/train/7_358.mp3,downstream customizations which get made. Those often never find their way back to upstream,0,0
data/train/7_359.mp3,"because, you know, it's been so long and the code base has moved on anyway.",0,0
data/train/7_360.mp3,"And this is a real problem when we think about not just things like Spectre and Meltdown, but",0,0
data/train/7_361.mp3,"the entire security landscape, you know, with such complex and rapidly moving software that you have",0,0
data/train/7_362.mp3,"to keep on top of it to ship something secure to people. So, this is a huge benefit because",0,0
data/train/7_363.mp3,the amount of testing that we do in the upstream projects these days gives so much more assurance,0,0
data/train/7_364.mp3,that the vendors are able to pull in much newer versions of upstream software much more quickly,0,0
data/train/7_365.mp3,than they have done in the past. But this is obviously only possible if you have a much smaller,0,0
data/train/7_366.mp3,"delta of changes that you've made to existing upstream trees. So, for the first time there's",0,0
data/train/7_367.mp3,"a real incentive for vendors to work with upstream, both in terms of the changes they make",0,0
data/train/7_368.mp3,"and also in terms of helping us with the QA, the CI, and the testing that we do.",0,0
data/train/7_369.mp3,Because everything done to upstream means you can ship better software to your customers faster,0,0
data/train/7_370.mp3,and it means that you can just have more and more assurance that what you're shipping,0,0
data/train/7_371.mp3,"is secure, it's validated, it's solid, and it will do what you need it to do.",0,0
data/train/7_372.mp3,"So, that's our quick summary of the landscape. We'll have some more details",0,0
data/train/7_373.mp3,"available in a blog on collabra.com with a lot more details on how these upstream projects work,",0,0
data/train/7_374.mp3,"how to get involved and help out, especially with the testing angles. But this is the thing",0,0
data/train/7_375.mp3,that's here. We're not talking about the old days where open source was a kind of wild west fun,0,0
data/train/7_376.mp3,project and it was the vendors who brought some kind of rigor to these projects. It's now,0,0
data/train/7_377.mp3,something that over time the open source projects have been able to embrace as part of their,0,0
data/train/7_378.mp3,projects and their methodologies and that's only going to increase.,0,0
data/train/7_379.mp3,"All of these efforts, they're open to contributors. Kernel CI is a Linux foundation project.",0,0
data/train/7_380.mp3,"Mesa CI is something primarily being worked on by Collabra, Google, Legalia, Red Hat, Valve,",0,0
data/train/7_381.mp3,"all companies who are just interested in the long-term health of Mesa. Similarly, Western,",0,0
data/train/7_382.mp3,"GStreamer, the testing infrastructure and development is shared between the entire",0,0
data/train/7_383.mp3,"community. The more we do this, the more you can benefit from what we do upstream.",0,0
data/train/7_384.mp3,"So, please come get involved. Don't be afraid. Help us out and we can ship",0,0
data/train/7_385.mp3,better software to you so you can ship better software to your customers.,0,0
data/train/7_386.mp3,"And with that, thank you very much. We'll be here to take any questions you might have and",0,0
data/train/7_387.mp3,"if you're interested in getting in touch, our email addresses as well are available",0,0
data/train/7_388.mp3,"in the title slide. So, thank you.",0,0
data/train/7_389.mp3,Thank you.,0,0
data/train/6_0.mp3,"Hello, everyone. Thank you for joining this virtual talk here at the Live Embedded event.",0,0
data/train/6_1.mp3,"And today I'm here to talk about Pipeware, which is a new technology for Linux that is",0,0
data/train/6_2.mp3,"essentially a multimedia service that has been in development for quite a long time,",0,0
data/train/6_3.mp3,I would say more than five years. And now it's mature enough and ready to be used for,0,0
data/train/6_4.mp3,"the automotive world and the embedded world. So, yeah, before moving on to the main topic",0,0
data/train/6_5.mp3,"and see how Pipeware works and how it can be used for the automotive and embedded world,",0,0
data/train/6_6.mp3,"I'd like to do a quick introduction to myself first. So, as you can see, my name is Julian.",0,0
data/train/6_7.mp3,I am a Spanish multimedia software developer working at Collabora. I joined the company,0,0
data/train/6_8.mp3,"quite recently. I joined at the beginning of 2019. And since I joined the company,",0,0
data/train/6_9.mp3,I've been part of the multimedia team and I've been mostly working with,0,0
data/train/6_10.mp3,"Pipeware and distributor projects. So that being said, let's move on",0,0
data/train/6_11.mp3,"into the main topic, which is what is Pipeware? What is this new technology that is emerging",0,0
data/train/6_12.mp3,"and is gaining more and more popularity nowadays? Well, as I said at the beginning,",0,0
data/train/6_13.mp3,Pipeware is essentially a fresh multimedia service for Linux that can handle any kind,0,0
data/train/6_14.mp3,of multimedia devices. It doesn't matter if it's video or audio. It was originally meant to,0,0
data/train/6_15.mp3,"handle only video devices. In fact, its original name was Pulse Video. But over the years,",0,0
data/train/6_16.mp3,it evolved and now it was renamed to Pipeware. And now it's more of a generic multimedia,0,0
data/train/6_17.mp3,framework that can handle both devices. And the reason for that is because it started,0,0
data/train/6_18.mp3,"addressing many issues previous audio services were having. So at the end, the developers,",0,0
data/train/6_19.mp3,they decided to just handle everything and at some point replace those old multimedia services.,0,0
data/train/6_20.mp3,"So basically with Pipeware, what you can do is applications, they can capture video from",0,0
data/train/6_21.mp3,"different video sources, such as cameras or even graphic sources. For example,",0,0
data/train/6_22.mp3,if you want to capture your desktop with Wayland or Vulkan. And you can also obviously do,0,0
data/train/6_23.mp3,"capturing and playback of audio in other devices. For example, you can capture audio from a microphone",0,0
data/train/6_24.mp3,and you can do audio playback using a speaker or even my Bluetooth devices. So applications can do,0,0
data/train/6_25.mp3,"all of that very easily without worrying about configuring devices and using low level APIs,",0,0
data/train/6_26.mp3,such as video for Linux when you want to capture video from cameras or Vulkan or Wayland complex,0,0
data/train/6_27.mp3,"APIs, or for audio also in Bluetooth, low level and complex APIs. So applications don't need to",0,0
data/train/6_28.mp3,"worry about that. So the way it works, Pipeware is a daemon that runs the background and applications",0,0
data/train/6_29.mp3,"connect to the daemon. And they basically tell them, hey, Pipeware, I want to just capture",0,0
data/train/6_30.mp3,"buffers from this device, or I want to play buffers on this device. And that's it. They",0,0
data/train/6_31.mp3,"don't need to worry about checking if the device is being used, if it's not used,",0,0
data/train/6_32.mp3,if they have permission or anything like that. All of that is handled automatically by Pipeware.,0,0
data/train/6_33.mp3,"So why do we need Pipeware? I mean, we already have, you know, in one hand, we have",0,0
data/train/6_34.mp3,"Pulse Audio and we have Jack. So why do we need an extra one? Well, you know,",0,0
data/train/6_35.mp3,"so Pulse Audio is a, it's like a generic audio device, you know,",0,0
data/train/6_36.mp3,"service that handles, you know, all of that in a generic way for you. And Jack,",0,0
data/train/6_37.mp3,audio server is more focused on professional and low latency audio processing. But what if,0,0
data/train/6_38.mp3,"an application wants to do a little bit of both? You know, you can't. So one of the problems",0,0
data/train/6_39.mp3,"Pipeware wants to solve is the unification of Pulse Audio and Jack, because it wants to replace",0,0
data/train/6_40.mp3,"them, get rid of them, and have a system running only one multimedia framework, simplifying a lot",0,0
data/train/6_41.mp3,"of the Linux multimedia stack, because otherwise it's quite complex because of all these different",0,0
data/train/6_42.mp3,"services. Now, another issue that Pipeware wants to solve is security.",0,0
data/train/6_43.mp3,"So at the moment, you know, the current approaches, the current multimedia frameworks,",0,0
data/train/6_44.mp3,"they don't handle containers properly, such as Flatpak or Wayland, because their permissions,",0,0
data/train/6_45.mp3,"basically, they rely on the video and audio user groups. Pipeware doesn't rely on that. Pipeware",0,0
data/train/6_46.mp3,"supports, fully supports containers properly. So it basically asks the container if he can access",0,0
data/train/6_47.mp3,"the device, and if he cannot access the device, cannot basically tell the client,",0,0
data/train/6_48.mp3,"this device cannot be accessed. So it's, for security, especially nowadays, Pipeware is much,",0,0
data/train/6_49.mp3,much safer and better. The third point that Pipeware wants to address is low latency.,0,0
data/train/6_50.mp3,"Pipeware is low latency and real-time capable, and it can handle very small buffer sizes of",0,0
data/train/6_51.mp3,"up to 32 samples, which is only one or two milliseconds of latency that not even Jack",0,0
data/train/6_52.mp3,"can do that. And last and last least, it's flexibility. So Pipeware is very flexible",0,0
data/train/6_53.mp3,because it exposes an API for users to write their own session manager and basically tell,0,0
data/train/6_54.mp3,"Pipeware how to behave based on different use cases and scenarios. So basically, we have simplicity,",0,0
data/train/6_55.mp3,"security, performance, and flexibility. So if you have a look at the Linux multimedia stack,",0,0
data/train/6_56.mp3,"if we are running the Pipeware daemon, we can see that there's something like that. So at the",0,0
data/train/6_57.mp3,"bottom, we have the kernel with all the different drivers, and on the top, we have the different",0,0
data/train/6_58.mp3,"applications, the different multimedia applications. And the Pipeware is like a middle layer in between",0,0
data/train/6_59.mp3,"those two layers where applications connect to it, and then Pipeware manages those connections",0,0
data/train/6_60.mp3,"and uses internally the kernel low-level APIs, multimedia APIs. And those connections, all of that",0,0
data/train/6_61.mp3,"is handled automatically by the session manager, which runs in a different process. So there's at",0,0
data/train/6_62.mp3,"least three processes going on here. There's the application process, the Pipeware daemon process,",0,0
data/train/6_63.mp3,and the Pipeware session manager process. And they all communicate each other via sockets,0,0
data/train/6_64.mp3,using a protocol. Many different protocols can be used.,0,0
data/train/6_65.mp3,"Pipeware has its own native protocol, but others can be used. You can use,",0,0
data/train/6_66.mp3,"for example, the Wayland protocol, or you can even implement your own protocol if you want.",0,0
data/train/6_67.mp3,"But yeah, so in this example, if you have a look at the song recorder on the top right",0,0
data/train/6_68.mp3,"corner, you can see that it's linked with the green square, which is a node,",0,0
data/train/6_69.mp3,"the green processing element, which is... the green processing elements here are more like",0,0
data/train/6_70.mp3,"converters. You know, they do audio conversion, they do video conversion or audio mixing,",0,0
data/train/6_71.mp3,all of that. And then we have the purple nodes that are syncs and sources that are connected,0,0
data/train/6_72.mp3,"to the device. So for example, different applications could connect to the same",0,0
data/train/6_73.mp3,"node and Pipeware decides whether... sorry, the session manager decides whether he wants to keep",0,0
data/train/6_74.mp3,"the previous link and play both of them at the same time, or just remove the previous one and",0,0
data/train/6_75.mp3,"only connect the new one. So yeah, the session manager has control of everything.",0,0
data/train/6_76.mp3,"So if I want to use Pipeware on my system, do I have to update all my multimedia applications",0,0
data/train/6_77.mp3,"and use the new Pipeware API? Not necessarily, because the Pipeware project also provides",0,0
data/train/6_78.mp3,"compatibility APIs built on top of Pipeware. So for example, there is an ALSA...",0,0
data/train/6_79.mp3,"for ALSA applications, there is a Pipeware PCM plugin that does the bridge between the ALSA API",0,0
data/train/6_80.mp3,and internally connects to the Pipeware daemon and exposes all these different Pipeware nodes.,0,0
data/train/6_81.mp3,"For Pulse Hold and Jack applications, the same approach is done by having replacement",0,0
data/train/6_82.mp3,for libpulse.so and libjack.so. So applications don't need to be updated right away if you want,0,0
data/train/6_83.mp3,"to use Pipeware, because thanks to these compatibility APIs, everything",0,0
data/train/6_84.mp3,"works fine. But eventually, in the future, it's nice for the applications to change and use the",0,0
data/train/6_85.mp3,Pipeware API to remove more complexity in the multimedia stack.,0,0
data/train/6_86.mp3,"So in terms of architecture and design, Pipeware basically follows the same design as most of",0,0
data/train/6_87.mp3,"open source projects. So it's modular and it has plugins. So basically, a module in Pipeware is",0,0
data/train/6_88.mp3,"it's basically an API. So it's, for example, you have a module for Bluetooth, you have a module for",0,0
data/train/6_89.mp3,"Video4Linux, you have a module for Wayland, you have a module for Vulkan, you have a module for",0,0
data/train/6_90.mp3,"all these different low-level APIs, you have a module for ALSA. And then plugins are basically",0,0
data/train/6_91.mp3,"elements inside these modules that implement different functionalities. So for example, you",0,0
data/train/6_92.mp3,"have elements which are nodes that implement audio mixing, you have also format conversion,",0,0
data/train/6_93.mp3,like some video conversion or audio conversion. Then you have also resampling. So you basically,0,0
data/train/6_94.mp3,"have, you can write plugins for Pipeware that do any kind of different media processing.",0,0
data/train/6_95.mp3,So it's very similar to GStreamer. It's graph-based like GStreamer. Think of nodes as GStreamer,0,0
data/train/6_96.mp3,"elements and ports as GStreamer pads. And obviously, links are objects in Pipeware. It's not",0,0
data/train/6_97.mp3,"like GStreamer where you just link two elements. In Pipeware, you have to create the link and then",0,0
data/train/6_98.mp3,you have to tell what are the input and output nodes.,0,0
data/train/6_99.mp3,"Also, different to GStreamer, Pipeware is multi-process, as I said before.",0,0
data/train/6_100.mp3,"So the daemon is charged, it runs in the background and is charged to process most of the data.",0,0
data/train/6_101.mp3,"However, this is not 100% necessary. If you have, for example, a slow node,",0,0
data/train/6_102.mp3,clients have the ability to run nodes locally and avoid stalling the daemon in case a node is very,0,0
data/train/6_103.mp3,"slow. This is, for example, the case for Bluetooth nodes, which can be very slow,",0,0
data/train/6_104.mp3,especially when connecting and disconnecting a new Bluetooth device.,0,0
data/train/6_105.mp3,"And so, again, multi-process and also the external session manager that configures all",0,0
data/train/6_106.mp3,"the links and nodes. This runs also into its own process, you know, communicating",0,0
data/train/6_107.mp3,and they all communicate with each other with sockets.,0,0
data/train/6_108.mp3,"Then, finally, Pipeware is different from the remaining open source projects because",0,0
data/train/6_109.mp3,it only depends on its simple plugin API library. It doesn't depend on anything else. It doesn't,0,0
data/train/6_110.mp3,depend on Glib or any other famous open source library. And it does that because it really wants,0,0
data/train/6_111.mp3,to achieve low TPU usage and high performance. So this SPA library is extremely simple.,0,0
data/train/6_112.mp3,It's lightweight and it's used as a generic purpose multimedia library.,0,0
data/train/6_113.mp3,"With that library, that library has basically helpers to do",0,0
data/train/6_114.mp3,"audio conversion, audio mixing, audio resampling, and it also provides some",0,0
data/train/6_115.mp3,"structures, basic data structures, such as hash tables or lists or arrays and all of that",0,0
data/train/6_116.mp3,and basic video helper functionality. It's a mostly header-only C library with no dependencies.,0,0
data/train/6_117.mp3,"So thanks to that, the performance and efficiency of Pipeware is very impressive because,",0,0
data/train/6_118.mp3,"you know, it follows a static co-design approach. There's hardly any mallocs.",0,0
data/train/6_119.mp3,"If you grab for malloc in the Pipeware project, you are not going to see a lot of them.",0,0
data/train/6_120.mp3,"And it also uses modern Linux APIs, memfd and dma-buff to zero-copy buffers from device to",0,0
data/train/6_121.mp3,"memory. So thanks to eventfd and timerd for scheduling. So thanks to all of that,",0,0
data/train/6_122.mp3,the CPU usage of Pipeware is impressive and it's low latency real-time capable.,0,0
data/train/6_123.mp3,"In fact, if you have a look at some graphs and we compare, you know, Pipeware with PulseAudio,",0,0
data/train/6_124.mp3,"we can see that in the following hardware, an Intel Core i7,",0,0
data/train/6_125.mp3,"we can see on the left chart, so we have on the bottom, the x-axis is basically the buffer size",0,0
data/train/6_126.mp3,"and the y-axis is the CPU percentage. So we can see that for buffers, for big buffers of",0,0
data/train/6_127.mp3,"8192 samples, Pipeware and Jack, the performance, the CPU usage is mostly the same. Pipeware is",0,0
data/train/6_128.mp3,"0.001% of CPU usage, while PulseAudio is 0.005%. However, if we reduce the buffer size up to 64",0,0
data/train/6_129.mp3,"samples, we can see that the performance and the CPU usage with PulseAudio increases quite",0,0
data/train/6_130.mp3,"significantly, while Pipeware is only 0.03%. The graph on the right is the same, but it's an",0,0
data/train/6_131.mp3,"example of mixing two different files, mixing a 41.1 kilohertz file with a 48 kilohertz file.",0,0
data/train/6_132.mp3,"The performance is also very, very impressive. For buffers of 512 samples, which is about 10",0,0
data/train/6_133.mp3,"milliseconds, the CPU usage for Pipeware is only 0.007% and for PulseAudio is 0.2%.",0,0
data/train/6_134.mp3,"Now, if you compare Pipeware against Jack, the performance is mostly similar, especially for",0,0
data/train/6_135.mp3,"big buffers of 8000 samples. You can see on the graph on the left that it's the same, but again,",0,0
data/train/6_136.mp3,if you reduce the buffer sizes to achieve a low latency and you want to have a buffer size of 128,0,0
data/train/6_137.mp3,"samples, which is about 4 milliseconds, the performance in Pipeware is actually lower.",0,0
data/train/6_138.mp3,"The performance usage is lower than Jack. So, in Pipeware it's 0.017%,",0,0
data/train/6_139.mp3,"whereas in Jack it's 0.026%. As you reduce the buffer size, you can see that the performance",0,0
data/train/6_140.mp3,"is faster, it's better in Pipeware than Jack.",0,0
data/train/6_141.mp3,"Now, security, the way it works is the Session Manager grants permissions to applications in",0,0
data/train/6_142.mp3,Pipeware. The Session Manager basically can decide what application can have permissions to,0,0
data/train/6_143.mp3,"access a specific device or not, and the Pipeware nodes can be only visible for some applications.",0,0
data/train/6_144.mp3,The Session Manager can make visible... Applications can see only part of the whole,0,0
data/train/6_145.mp3,"node graph if they want. Now, there's three kinds of permissions. There's read permissions,",0,0
data/train/6_146.mp3,"write permissions, and there's executable permissions. The read permissions allows you",0,0
data/train/6_147.mp3,to see the node and capture data from it. The write permissions allows you to play,0,0
data/train/6_148.mp3,"buffers in a node, and the execute permissions allows you to configure",0,0
data/train/6_149.mp3,basically the node. It allows you to set up a format and all of that.,0,0
data/train/6_150.mp3,"The External Session Manager, Pipeware, it's not included in the Pipeware project. It's",0,0
data/train/6_151.mp3,"an external project. It's not maintained by the Pipeware developers, but it's the one",0,0
data/train/6_152.mp3,charged to create and configure the devices that emits then later the Pipeware nodes.,0,0
data/train/6_153.mp3,"It's also the one charged to set up nodes, format port, etc., create links based on its policy",0,0
data/train/6_154.mp3,"logic when a client connects, grant security and access control to clients,",0,0
data/train/6_155.mp3,and it's also launched by the Pipeware demo startup.,0,0
data/train/6_156.mp3,"So, the current start of Pipeware is version 0.3.15, released in November 2020.",0,0
data/train/6_157.mp3,There were some major improvements in this release.,0,0
data/train/6_158.mp3,"So, one of the biggest improvements was that Pipeware reused the Alzacor profile code from",0,0
data/train/6_159.mp3,"PulseAudio. So, now devices support all profiles, UCM and hardware mixes that PulseAudio implements.",0,0
data/train/6_160.mp3,"So, Pipeware basically, right now, the behavior, it's mostly the same as PulseAudio, and PulseAudio",0,0
data/train/6_161.mp3,"can be entirely replaced right now, tools such as the PulseAudio Volume Control works with Pipeware.",0,0
data/train/6_162.mp3,"Then, there was a lot of improvements in Bluetooth. So, the HTTP profile and HSP profile work now",0,0
data/train/6_163.mp3,with the basic codecs. They work for most devices. Support for MSBC codec is ongoing.,0,0
data/train/6_164.mp3,Most of the Java application works in Pipeware. The musical instrument digital interface works.,0,0
data/train/6_165.mp3,"Video capture from video for linux sources, they work very well. And Wayland screencasting",0,0
data/train/6_166.mp3,from Western GNOME Shell and Wayland Root is also supported. Who started the project?,0,0
data/train/6_167.mp3,"So, the project is started by Wintimons, which is a well-known old distro developer and ex-maintainer.",0,0
data/train/6_168.mp3,It's sponsored by Red Hat. It's embraced by PulseAudio developers because it's seen as the next,0,0
data/train/6_169.mp3,"generation of PulseAudio, and it's welcomed by ALS and JAC developers. Another interesting feature",0,0
data/train/6_170.mp3,"is that the license is MIT. Before moving on to the next part, which is explaining how Pipeware",0,0
data/train/6_171.mp3,"can be used for the automotive world, I'd like to mention some contributions I have made in the",0,0
data/train/6_172.mp3,"project. So, in Pipeware, there is a tool called Pipeware dot that generates a dot graph showing",0,0
data/train/6_173.mp3,"all the Pipeware objects and links, similar to the streamer, which is very handy for debugging.",0,0
data/train/6_174.mp3,"And most of the Bluetooth support, I did a lot of Bluetooth support, so I fixed several",0,0
data/train/6_175.mp3,"HTTP issues in some devices. I have support for HTTP sources using the SBC codec, and I",0,0
data/train/6_176.mp3,"add support for HSP and HFP profile using the CVSD codec. Okay, so that was the first part of the",0,0
data/train/6_177.mp3,"talk, and now I'm going to move on Pipeware in the automotive industry section. So, why Pipeware",0,0
data/train/6_178.mp3,suits perfectly the automotive world? The current problem is device handling in connected cars is,0,0
data/train/6_179.mp3,"complex, because cars, they have a lot of multimedia devices. You know, cars have a lot of",0,0
data/train/6_180.mp3,"cameras, they have a lot of speakers, and on top of that, all of them can work at the same time,",0,0
data/train/6_181.mp3,"and also different streams can play audio at the same time. So, for example, you can use the",0,0
data/train/6_182.mp3,"navigation at the same time as listening to music, and you can even have, for example,",0,0
data/train/6_183.mp3,"your Bluetooth paired to the car while you're speaking when driving. So, all this audio",0,0
data/train/6_184.mp3,"needs to be handled properly, and some, you might want to just play, for example,",0,0
data/train/6_185.mp3,"the navigation on the front speakers of the car, but not on the back speakers of the car,",0,0
data/train/6_186.mp3,"or maybe you want to use the camera, the back camera when you are going backwards and not when",0,0
data/train/6_187.mp3,"you're going forward. So, again, plenty of devices, plenty of speakers, plenty of streams,",0,0
data/train/6_188.mp3,how do we handle that properly? It's very hard to do that with pulse audio,0,0
data/train/6_189.mp3,"without hacking into it. So, the solution is Pipeware with a flexible external session manager",0,0
data/train/6_190.mp3,"that allows you to do custom policy logic, custom hardware pipelines,",0,0
data/train/6_191.mp3,"hardware, control abstraction, and security. Now, since Pipeware doesn't include a proper",0,0
data/train/6_192.mp3,"and extensible session manager, here at Collabora, we have decided to create the first",0,0
data/train/6_193.mp3,external and extensible session manager for Pipeware called White Plumber. We decided to,0,0
data/train/6_194.mp3,"do this because we also had a client, we had an automotive Linux client who wanted to adopt",0,0
data/train/6_195.mp3,"Pipeware as the core of their audio system into their system, and we had to basically develop a",0,0
data/train/6_196.mp3,"session manager for them. So, it was already focused on embedded only, but a lot of work has",0,0
data/train/6_197.mp3,"been done, and now it's a generic and fully-featured session manager for both embedded and",0,0
data/train/6_198.mp3,desktop. Another thing to notice is that White Plumber is based on GObject to support writing,0,0
data/train/6_199.mp3,"bindings in other languages, such as Rust, Python, and Lua, because at some point we want users to",0,0
data/train/6_200.mp3,have an even higher API to basically control Pipeware. We want users to control Pipeware,0,0
data/train/6_201.mp3,"using, for example, Python script. So, basically, White Plumber, since it's a higher-level API,",0,0
data/train/6_202.mp3,"it introduces three new objects. So, it introduces the concept of an endpoint. So,",0,0
data/train/6_203.mp3,an endpoint is basically a set of nodes that follows a similar specific logic.,0,0
data/train/6_204.mp3,"This is very useful for devices that expose a lot of nodes, but a lot of them need to be treated",0,0
data/train/6_205.mp3,"in the same way. So, for example, you could have a Bluetooth endpoint that has one node for the",0,0
data/train/6_206.mp3,"HTTP profile and one for the HSP profile, and the application, when they connect to it,",0,0
data/train/6_207.mp3,they don't need to worry about switching different profiles in the Bluetooth device.,0,0
data/train/6_208.mp3,They just need to connect to the specific endpoint stream.,0,0
data/train/6_209.mp3,And this is where the endpoint stream comes in. An endpoint stream is essentially a connection,0,0
data/train/6_210.mp3,"point for an endpoint. It's like a port for a node. It's like a port for an endpoint, sorry.",0,0
data/train/6_211.mp3,"And finally, we have also the concept of sessions, which is a set of endpoints,",0,0
data/train/6_212.mp3,and this is also important because it makes it easy to grant permissions to just a group of,0,0
data/train/6_213.mp3,"endpoints. It's not instead of just one by one. So, at the moment, White Plumber creates a video",0,0
data/train/6_214.mp3,"session and an audio session, and it basically assigns a session to an endpoint. So, in this",0,0
data/train/6_215.mp3,"graph, we can see an example of two software DSP endpoints. This is, for example, when running",0,0
data/train/6_216.mp3,"White Plumber in a laptop. So, in a laptop, we have the same, we have the same, we use the same",0,0
data/train/6_217.mp3,"audio device for both music and notification. So, the endpoint basically wraps the same node",0,0
data/train/6_218.mp3,"and adds two conversions for different volume controls, one for music, one for notifications,",0,0
data/train/6_219.mp3,"and the media player basically always uses the music stream from that endpoint, whereas, for",0,0
data/train/6_220.mp3,"example, the desktop manager could use a notification point to notify the user when a new",0,0
data/train/6_221.mp3,"email comes in. However, you know, in a car, you know, we might have a different hardware device",0,0
data/train/6_222.mp3,for the notifications. We might have different hardware device depending on the stream. We,0,0
data/train/6_223.mp3,"might have a hardware device for navigation and one for notifications. So, in this case,",0,0
data/train/6_224.mp3,the endpoint would wrap those two nodes into one endpoint and would link the music stream with the,0,0
data/train/6_225.mp3,also sub device and the notification with the proper notification also sub device.,0,0
data/train/6_226.mp3,"But basically, it hides the complexity of dealing with these different nodes and the",0,0
data/train/6_227.mp3,policy logic would be the same for both desktop and embedded and automotive.,0,0
data/train/6_228.mp3,"So, the design of White Plumber, it's essentially a library. So, White Plumber is essentially a",0,0
data/train/6_229.mp3,library that allows you to write in a much easier way other pipe or session managers.,0,0
data/train/6_230.mp3,And it also provides an executable that basically executes load modules written,0,0
data/train/6_231.mp3,"using that White Plumber library that have, you know, all the different functionality.",0,0
data/train/6_232.mp3,"So, users can just use the library to write the White Plumber library to write their own pipe",0,0
data/train/6_233.mp3,or they can use the already existing modules to do pipe or logic.,0,0
data/train/6_234.mp3,"An example of White Plumber modules is the monitor module,",0,0
data/train/6_235.mp3,which basically monitor devices and creates nodes when enabled. We have also the White,0,0
data/train/6_236.mp3,Plumber client permission modules that grant permissions to clients when connected.,0,0
data/train/6_237.mp3,We have the configuration endpoint module that basically creates endpoints based on,0,0
data/train/6_238.mp3,configuration files. And we have the config policy module that basically is the one charged to create,0,0
data/train/6_239.mp3,links between endpoints based on configuration files. But users can decide whether they want,0,0
data/train/6_240.mp3,to load these modules and implement their own modules.,0,0
data/train/6_241.mp3,"In the future, we plan to add bindings in order to have a higher level API, as I said before.",0,0
data/train/6_242.mp3,"And to avoid using, obviously, the low level pipe or API and objects. And we also want to,",0,0
data/train/6_243.mp3,"because at the moment, the modules are reading configuration files, but we would like them to",0,0
data/train/6_244.mp3,read also scripting files such as Lua to have more flexibility when writing policy logic,0,0
data/train/6_245.mp3,or endpoint creation logic.,0,0
data/train/6_246.mp3,The current status of White Plumber is version 0.3.0.,0,0
data/train/6_247.mp3,"We started, the first version was 0.1.0, which was released last year in July. And it was used",0,0
data/train/6_248.mp3,in AGL Happy Hollywood 8.0 branch. Then version 0.2 was released last December 2019.,0,0
data/train/6_249.mp3,And it was used both in AGL Happy Hollywood and Ichi Icefish. Version 0.3 was released in June,0,0
data/train/6_250.mp3,"this year, which was the first release with version with support for desktop. And we probably",0,0
data/train/6_251.mp3,are going to do a release at the end of this year or beginning next year,0,0
data/train/6_252.mp3,"with API improvements, script with scripting bindings. And we want also to stabilize the API,",0,0
data/train/6_253.mp3,"because at the moment, it's always changing, because we are trying to figure out the best",0,0
data/train/6_254.mp3,"cases. So, again, future release will support bindings, improve the API. It will improve",0,0
data/train/6_255.mp3,also the documentation and it will add more unit tests and examples so that people can contribute,0,0
data/train/6_256.mp3,"to it. So, who started this project? The owner of the project is George.",0,0
data/train/6_257.mp3,He's working at Collabora too. The project Wireplumber is sponsored by Collabora.,0,0
data/train/6_258.mp3,It's welcomed by Piper developers. You've got the Git repository and documentation,0,0
data/train/6_259.mp3,there if you want to know. And the license is the same as Piper. It's MIT.,0,0
data/train/6_260.mp3,And that's it for this talk. I'm going to show you now a demonstration,0,0
data/train/6_261.mp3,so you can have a better idea of how all of this works. It's a demonstration I pre-recorded.,0,0
data/train/6_262.mp3,It's going to basically show the users of both Piper and Wireplumber projects.,0,0
data/train/6_263.mp3,"Okay. So, welcome back. And so, yeah, in this demonstration, what I want to show you is how",0,0
data/train/6_264.mp3,to use Piper and Wireplumber on your desktop. Which can be quite interesting for some of you,0,0
data/train/6_265.mp3,if you want to play a little bit with this technology and also have a better feeling,0,0
data/train/6_266.mp3,"of how an audio server works. So, as you can see here, I have on my left terminal the Piper project",0,0
data/train/6_267.mp3,already configured and built. And the same on the right terminal with Wireplumber.,0,0
data/train/6_268.mp3,"So, I'm going to basically run first Piper here on the left and then Wireplumber. But before doing",0,0
data/train/6_269.mp3,"that, I want to open a couple more terminals. Because I'm going to use these terminals to",0,0
data/train/6_270.mp3,"run the clients. Now, by default, if I just run an audio client here, such as end player,",0,0
data/train/6_271.mp3,it's going to connect to the default audio server of my distro. Which is Pulse Audio. And,0,0
data/train/6_272.mp3,"we don't want to do that. We want them to connect to Piper. So, we are going to run make shell",0,0
data/train/6_273.mp3,"that basically sends a bunch of environment variables. Such as, you know, the path,",0,0
data/train/6_274.mp3,"which allows you to use the Piper tools you just already built. Or the LD library path,",0,0
data/train/6_275.mp3,which points to the build directory of the Piper we just built and we are going to run.,0,0
data/train/6_276.mp3,"So, make shell allows us to run clients within this shell. And they will automatically connect",0,0
data/train/6_277.mp3,"to Piper. Which makes it very easy to test Piper. So, I'm going to open a bunch more tabs. Because",0,0
data/train/6_278.mp3,we are going to use several clients. And we're going to run make shell on all of them.,0,0
data/train/6_279.mp3,I think five should be enough.,0,0
data/train/6_280.mp3,"So, yeah. Now, once everything is ready, we are going to run Piper with make run.",0,0
data/train/6_281.mp3,"And we are going to run Piper with the log enabled. So, you can see it's basically doing",0,0
data/train/6_282.mp3,"some stuff. Now, you're going to also see some warning messages, such as device being busy.",0,0
data/train/6_283.mp3,"And this is because I'm recording using my microphone. So, that device is used by the",0,0
data/train/6_284.mp3,"screen recorder. But it should be fine for what we are going to do. So, don't worry too much about",0,0
data/train/6_285.mp3,"that. So, everything is running. This is a log of Piper. And now we're going to try to play some",0,0
data/train/6_286.mp3,"audio with mPlayer. For example, this one. Now, mPlayer, by default, uses the Pulse audio API.",0,0
data/train/6_287.mp3,"So, when I run this, what it's going to do is it's going to use the",0,0
data/train/6_288.mp3,"lib Pulse compatibility API of Piper. And that library internally, it's going to tell Piper",0,0
data/train/6_289.mp3,that a new client comes in. And it's going to notify the session manager. And the session,0,0
data/train/6_290.mp3,"manager is going to create the notes and link the notes based on the custom policy. So, I run it.",0,0
data/train/6_291.mp3,And you can hear that music is playing. We can also see some warnings of the Pulse audio,0,0
data/train/6_292.mp3,"compatibility API library. Not all features are implemented yet. But, yeah, we can hear music.",0,0
data/train/6_293.mp3,"Now, I'm going to use the Pipeware dot tool to generate a dot graph similar to the streamer. And",0,0
data/train/6_294.mp3,we can see that the notes are basically connected. It's very easy to use. You just do Piper dot and,0,0
data/train/6_295.mp3,then the name of the file where you want the graph to be written. And then we can view the,0,0
data/train/6_296.mp3,"graph with tools such as X dot. So, yeah. We can see this here. So, the green squares here",0,0
data/train/6_297.mp3,are notes. The red squares are the output ports. And the purple squares are the input ports. And,0,0
data/train/6_298.mp3,"the blue squares are actually the links created by the RIPE number. So, this also playback node",0,0
data/train/6_299.mp3,is actually the end player client that has two channels. The left channel and the right channel.,0,0
data/train/6_300.mp3,And it's connected to a converter. And that converter is connected to the default,0,0
data/train/6_301.mp3,also node. Which is my speakers on my laptop. We can actually view more information if we run it,0,0
data/train/6_302.mp3,with the detail option. And we can see more properties. It makes the graph much bigger.,0,0
data/train/6_303.mp3,"So, yeah. We can see here, for example,",0,0
data/train/6_304.mp3,that end player is this node. And we can see that the also device that it's using is the hardware,0,0
data/train/6_305.mp3,"zero. So, yeah. We can now do more cool stuff. For example, we can use the pulse audio volume",0,0
data/train/6_306.mp3,control. And we can see that it's monitoring all the audio being played on my laptop.,0,0
data/train/6_307.mp3,"And we can also change the volume, for example.",0,0
data/train/6_308.mp3,And we can see some warnings here because not all the compatibility APIs are implemented yet.,0,0
data/train/6_309.mp3,"But, yeah. It's working nicely. And we can see then now here if we run the Piper tool.",0,0
data/train/6_310.mp3,"That it's created more links. Now, all the input nodes, they have a monitor port. And basically,",0,0
data/train/6_311.mp3,the volume control uses those monitor ports and creates these nodes to actually,0,0
data/train/6_312.mp3,"monitor the audio coming out. So, that's why we see this here.",0,0
data/train/6_313.mp3,"So, yeah. Now we can do one more thing, which is running Carla. Carla is an audio plugin host.",0,0
data/train/6_314.mp3,"And here in the patch bay section, we can see all the audio stuff that is connected.",0,0
data/train/6_315.mp3,"So, end player is this also playback node. And we can see that two channels are connected.",0,0
data/train/6_316.mp3,"We can disconnect the left channel, for example. And now only the right channel is playing on my",0,0
data/train/6_317.mp3,"speaker. So, if we run the tool again, we can see that, for example, only the right channel",0,0
data/train/6_318.mp3,"is connected. And, for example, if I can even connect the left channel to the right speaker.",0,0
data/train/6_319.mp3,And we can see here that the player both channels are connected to the left.,0,0
data/train/6_320.mp3,"Sorry, to the right channel of the audio convert. We can leave that as it is.",0,0
data/train/6_321.mp3,We can leave that as it is. And it's back to normal.,0,0
data/train/6_322.mp3,"So, yeah. That's all for this demonstration. I hope you enjoyed. Thanks for watching. And",0,0
data/train/6_323.mp3,see you soon. And that's it. Thank you for watching. And please let me know if you have,0,0
data/train/6_324.mp3,any questions. I will be very happy to reply as many as I can. Bye.,0,0
