file_name,sentence,verified,checked
data/train/2_0.mp3,"Okay, so creating Debian-based embedded systems using debos.",0,1
data/train/2_1.mp3,My name's Chris and I'm an engineer at Collabora.,0,0
data/train/2_2.mp3,I work on creating custom distributions for our clients.,0,0
data/train/2_3.mp3,"Usually these custom distros end up running on embedded platforms, embedded little boards that customers have bought like Raspberry Pis, those sorts of development boards, but sometimes they end up on customer-specific hardware.",0,0
data/train/2_4.mp3,Occasionally they end up running in the cloud on a virtual machine.,0,0
data/train/2_5.mp3,"So really, the images that I create end up running kind of everywhere, really.",0,0
data/train/2_6.mp3,I work on continuous integration and packaging of the customer software.,0,0
data/train/2_7.mp3,"So basically, customers normally don't care so much about packaging their software, they just want their software to work.",0,0
data/train/2_8.mp3,So we take the hassle out of that and package the software for them.,0,0
data/train/2_9.mp3,We make sure that their devices can be upgraded over the air.,0,0
data/train/2_10.mp3,"We also implement fail-safes so that if the over-the-air upgrade fails, the power's taken out of the power jack or the internet connection's gone, we mitigate these sort of problems.",0,0
data/train/2_11.mp3,"Also, I work on the tooling to make all of these things happen.",0,0
data/train/2_12.mp3,"So most recently, I've been working on debos and fake machine.",0,1
data/train/2_13.mp3,"So hopefully, this presentation is going to give you a little bit of insight on what I've been working on over the past year or so.",0,0
data/train/2_14.mp3,"I'm also learning some Rust, which is proven to be quite useful for some of my daily tasks.",0,0
data/train/2_15.mp3,Small scripts I've been writing in Python and Go in the past are now being written in Rust.,0,0
data/train/2_16.mp3,Slowly but surely I'm getting there and the future is bright.,0,0
data/train/2_17.mp3,So today I'm going to talk to you about what actually debos is and how it compares to other tools.,0,1
data/train/2_18.mp3,I'm also going to go through how to use it and the future plans that we've got for the tooling.,0,0
data/train/2_19.mp3,Hopefully we'll get a chance for a question and answer session at the end but,0,0
data/train/2_20.mp3,Please do download the slides and copy my email address and feel free to email me if you have any questions that you feel weren't covered today.,0,0
data/train/2_21.mp3,I'll do my best to get back to you.,0,0
data/train/2_22.mp3,"Also, I would suggest downloading the slides so you can get access to some of the blue links that I've dotted around the presentation.",0,0
data/train/2_23.mp3,These should give you a little bit more context in places.,0,0
data/train/2_24.mp3,"So the link on this slide will show you the introduction to YAML, yet another markup language, which is extensively used throughout debos.",0,1
data/train/2_25.mp3,"And also lots of other continuous integration systems like GitHub Actions, GitLab CI, these all use YAML.",0,0
data/train/2_26.mp3,So I'd highly recommend having a look.,0,0
data/train/2_27.mp3,YAML is a fairly basic markup language.,0,0
data/train/2_28.mp3,You should be able to follow along with the examples and get a feel for how the markup language works.,0,0
data/train/2_29.mp3,But there are some details which the tutorial goes into,0,0
data/train/2_30.mp3,"quite well, so I'd recommend checking that link out.",0,0
data/train/2_31.mp3,So first I'd like to explain what a GNU Linux distribution is.,0,0
data/train/2_32.mp3,In my opinion it's a collection of software packages developed by like-minded developers,0,0
data/train/2_33.mp3,"Um, these packages follow a set of guidelines to meet this distribution.",0,0
data/train/2_34.mp3,"Um, so.",0,0
data/train/2_35.mp3,All the packages end up working together quite well.,0,0
data/train/2_36.mp3,"Uh, you don't end up with too many brokerages, hopefully, and the developers end up fixing bugs in the distribution and passing the bugs upstream and releasing new versions of the upstream software in the distribution.",0,0
data/train/2_37.mp3,Um.,0,0
data/train/2_38.mp3,So each one of the distributions have different goals.,0,0
data/train/2_39.mp3,So Debian is a distribution which uses apt for its package management and dpkg.,0,0
data/train/2_40.mp3,Red Hat use rpm and yum for their package management.,0,0
data/train/2_41.mp3,So there are lots of choices and design decisions which,0,0
data/train/2_42.mp3,"each distribution makes, and everyone has their own preference.",0,0
data/train/2_43.mp3,"I mean, my preference personally is Debian.",0,0
data/train/2_44.mp3,"I've been working with Debian since the 2000s, so I am very familiar with Debian.",0,0
data/train/2_45.mp3,"But at the same time, I don't really know a lot about Red Hat or Fedora, so I would suggest",0,0
data/train/2_46.mp3,"asking someone else about Red Hat Fedora, not me.",0,1
data/train/2_47.mp3,But I think one thing that we can all agree on is the usual trend at the moment is for embedded targets to run a custom image generated by something like Yocto or Buildroot rather than run a full distribution.,0,0
data/train/2_48.mp3,"Hopefully with tools like debos, we can change that and let distributions run on embedded targets.",0,1
data/train/2_49.mp3,So why might you want to create your own distribution?,0,0
data/train/2_50.mp3,So your project might have different targets.,0,0
data/train/2_51.mp3,So your project might want to run on embedded board or multiple types of embedded board.,0,0
data/train/2_52.mp3,"It might want to run on a PC or it might want to run in the cloud, or it may even want to run a combination of those.",0,0
data/train/2_53.mp3,"And usually you can buy, for instance, hardware development kits.",0,0
data/train/2_54.mp3,These are supplied with a general purpose distribution that the,0,0
data/train/2_55.mp3,the developers have made for that development kit.,0,0
data/train/2_56.mp3,"And usually these are based on Debian or Ubuntu, and they're quite bad.",0,0
data/train/2_57.mp3,"I mean, they've got a lot of unnecessary, insecure, and outdated packages, and they're incompatible with updating.",0,0
data/train/2_58.mp3,And they've done a lot of hacks for that platform as well.,0,0
data/train/2_59.mp3,So your own distribution would solve these issues quite nicely.,0,0
data/train/2_60.mp3,"From scratch, it's a lot of hard work to maintain a distribution.",0,0
data/train/2_61.mp3,So my suggestion is there's no need to reinvent the wheel and you should rebase or base your distribution on a proven technology like Debian.,0,0
data/train/2_62.mp3,"So Yocto and Buildroot, usually the images are only for embedded platforms.",0,0
data/train/2_63.mp3,"I had our Yocto expert shout at me last time I said this, no, no, no, you can run Yocto images in the cloud now.",0,0
data/train/2_64.mp3,But I would likely say that it's a lot harder than to have a lot of specific knowledge of how to run these images in the cloud.,0,0
data/train/2_65.mp3,"They create a nice custom distribution or a custom image, but it can become a maintenance nightmare when you want to update software or create packages for your own software.",0,0
data/train/2_66.mp3,"All the packages are compiled on your own machine, which some may say is a benefit, but I personally think it is a negative.",0,0
data/train/2_67.mp3,Having to recompile a window manager every time I want to build a new image for different platforms is kind of,0,0
data/train/2_68.mp3,"not a benefit in my view, um, there's a high learning curve.",0,0
data/train/2_69.mp3,So my suggestion is why make things hard for yourself?,0,0
data/train/2_70.mp3,"Um, my suggestion is to use Debian as a base for your, for your image.",0,0
data/train/2_71.mp3,"So Debian is both traditionally seen as a desktop operating system, but recent years, a lot of effort has gone into enabling embedded targets and lots of different embedded targets.",0,0
data/train/2_72.mp3,"I think this mainly started with the Raspberry Pi, um, that really drove the embedded sort of world.",0,0
data/train/2_73.mp3,into some of the Debian developers.,0,0
data/train/2_74.mp3,"Debian was released in 1993, and it's widely used, and there are lots and lots of volunteers who shape Debian, inform Debian developers, Debian maintainers, and they follow a social contract called the Debian Free Software Guidelines, and they have social contracts as well, which basically means that all developers work to a common set of",0,0
data/train/2_75.mp3,rules and they're free to change these rules so long as the changes make sense.,0,0
data/train/2_76.mp3,I think that's a great way of working.,0,0
data/train/2_77.mp3,It's really community spirit.,0,0
data/train/2_78.mp3,You're not being forced into doing things that you don't want to do by large corporations.,0,0
data/train/2_79.mp3,It's all owned by the community.,0,0
data/train/2_80.mp3,So I think that's really nice.,0,0
data/train/2_81.mp3,These developers,0,0
data/train/2_82.mp3,"have written over 50,000 packages and libraries and you can easily install or upgrade these using apps.",0,0
data/train/2_83.mp3,The community is great.,0,0
data/train/2_84.mp3,Unfortunately these mailing lists but if you're used to using mailing lists then this is really not a problem.,0,0
data/train/2_85.mp3,There are lots of tutorials on the internet and it's fairly easy to get started.,0,0
data/train/2_86.mp3,"We have stable and testing distributions as well as unstable, which have bleeding edge packages.",0,0
data/train/2_87.mp3,"Timely security updates go into the stable release and unstable, or seed as it's known, usually gets the latest bleeding edge packages.",0,0
data/train/2_88.mp3,"And as I've already said, no one company leads the development or the direction of the project.",0,0
data/train/2_89.mp3,The developers themselves lead the project.,0,0
data/train/2_90.mp3,which in my view is very important.,0,0
data/train/2_91.mp3,"So using Debian as a base in summary lets you concentrate on the most important part of the project, your application.",0,0
data/train/2_92.mp3,You haven't got to worry about the base operating system behind it and all the things that happen there.,0,0
data/train/2_93.mp3,So some disadvantages with Debian.,0,0
data/train/2_94.mp3,Debian only caters for systemd.,0,0
data/train/2_95.mp3,This is changing.,0,0
data/train/2_96.mp3,there are some changes in force to allow for other system managers.,0,0
data/train/2_97.mp3,But I don't see this as a big disadvantage personally.,0,0
data/train/2_98.mp3,Most of our projects use systemd and use systemd very well.,0,0
data/train/2_99.mp3,"The other thing is Debian packages are compiled with glibc, so",0,1
data/train/2_100.mp3,"This can be a problem for very small embedded targets, but typically most projects now have got a fair amount of RAM and a fairly big CPU.",0,0
data/train/2_101.mp3,"I mean, it doesn't make a lot of sense in some cases to have anything smaller than a dual core sort of embedded processor.",0,0
data/train/2_102.mp3,So I would suggest that these two disadvantages don't really matter so much these days.,0,0
data/train/2_103.mp3,"Debian was designed with desktop or server use in mind, but as I said originally,",0,0
data/train/2_104.mp3,"It is coming onto embedded targets, but it needs a little bit more work than if you were to install it on the desktop.",0,0
data/train/2_105.mp3,"So if you're installing on the desktop, you can easily just plug in a USB with Debian installed on the USB and install that to your hard drive quite easily.",0,0
data/train/2_106.mp3,"With embedded platforms, typically you will run an image on an SD card.",0,0
data/train/2_107.mp3,The Debian installer typically won't work for a custom distribution.,0,0
data/train/2_108.mp3,"So there's some challenges there, but.",0,0
data/train/2_109.mp3,debos actually helps with installing the system on an image so hopefully by the end of this talk you will understand a little bit more about that.,0,1
data/train/2_110.mp3,Debian are a little bit conservative of new technologies but again this isn't so bad.,0,0
data/train/2_111.mp3,I think that this is quite a good thing to be conservative of new things because sometimes new things aren't always good.,0,0
data/train/2_112.mp3,"There's limited enterprise support, but there is paid support by companies like Collabora to help customers with their projects.",0,1
data/train/2_113.mp3,"And Debian also has quite a slow release cycle, so stable upgrades happen every kind of two years, but that's not always a bad thing.",0,0
data/train/2_114.mp3,"And as I've already said, there are fresh packages in Unstable, which suits most users.",0,0
data/train/2_115.mp3,So how would you create a custom Debian image?,0,0
data/train/2_116.mp3,So normally when you want to create a custom Debian image you would create an image using DD.,0,1
data/train/2_117.mp3,You'd basically flash the image with all zeros to begin with on your local hard drive.,0,0
data/train/2_118.mp3,You'd insert a partition table using Fdisk and format these partitions.,0,1
data/train/2_119.mp3,You'd mount the partitions on a loop device and then you can chroot into the mounted image and,0,1
data/train/2_120.mp3,"Debootstrap a basic Debian file system, install packages using apt, and then you can basically work on it as if it was a normal system on your hard drive by setting the hostname, setting up user accounts, configuration files.",0,0
data/train/2_121.mp3,"And then at the end of all of that, you want to unmount the image, clean up the loop devices, compress your image, save the build, logs.",0,0
data/train/2_122.mp3,"And then hopefully after that, you've got a nice image.",0,0
data/train/2_123.mp3,It's nice until the whole lot breaks and,0,0
data/train/2_124.mp3,"Also, you have these problems where it works on your machine, but it doesn't work in the continuous integration machine, or it doesn't work on other developers' machines.",0,0
data/train/2_125.mp3,There are lots of issues with this kind of script-based setup.,0,0
data/train/2_126.mp3,There are lots of tools out there already that follow this kind of routine.,0,0
data/train/2_127.mp3,"There's a presentation called The Many Methods to Build a Debian Image by Riku, which summarizes the most popular tools.",0,0
data/train/2_128.mp3,Usually these other tools serve a very specific purpose.,0,0
data/train/2_129.mp3,"So originally, when I first started looking at Debian systems, I was looking at a tool called Spindle, which basically created Raspberry Pi images, but the images were very specific just for Raspberry Pi.",0,0
data/train/2_130.mp3,"So at the time I was looking at creating a BeagleBone Black image, and I couldn't create an image using Spindle for that without a lot of hacking.",0,0
data/train/2_131.mp3,So these other tools also,0,0
data/train/2_132.mp3,"have random failures, which we call it.",0,0
data/train/2_133.mp3,"debos is inherently a lot more robust against these failures, and it's also a lot more flexible than these other tools that serve very specific purposes.",0,1
data/train/2_134.mp3,"debos generates your custom image from one configuration file, which can be stored in version control, which is quite nice.",0,1
data/train/2_135.mp3,We also use GitLab continuous integration to build images as soon as they're pushed into the virtual control.,0,0
data/train/2_136.mp3,I'm going to go into a little bit of that in this presentation as well.,0,0
data/train/2_137.mp3,"Collabora are constantly evolving and improving debos and Apertis, which is a project by Collabora and Bosch, is continuously evolving debos as well because",0,1
data/train/2_138.mp3,Apertis use debos to generate the images for their boards.,0,1
data/train/2_139.mp3,So that's very good.,0,0
data/train/2_140.mp3,"Basically, I think you're going to get started with debos quicker than some of these other tools as well.",0,1
data/train/2_141.mp3,So the solution to all of these problems is debos.,0,1
data/train/2_142.mp3,"Basically, it uses a library called FakeMachine to create a virtual machine on your computer.",0,0
data/train/2_143.mp3,"Disks are attached to the virtual machine, so we don't use loop devices.",0,0
data/train/2_144.mp3,"And that's very good because these loop devices, as we've discussed, are very fragile.",0,0
data/train/2_145.mp3,We have a recipe file which contains actions or the steps to create your image.,0,0
data/train/2_146.mp3,"And these recipes are translated into commands, which are right inside the VM in this clean environment.",0,0
data/train/2_147.mp3,And the recipe actions abstract the changes and the configuration files and the commands.,0,0
data/train/2_148.mp3,So basically you don't have to write so many commands in your build script.,0,0
data/train/2_149.mp3,"When there's no action already created, you can just run a shell command or a script inside the fake machine, which then you can change route into the disk image and do any changes you want there.",0,0
data/train/2_150.mp3,Easy cleanup.,0,0
data/train/2_151.mp3,"If anything goes wrong, you just kill the virtual machine.",0,0
data/train/2_152.mp3,And this is quite nice because it doesn't break your host.,0,0
data/train/2_153.mp3,"Everything's reproducible on your computer as well as in the CI system, which all of these things I think make debos quite a nice solution for building your own images.",0,1
data/train/2_154.mp3,So you've got lots of people using debos.,0,1
data/train/2_155.mp3,"We've got Apertis, KernelCI, Redaxor, the Mobium project, Plasma Mobile.",0,0
data/train/2_156.mp3,uh gemion and also reproducible builds use debos this is just a short list here i'm not going to go into detail of all of them because i don't think we've got the time today um but please feel free to check these projects out they're very cool projects um,0,1
data/train/2_157.mp3,So debos is a tool written in Go.,0,1
data/train/2_158.mp3,You don't need to know Go to run debos.,0,1
data/train/2_159.mp3,You only need to know Go if you want to add features to debos.,0,1
data/train/2_160.mp3,"There is FakeMachine, which is a separate library and a standalone tool which Collabora have generated, which creates virtual machines.",0,1
data/train/2_161.mp3,Packages for both FakeMachine and debos are in Debian stable.,0,1
data/train/2_162.mp3,We try to update these packages fairly quickly as well when new features are added.,0,0
data/train/2_163.mp3,"It's also available as a docker container, so you can run it pretty much anywhere.",0,0
data/train/2_164.mp3,"We use a docker container to run in the GitLab continuous integration, and also you can install from source and other operating systems fairly easily too.",0,0
data/train/2_165.mp3,So a debos recipe is a YAML file which defines the steps to create your image.,0,1
data/train/2_166.mp3,"As we've said already, it's simple and can be version controlled.",0,0
data/train/2_167.mp3,"And the recipe consists of a header, which has got the metadata, for instance, the image architecture, and an array of actions which are ran sequentially.",0,0
data/train/2_168.mp3,Each of these actions has their own properties.,0,0
data/train/2_169.mp3,"So the YAML file has comments inside of it, or you can add comments if you so wish.",0,0
data/train/2_170.mp3,I'd highly recommend adding comments to all code that you write.,0,0
data/train/2_171.mp3,"For me, my memory is like a sieve, so if I don't write comments in three weeks time, I won't know what the point of the comment of the code was.",0,0
data/train/2_172.mp3,"All of the recipes are pre-processed through the Go templating engine, which allows you to have variables, if-else statements, and you can also include recipes in other recipes, which is all very nice.",0,0
data/train/2_173.mp3,So enough talk.,0,0
data/train/2_174.mp3,Here's a simple example.,0,0
data/train/2_175.mp3,"Again, please copy these slides and copy the example.",0,0
data/train/2_176.mp3,"This example, as the comment says, creates a tarball of a simple Debian operating system.",0,0
data/train/2_177.mp3,"So basically, you can run this on Debian using the steps I've given here.",0,0
data/train/2_178.mp3,You basically want to install Docker first and then run the Docker container.,0,0
data/train/2_179.mp3,And then you get this output here of each,0,0
data/train/2_180.mp3,action inside the recipe and at the end you get a tarball with the contents of a operating system.,0,0
data/train/2_181.mp3,So here again I've shown you the original recipe on the left hand side and the output on the right hand side.,0,0
data/train/2_182.mp3,You can see how each action relates to some commands.,0,0
data/train/2_183.mp3,I've had to remove the command output because it doesn't actually fit on the screen but hopefully that gives you a quick overview of how the actions relate to the output.,0,0
data/train/2_184.mp3,You can also run this in GitLab CI using the Docker image.,0,0
data/train/2_185.mp3,"So as you can see here, it's not much.",0,0
data/train/2_186.mp3,It's about 12 lines of code to actually run this in GitLab CI.,0,0
data/train/2_187.mp3,And GitLab CI is very helpful because it shows you whether things pass or fail in the browser.,0,0
data/train/2_188.mp3,Everyone on your team can see it.,0,0
data/train/2_189.mp3,You can set jobs up to run our schedule so nightly.,0,0
data/train/2_190.mp3,You can have email notifications when things don't work.,0,0
data/train/2_191.mp3,It's all very nice.,0,0
data/train/2_192.mp3,"So then, debos has a bunch of actions which you can use to create your operating system.",0,1
data/train/2_193.mp3,"So we've got the debootstrap action, which sets a basic Debian system up in the file system.",0,0
data/train/2_194.mp3,"We've got the apt action, which installs packages.",0,0
data/train/2_195.mp3,"We've got the pack and unpack action, which pack and unpack tarballs.",0,0
data/train/2_196.mp3,"Image partition uses some tools on the operating system to create an image partition table, format file systems.",0,0
data/train/2_197.mp3,"And it's very comprehensive, the partition layouts that you can create with this tool.",0,0
data/train/2_198.mp3,"I actually, as a tip, use debos Recipes, even not when creating Debian systems.",0,1
data/train/2_199.mp3,So it's very flexible in that regard.,0,0
data/train/2_200.mp3,You can use debos to generate a system or an image which contains virtually anything in it.,0,1
data/train/2_201.mp3,"We've got file system deploy, which actually copies root file systems from a temporary directory into an image.",0,0
data/train/2_202.mp3,"We've got overlay, which copy files from your host machine into the container and inside the target file system.",0,0
data/train/2_203.mp3,"We've got the raw action, which writes images to a partition.",0,0
data/train/2_204.mp3,So you can write things like bootloaders or pre-prepared images.,0,0
data/train/2_205.mp3,So I use the raw action as a tip to copy vendor provided root file systems into an image and then modify the image that they've given.,0,0
data/train/2_206.mp3,The run action allows you to run scripts or commands inside the virtual machine or inside the actual image that you're creating.,0,0
data/train/2_207.mp3,Then here is an example of variables so you can,0,0
data/train/2_208.mp3,define variables and you can use the variables inside the recipe.,0,0
data/train/2_209.mp3,You can pass the values to these variables on the command line and you can also do things like printf.,0,0
data/train/2_210.mp3,There's an example there where we generate the file name based on two other variables.,0,0
data/train/2_211.mp3,So that's quite nice.,0,0
data/train/2_212.mp3,You've also got some defaults at the top.,0,0
data/train/2_213.mp3,So the default are those two values.,0,0
data/train/2_214.mp3,"Also, the scripting allows you to do if else, so you can pass in, in this example here, you can install different packages based on what architecture you're running, which is quite useful.",0,0
data/train/2_215.mp3,"You can also run recipes inside recipes using the action, using the recipe action, sorry.",0,0
data/train/2_216.mp3,You can also pass variables into these other actions and,0,0
data/train/2_217.mp3,"the command, the variables from the command line is also passed in.",0,0
data/train/2_218.mp3,"So that allows you to, to abstract reusable things into a different action, which is into a different recipe, sorry, which is quite nice.",0,0
data/train/2_219.mp3,We've got some more examples here.,0,0
data/train/2_220.mp3,"We've got a recent Raspberry Pi image, which one of my colleagues, Dennis has created.",0,0
data/train/2_221.mp3,"That's a very basic image, which just bootstraps a basic Debian image onto an SD card for you to run.",0,0
data/train/2_222.mp3,"Also, we have Apertis, which is, as I've already said, the automotive operating system by Collabora.",0,1
data/train/2_223.mp3,These recipes have got more scripting in them and if statements.,0,0
data/train/2_224.mp3,"There's an ospack image, which basically includes everything to create the operating system.",0,1
data/train/2_225.mp3,"And then on top of that,",0,0
data/train/2_226.mp3,"Apertis have a kind of hardware pack, if you like, which allows you to create Raspberry Pi image, this example, but there are other example images for other targets as well.",0,0
data/train/2_227.mp3,"So the future plans we've got for debos, some of these actually already finished.",0,1
data/train/2_228.mp3,"By the end of this year, we wanted to have Raspberry Pi 4 example recipe, which we've now got.",0,0
data/train/2_229.mp3,We wanted,0,0
data/train/2_230.mp3,"instead of fake machine just running under KVM for a virtual machine, we wanted to add user mode Linux so we could build images without KVM and this works quite nicely so you can build images inside things like GitHub actions or inside cloud workers that don't have access to GitLab, sorry, which don't have access to KVM.",0,0
data/train/2_231.mp3,This is quite useful because it by default most,0,0
data/train/2_232.mp3,Cloud images or cloud providers don't allow you access to run nested virtualization.,0,0
data/train/2_233.mp3,We want to have some more useful actions.,0,0
data/train/2_234.mp3,"So you want to be able to install a Debian package from a file, for instance.",0,0
data/train/2_235.mp3,"We want to have automated testing in place so that every kind of push to debos doesn't break any recipes or break any customer projects, really.",0,1
data/train/2_236.mp3,"Next year, we'd like to add some support for Arch Linux.",0,0
data/train/2_237.mp3,So basically running debos on Arch Linux.,0,1
data/train/2_238.mp3,"We'd like to create some more recipe examples, some documentation and some blog posts around the changes we've done to debos.",0,1
data/train/2_239.mp3,So hopefully we can market the sort of products or the free open source technology to others who may not know about it.,0,0
data/train/2_240.mp3,We'd also like to have automated recipe builds.,0,0
data/train/2_241.mp3,The example recipes I've already mentioned building automatically on GitHub actions.,0,0
data/train/2_242.mp3,And if all that goes to plan.,0,0
data/train/2_243.mp3,we'd like to release version 1.1.,0,0
data/train/2_244.mp3,So thank you and I'll take any questions.,0,0
data/train/2_245.mp3,"Again, if you didn't manage to ask any questions on the chat here, please do feel free to email me and hopefully we'll see each other again soon.",0,0
data/test/8_0.mp3,"Hello, I'm Nicolas Dufresne.",0,0
data/test/8_1.mp3,I've been at Collabora for over a decade.,0,1
data/test/8_2.mp3,"I'm now principal engineer, specialize in multimedia.",0,0
data/test/8_3.mp3,"And my main interest and work on day-to-day is on GStreamer multimedia framework, but I also contribute to the Linux kernel through the Linux Media subsystem in order to bring new API and new hardware support, especially hardware accelerators, which is of very good interest.",0,0
data/test/8_4.mp3,"So speaking of new API, I'd like to tell you a bit of the story of the apparition of Codecs in the Linux kernel.",0,0
data/test/8_5.mp3,"Codecs support isn't new, but it took a lot of time to stabilize and improve.",0,0
data/test/8_6.mp3,So everything started in 2011.,0,0
data/test/8_7.mp3,"So in 2011, Google partnered with Samsung and Asus and actually produced the first ARM Chromebook.",0,0
data/test/8_8.mp3,"This Chromebook was based on Exynos 5 system on a chip, and it included an encoder called Multifunction Codec, the MFC decoder.",0,0
data/test/8_9.mp3,And this was actually the first codec to be integrated into the mainline Linux.,0,0
data/test/8_10.mp3,And this codec landed right on the launch of this device.,0,0
data/test/8_11.mp3,"Now,",0,0
data/test/8_12.mp3,"This type of codec that we later started calling stateful codec, there was no terminology back then, how it works is basically that it has a coprocessor, whether it's a DSP or custom processor or ARM processor, it doesn't really matter, but it has a coprocessor that will handle and manage the bitstream, parse the bitstream, and feed the required information, which is codec specific to the",0,0
data/test/8_13.mp3,accelerator.,0,0
data/test/8_14.mp3,"Of course, this is delivered to us as a black box, so we're only modeling what our imagination can see here.",0,0
data/test/8_15.mp3,"Now, they needed to fit that into the kernel.",0,0
data/test/8_16.mp3,"They didn't really have a subsystem, so they decided to pick the V4LFAT subsystem and create a new type of V4L device, the memory-to-memory device, or M2M as a short.",0,0
data/test/8_17.mp3,"And in order to do that, they've used two distinct concepts in V4L.",0,0
data/test/8_18.mp3,"So V4L had actually devices that have queues, and those queues have specific properties.",0,0
data/test/8_19.mp3,"So one of the queues was the capture queue used for cameras, and the other queue was the output queue, which back then was used for analog output mostly, but could be used also for SDI output, but it's a bit abandoned these days.",0,0
data/test/8_20.mp3,"So they've decided to pick the capture as being the output of the codec, the decoded image.",0,0
data/test/8_21.mp3,"And then the output, and that's where it's a bit confusing, has been picked to be the input of your codec, so the encoded bitstream, the encoded data.",0,0
data/test/8_22.mp3,"Of course, this was not enough.",0,0
data/test/8_23.mp3,"They also added the concept of enter queue configuration, because the selection of the codec will have an impact on which raw format you'll be able to support.",0,0
data/test/8_24.mp3,"Especially that some of these accelerators, actually, they offer also color transformation, scaling, or rotation functionalities.",0,0
data/test/8_25.mp3,"Now, just quick pros and cons.",0,0
data/test/8_26.mp3,This type of hardware is relatively simple to implement in software.,0,0
data/test/8_27.mp3,"You don't need any very advanced knowledge of the codec itself because everything, all the",0,0
data/test/8_28.mp3,hard stuff is handled by the hardware.,0,0
data/test/8_29.mp3,So you pass a bit stream and you get images out.,0,0
data/test/8_30.mp3,"Now, the downside is that to drive these accelerators, you need a firmware.",0,0
data/test/8_31.mp3,"And why it's a downside is because most of these firmware, actually all of these firmwares are proprietary and are blobs, basically.",0,0
data/test/8_32.mp3,So it's a piece of software that you actually upload to the card and you have no idea what it's doing.,0,0
data/test/8_33.mp3,"And this piece of software, as it manages your",0,0
data/test/8_34.mp3,your decoding session may have some limitations.,0,0
data/test/8_35.mp3,So there's a limit of resource on the chip to handle the stream.,0,0
data/test/8_36.mp3,"So even though you have very, very small stream, you might not be able to decode more streams in parallel with this chip.",0,0
data/test/8_37.mp3,We even have implementation which only support one or two streams.,0,0
data/test/8_38.mp3,So it's much harder to multiplex.,0,0
data/test/8_39.mp3,So that's it.,0,0
data/test/8_40.mp3,We had codec.,0,1
data/test/8_41.mp3,"In 2014, we had the second stateful codec being added, the CODA driver.",0,1
data/test/8_42.mp3,"So it was added for platforms called IMX.6 and IMX.51, which was still Freescale, which was bought by NXP later.",0,0
data/test/8_43.mp3,"And CODA, actually, is the name of the chip brand as manufactured by Chips and Media.",0,1
data/test/8_44.mp3,"So it's not a free scale design, it's an actual design that has been built.",0,0
data/test/8_45.mp3,"Back in the days, we didn't have any information about this codec, so this was all reverse engineered by Philipp Zabel and his team at Pengutronix.",0,1
data/test/8_46.mp3,"Now, things didn't stay there, and Google wanted to go further, and they decided to partner with a new chipset vendor, Rockchip, from China.",0,0
data/test/8_47.mp3,"And with them, they created the second generation of ARM Chromebook, much more powerful, but it also came with a much more complex-to-use codec.",0,0
data/test/8_48.mp3,"Back then, in 2015, it was thought to be the Rockchip VDPU hardware.",0,0
data/test/8_49.mp3,"They didn't really know anything about the hardware, except what they had as a reference.",0,0
data/test/8_50.mp3,"Now, this new chip, the main difference is that there's no more coprocessor on the chip.",0,0
data/test/8_51.mp3,So the accelerator are almost exposed as is.,0,0
data/test/8_52.mp3,"There's a bit of logic implemented in the hardware to make it kind of possible to use, but they're there.",0,0
data/test/8_53.mp3,"And instead of just having to pass the bit stream, you also need to pass the references.",0,0
data/test/8_54.mp3,and all the codec parameters needed to drive this accelerator.,0,0
data/test/8_55.mp3,"And the codec parameter, even though they're fairly standard, they need to be extracted from the bitstream.",0,0
data/test/8_56.mp3,So they require deep parsing of the bitstream.,0,0
data/test/8_57.mp3,And that's the easy part.,0,0
data/test/8_58.mp3,"You also need to understand the workflow, because some stuff is not encoded in the bitstream.",0,0
data/test/8_59.mp3,Some stuff is deduced by monitoring the flow.,0,0
data/test/8_60.mp3,And it's the case for references and many of the parameters.,0,0
data/test/8_61.mp3,Now you may wonder and you may have heard about GPU codec and the fact that these are also lookalike of the stateless decoder.,0,0
data/test/8_62.mp3,"So indeed, that's correct.",0,0
data/test/8_63.mp3,"So the GPU decoders as found on Intel, AMD and NVIDIA are very similar.",0,0
data/test/8_64.mp3,"Instead of a registers that you write into memory, they use actually a common stream.",0,0
data/test/8_65.mp3,What happened is that the crafting of this common stream has been,0,0
data/test/8_66.mp3,merged with the other commands on your GPU.,0,0
data/test/8_67.mp3,And creating those command streams is something that has been decided to be done in user space.,0,0
data/test/8_68.mp3,So it's hardware-specific code in user space.,0,0
data/test/8_69.mp3,"It's a driver, but in user space, and notably through Mesa project.",0,0
data/test/8_70.mp3,"It would be pretty hard to implement a V4L driver for them because we would have to copy some code from Mesa into the kernel, which is probably not where we want to go.",0,0
data/test/8_71.mp3,"In the end, what Mesa does is that it implements the common stream and expose well-known API like Intel VA API, VDAPU, which is now deprecated, and NVDEC decoder.",0,1
data/test/8_72.mp3,"On Microsoft Windows, they also have DXVA2, which is their GPU codec accelerator interface.",0,0
data/test/8_73.mp3,Could we have done things differently?,0,0
data/test/8_74.mp3,Could we have decided to expose these accelerators as a GPU?,0,0
data/test/8_75.mp3,"I believe we could, but there was a bit of an overhead of having to use one of those high-level GPU-centric abstraction layers.",0,0
data/test/8_76.mp3,"Now, how did they model this in the context?",0,0
data/test/8_77.mp3,So they decided to build up on top of what was done for the stateful codecs.,0,0
data/test/8_78.mp3,"So they still have an M2M device with a capture and an output queue, but now they add a lot of controls and those controls are bitstream specific.",0,0
data/test/8_79.mp3,"Now, the problem is that",0,0
data/test/8_80.mp3,You don't just set controls to be applied on the next to be processed frame in the queue.,0,0
data/test/8_81.mp3,You want to apply the control to a very specific frame in the bitstream.,0,0
data/test/8_82.mp3,"In order to do that, they created the request API, which is basically an object, a file descriptor, that you can pass when setting the controls and when queuing bitstream buffers.",0,0
data/test/8_83.mp3,"This basically, you could see it as if the controls and the buffers are now attached to the request.",0,0
data/test/8_84.mp3,And then the request is queued and the driver will process requests rather than processing buffers.,0,0
data/test/8_85.mp3,This way you can really associate the right parameters with the right buffer.,0,0
data/test/8_86.mp3,"On top of that, they decided to put this API in the media controller in order for that API in the future to be usable by cameras.",0,0
data/test/8_87.mp3,And with the media controller came the topology.,0,0
data/test/8_88.mp3,And the topology is kind of a really nice feature because there was a big problem of identification of your hardware.,0,0
data/test/8_89.mp3,"of your hardware driver, what your driver is doing actually with the other model.",0,0
data/test/8_90.mp3,So the topology gives a very neat view of what your instance can do.,0,0
data/test/8_91.mp3,"Now, it will be really hard to understand all this",0,0
data/test/8_92.mp3,without going a little bit over some codecs work.,0,0
data/test/8_93.mp3,"So I've picked up H.264, and I'm going to give you a little bit of information about H.264 itself.",0,0
data/test/8_94.mp3,"So H.264 bitstream is split into NALUs, so Network Access Layer Unit, something like that.",0,0
data/test/8_95.mp3,and they form a sequence and in this sequence there's well-known types of NALU that will be found.,0,0
data/test/8_96.mp3,"So notably the one that we really care about, the SPS, the sequence parameter set, are part of the parameters we need to pass to the IP in order to decode frames.",0,0
data/test/8_97.mp3,"The PPS, the picture parameter set,",0,0
data/test/8_98.mp3,And then there's slices.,0,0
data/test/8_99.mp3,"Slices are visual bits of information, the bit that you actually decode in order to create an image.",0,0
data/test/8_100.mp3,"And in these slices, there's a header.",0,0
data/test/8_101.mp3,And we need to parse this header in order to do the bitstream processing.,0,0
data/test/8_102.mp3,"And for some accelerators, like the Allwinner Coda, we need to actually program these headers into the hardware, as the hardware won't parse it.",0,0
data/test/8_103.mp3,It will just skip over.,0,0
data/test/8_104.mp3,There's different type of slices.,0,0
data/test/8_105.mp3,"The IDR, the I slice in the IDR slices are slices that don't use reference.",0,1
data/test/8_106.mp3,"So it's per compression, a bit like your DPEGs or other images like this.",0,0
data/test/8_107.mp3,"And the DR in the IDR means that at this point, it's not allowed to actually for the following frames actually to use reference before this point in time.",0,1
data/test/8_108.mp3,The P-slice are slices that actually refer to frame that was presented in the past.,0,0
data/test/8_109.mp3,And the B-slice actually refers to frame that was presented in the past and that are going to be presented in the future.,0,0
data/test/8_110.mp3,I use the term presented because the decoding order will be different from the presentation order.,0,0
data/test/8_111.mp3,There's a reordering of the cube.,0,0
data/test/8_112.mp3,"Now, these Nalu comes in two forms, in two packing.",0,0
data/test/8_113.mp3,"One is the Annex B Nalu with a start code, which is nice for random access because you can actually locate the beginning of your Nalu in the stream and start streaming.",0,0
data/test/8_114.mp3,"And there's another one, the AVCC header, which instead of encoding the start code, they actually",0,0
data/test/8_115.mp3,allow encoding the size of the NAL.,0,0
data/test/8_116.mp3,So you would read the size and jump over if you don't care about this NAL.,0,0
data/test/8_117.mp3,"So it's much faster to navigate, but you need to receive the data aligned with the NAL.",0,0
data/test/8_118.mp3,"So for storage, we will mostly use AVCC.",0,0
data/test/8_119.mp3,"And for streaming, we will mostly use NALUs in this case.",0,1
data/test/8_120.mp3,"Now, the decoding process isn't simple, and I'm just giving you another view of that decoding process.",0,0
data/test/8_121.mp3,And this represents what you need to implement in user space.,0,0
data/test/8_122.mp3,"Fortunately, all this stuff is now implemented in Chromium, FFmpeg, and GStreamer.",0,1
data/test/8_123.mp3,"And assuming you have the luxury to be able to use one of these three, you won't have to program it yourself again.",0,0
data/test/8_124.mp3,So how does it go?,0,0
data/test/8_125.mp3,So first you need to locate and parse the null headers.,0,0
data/test/8_126.mp3,Then you need to parse all the non-VCL information.,0,0
data/test/8_127.mp3,"VCL is the visual coding actually, the data that you're going to decode.",0,0
data/test/8_128.mp3,So non-visual or informative NALs that are used in the process.,0,1
data/test/8_129.mp3,And you also need to parse the headers of the VCL NAL in order to retrieve some information there.,0,1
data/test/8_130.mp3,"With this information, you'll have to calculate the frame number and handle the case there would have been some gaps, which happens in lossy networks.",0,0
data/test/8_131.mp3,"This, of course, is a recipe, so it's described in prose in the specification, and you just implement code out of the text.",0,0
data/test/8_132.mp3,"You also have to calculate the picture order count, the POC, and the picture number, which are numbers that will be used in some logic in the processing of decoding.",0,1
data/test/8_133.mp3,"So you need it for your code in user space, but the IP might need it for some logical",0,0
data/test/8_134.mp3,"Now, there's two types of decoders.",0,0
data/test/8_135.mp3,Some decoders will be frame-based.,0,0
data/test/8_136.mp3,So you pass all the slices of a frame.,0,0
data/test/8_137.mp3,"So in this case, the decoder, the hardware, will have to parse the slice header.",0,0
data/test/8_138.mp3,So you don't need to pass as much information.,0,0
data/test/8_139.mp3,"And there's those that don't do that, that will decode each slices separately.",0,0
data/test/8_140.mp3,"In that case, we need to prepare the reference list, as we will have to provide a very specific ordered set of reference as described by the",0,0
data/test/8_141.mp3,by the specification.,0,0
data/test/8_142.mp3,"At that point, you got pretty much all the information you need for the next decode operation.",0,0
data/test/8_143.mp3,"You can fill the SPS, PPS, decode param, slice parameters, and pass that into a V4L structure format and set that to controls.",0,0
data/test/8_144.mp3,"If you're slice-based, you need to apply another algorithm called the modification of reference list, which you pick from the reference that you created for.",0,0
data/test/8_145.mp3,the picture and you transform them based on a per slice modification.,0,0
data/test/8_146.mp3,"And finally, you should be able to decode a frame.",0,0
data/test/8_147.mp3,"When a frame is decoded, you do your DPB management.",0,0
data/test/8_148.mp3,"DPB is the picture buffer, the displayed picture buffer.",0,0
data/test/8_149.mp3,This is used to store your decoded picture and to figure out actually which picture are now ready to be displayed and which picture no longer have,0,0
data/test/8_150.mp3,"another picture that will have to be decoded, presented before it, because of the B frames, the order of decoding can be complicated.",0,0
data/test/8_151.mp3,So it's also a buffer to reorder your frames.,0,0
data/test/8_152.mp3,"On the V4L side, it's much simpler if we just look at driving the hardware itself.",0,0
data/test/8_153.mp3,"So on V4L's side, you need to allocate a request, you need to set all the parameters,",0,0
data/test/8_154.mp3,You need to queue your bitstream buffers for that request.,0,0
data/test/8_155.mp3,You set the parameters for that request also.,0,0
data/test/8_156.mp3,And then you queue that request.,0,0
data/test/8_157.mp3,"And instead of waiting for a buffer to come out, you actually wait for that request to complete.",0,0
data/test/8_158.mp3,So you pull on the file descriptor of the request.,0,0
data/test/8_159.mp3,It's a much simpler process than the other accelerators.,0,0
data/test/8_160.mp3,And things stay there and time passed.,0,0
data/test/8_161.mp3,"In 2016, we had yet another stateful decoder from Mediatek, actually provided by Mediatek.",0,0
data/test/8_162.mp3,"It was a bit annoying because it was limited to tile output, which support is still not great in the V4L framework.",0,0
data/test/8_163.mp3,"Then the year after, the Qualcomm Venus driver was merged also, and it's by far today the most featureful codec as it supports MPEG-4, MPEG-2, H.264, VC1, H.26... What did I say?",0,0
data/test/8_164.mp3,"Okay, H.263.",0,0
data/test/8_165.mp3,There's a typo in the slide.,0,0
data/test/8_166.mp3,"VP8, VP9, and HEVC to decode.",0,0
data/test/8_167.mp3,"And assuming you got the latest Snapdragon, I think it's 855+, you're going to have all these encoders too.",0,0
data/test/8_168.mp3,"So MPEG-4, H.263, H.264, VP8, and HEVC.",0,0
data/test/8_169.mp3,I suspect they're most likely at VP9 also.,0,0
data/test/8_170.mp3,"So, as for our stateless codec implementation, development was pretty much stalled.",0,0
data/test/8_171.mp3,"In fact, it was not stalled, but it was blocked on",0,0
data/test/8_172.mp3,multiple work in progress.,0,0
data/test/8_173.mp3,So one of them was the request API.,0,0
data/test/8_174.mp3,So it was hard to finalize a request API.,0,0
data/test/8_175.mp3,It was picked up and renamed to job API.,0,0
data/test/8_176.mp3,People didn't like the name.,0,0
data/test/8_177.mp3,It came back to request API.,0,0
data/test/8_178.mp3,And it took a while before this was finalized.,0,0
data/test/8_179.mp3,And it was key feature in order to get this running.,0,0
data/test/8_180.mp3,The other problem was that there was a very low knowledge of how Codec works in the Linux media community.,0,0
data/test/8_181.mp3,"So maintainers had to train themselves, find some times to understand how Codec works in order to review and make sure that the design was going to stay long enough.",0,0
data/test/8_182.mp3,"There was only one hardware running so far, the Rockchip 3288 VDPU.",0,0
data/test/8_183.mp3,And there was just no formal specification to help focus on how these decoders are going to be used.,0,0
data/test/8_184.mp3,"And this stayed there till 2018, where really everything started launching.",0,0
data/test/8_185.mp3,"So Bootlink actually started this, made a Kickstarter in order to finance the development of VPU support on all Winner chipset.",0,0
data/test/8_186.mp3,"And with this effort, motivation came along.",0,0
data/test/8_187.mp3,"There was a lot of discussion in various workshops, and the request API was finalized.",0,0
data/test/8_188.mp3,"the MPEG-2 support landed in staging, H.264 was in progress, and the targeted user space back then was a VA API driver.",0,0
data/test/8_189.mp3,So basically you would use your all-winner VPU just like you would use,0,0
data/test/8_190.mp3,"a VPU, an Intel VPU, as an example.",0,0
data/test/8_191.mp3,"It was a good fit, considering that cedrus, the driver that they created here, actually is a slice-based decoder, just like Intel produces.",0,1
data/test/8_192.mp3,"So, in 2019, the crowdfunding was full steam.",0,0
data/test/8_193.mp3,"And so,",0,0
data/test/8_194.mp3,"And basically, things started moving.",0,0
data/test/8_195.mp3,"I forgot to mention, the crowdfunding was being developed by Paul Koscialski, an intern at Bootlin, and Maxime Rippard.",0,0
data/test/8_196.mp3,So a formal specification was written.,0,0
data/test/8_197.mp3,What's a formal specification?,0,0
data/test/8_198.mp3,"In the V4L, in the Linux Media Community, they try to document how a driver is supposed to be written using the functionality in V4L, and how it's supposed to work.",0,0
data/test/8_199.mp3,"This helps keeping drivers... I mean, it helps keeping the drivers more generic,",0,0
data/test/8_200.mp3,in order to run on various software without any difficulties.,0,0
data/test/8_201.mp3,"H.264, VP8, HEVC support was added with their controls.",0,0
data/test/8_202.mp3,All these controls are not officially stable yet.,0,0
data/test/8_203.mp3,"They're actually staging, so if you want to use them, you need to copy the others from the kernel as they may have some modification later.",0,0
data/test/8_204.mp3,Then things started to follow on RK3288.,0,0
data/test/8_205.mp3,"The Collabora team actually started looking at finalizing Google upstreaming of that, and MPEG-2, H.264, VP8 was added, JPEG encoder was also added, and something special happened.",0,1
data/test/8_206.mp3,"So at that time, my colleagues were a bit overwhelmed by all this work.",0,0
data/test/8_207.mp3,They didn't know much about Bitstream.,0,0
data/test/8_208.mp3,I was in multimedia.,0,0
data/test/8_209.mp3,"I had worked on the GStreamer parser a little bit, so I probably had a good base knowledge.",0,0
data/test/8_210.mp3,"So I came to help and understand and review all these API in order to make all this work, actually, and make this proper.",0,0
data/test/8_211.mp3,"And as I was seeking for documentation on the Rockchip side and for other hardware,",0,0
data/test/8_212.mp3,I was also in discussion with Chris Haley from Zodiac.,0,0
data/test/8_213.mp3,"Chris is well known for having pushed forward Ethnaviv reverse engineering project, the GPU driver called Vivante, for Vivante chip that is found on iMX6 and now iMX8.",0,1
data/test/8_214.mp3,And he was also behind CODA pushing that codec forward as he's using it at Zodiac in the infotainment system.,0,1
data/test/8_215.mp3,"And while I was discussing with him, he was presenting me his new iMX8M-based devices, which was the new generation of in-flight entertainment there.",0,0
data/test/8_216.mp3,And he knew back then that this new hardware from NXP didn't use the Coda chips to do the multimedia.,0,0
data/test/8_217.mp3,"And instead, they had picked a design from Hantro",0,0
data/test/8_218.mp3,"company that was called G1 and G2, two different cores.",0,0
data/test/8_219.mp3,So I was quite curious and I started searching for documentation.,0,0
data/test/8_220.mp3,NXP is kind of nice because you just need to exchange your email and you get the documentation.,0,0
data/test/8_221.mp3,So I started comparing the documentation of RK3288 and the iMX8M.,0,0
data/test/8_222.mp3,"to my surprise, found out that they were not just similar, they were identical.",0,0
data/test/8_223.mp3,The register set was binary compatible between the two devices.,0,0
data/test/8_224.mp3,"And then I came to my colleague and I'm like, hmm, I don't think this is a Rockchip design.",0,0
data/test/8_225.mp3,I don't think this driver should be called Rockchip anymore.,0,0
data/test/8_226.mp3,So just a little bit about Hantro.,0,0
data/test/8_227.mp3,and why we decided to rename this driver Hantro.,0,1
data/test/8_228.mp3,Hantro was a Finnish company that eventually got bought by On2.,0,1
data/test/8_229.mp3,"themselves got acquired by Google, and within Google, On2 developed the well-known VP8 codec that was one of the first royalty-free viable codec out there.",0,1
data/test/8_230.mp3,"It was not the first, of course, and then came VP9, which is highly used now on YouTube and everything on the web.",0,0
data/test/8_231.mp3,Google didn't really want to keep that but they did great great work as the Hantro team actually made a VP9 design and that was made freely available to any silicon vendors.,0,1
data/test/8_232.mp3,This business of hardware was then sold to VeriSilicon who was still doing new revision of this decoding hardware.,0,0
data/test/8_233.mp3,"What we wanted to avoid, and that was something I had learned about just a couple of weeks before we found that this hardware was not actually Rockchip, was the story about STM Mac.",0,0
data/test/8_234.mp3,"So STM Mac is an Ethernet driver that is in the Linux kernel, and it is still called STM Mac even though the hardware is actually DesignWare.",0,0
data/test/8_235.mp3,"And it's not just a DesignWare, it's the DesignWare, the one that is used on most SBC out there.",0,0
data/test/8_236.mp3,"So that's very confusing when you first see that, but STM Mac is actually DesignWare driver, generic driver used across multiple SoC.",0,0
data/test/8_237.mp3,And so we avoided to repeat HistoryMystic.,0,0
data/test/8_238.mp3,"The project continued, and we finally got more support from the community with the folks from LibreElec and Kodi, who came along and started and implemented this FFmpeg backend.",0,1
data/test/8_239.mp3,"So when we started, we only had the VA driver, which was limited to cedrus support, or the Chromium browser, which wasn't limited, but it's",0,1
data/test/8_240.mp3,more complicated to do testing with a full-fledged browser.,0,0
data/test/8_241.mp3,So they provided this FFmpeg support and that actually boosted the development as we could do faster testing and validation of our decoder.,0,0
data/test/8_242.mp3,They also provided a lot of bug fixing in the driver and Cedrus.,0,0
data/test/8_243.mp3,"They implemented interlace content support, which we didn't have initially.",0,0
data/test/8_244.mp3,"And came 2020, everything was full steam.",0,0
data/test/8_245.mp3,"Support for the RockChip 3399 came in with the RKV deck driver, which is this time a RockChip design.",0,0
data/test/8_246.mp3,"And something moved in GStreamer, so we gained generic base classes to do hardware acceleration decoding on",0,0
data/test/8_247.mp3,"in GStreamer, something that FFmpeg had for years and years, which we didn't have in GStreamer.",0,0
data/test/8_248.mp3,"Instead, Intel, who was behind this development, decided to write some code highly specific to the API, and it was not possible to reuse this code.",0,0
data/test/8_249.mp3,"So Sung Ha, a GStreamer developer that was working at NavCorp back then, wanted to have DXVA2 support on Windows.",0,0
data/test/8_250.mp3,"And while doing it and while going through the reviews, he already had kind of split the Bitstream generic part and the DXVA part.",0,0
data/test/8_251.mp3,"So I've asked him kindly if he could split that into base classes, which he did.",0,0
data/test/8_252.mp3,And later I took those base classes and I made a new library within GStreamer called,0,0
data/test/8_253.mp3,"libgst-codec, which depends, of course, on libgst-parsers.",0,0
data/test/8_254.mp3,And it actually forms a very neat base class that we can share among multiple implementations.,0,0
data/test/8_255.mp3,So we could easily see in the future to port actually the VA API stuff on these base classes in order to share the bitstream work and enhancement that we do.,0,0
data/test/8_256.mp3,"On top of that, he implemented stateless support for NVDeck, because NVDeck property library offers both a stateful and stateless interface.",0,0
data/test/8_257.mp3,And it provides a little lower latency when you use the stateless interface.,0,0
data/test/8_258.mp3,"And then, beginning of the year, I implemented GStreamer support for H.264 and VP8 decoder, and it actually landed upstream.",0,0
data/test/8_259.mp3,I guess it's much easier when you're the maintainer of such a subsystem in GStreamer.,0,0
data/test/8_260.mp3,But it was a nice addition also to our testing workflow as GStreamer opened up other ways of using and testing the hardware.,0,0
data/test/8_261.mp3,"All this was targeting, I mean, I was racing this and I was targeting the Embedded World Conference and I was supposed to do a demo there.",0,0
data/test/8_262.mp3,And we actually managed to get this all in time until,0,0
data/test/8_263.mp3,COVID appear and they cancel the show.,0,0
data/test/8_264.mp3,So I never got to show the demo that we actually had prepared.,0,0
data/test/8_265.mp3,"And then, now that we had FFmpeg support, Chromium support, and Distributor Native support, it was commonly decided that there would be no more work done on the VA driver, as it was not very relevant anymore.",0,0
data/test/8_266.mp3,"There's, of course, a lot more to come in 2020.",0,0
data/test/8_267.mp3,at two meter distance.,0,0
data/test/8_268.mp3,"Now, all this work enables Codec, the hardware decoding support on many interesting project, and I only picked three of them, but there's more, of course.",0,0
data/test/8_269.mp3,"And interestingly, the MNT Reform laptop, which is a fully open source and blob-free laptop running mainline Linux, is based on iMX8M, which has one of the supported decoder.",0,0
data/test/8_270.mp3,"In the middle, that represents the Pine64 phone, is an Allwinner64 chip, which is supported by Cedrus.",0,0
data/test/8_271.mp3,"And on the right, the Parism phone, the Librem5, running some GNOME stack, actually, and using GStreamer, actually, again, the ability to do hardware decoding.",0,0
data/test/8_272.mp3,So quite a win.,0,0
data/test/8_273.mp3,And now it's going to be show time.,0,0
data/test/8_274.mp3,"So in order to demonstrate all this, I have chosen the Libre Computer Tritium because I really like what Libre Computer do.",0,0
data/test/8_275.mp3,They provide a wide variety of chips that have the potential to be fully supported mainline or are already fully supported mainline in very simple packages like this.,0,0
data/test/8_276.mp3,"In this case, it's the Allwinner H3 and we're going to demonstrate the CODA driver.",0,0
data/test/8_277.mp3,"In order to do that, I brought a little HDMI recorder from a company called Inogenie, one of the rare French-Canadian hardware company I know.",0,0
data/test/8_278.mp3,So I'm going to plug HDMI in there.,0,0
data/test/8_279.mp3,"As I'm doing TFTP NFS booting I'm going to put Ethernet and Finally, I'm gonna boot it up.",0,0
data/test/8_280.mp3,"Oh, I'm gonna show you the The console and I'm gonna boot it up straight from my laptop power and hopefully that's gonna work.",0,0
data/test/8_281.mp3,Oh I've also connected a little,0,0
data/test/8_282.mp3,keyboard so I can actually log in and type.,0,0
data/test/8_283.mp3,So now it's booting.,0,0
data/test/8_284.mp3,"So in this case, my NFS root is Fedora running in the background.",0,0
data/test/8_285.mp3,It's running ahead of Linux TV 3 with one of the patches I've submitted upstream.,0,0
data/test/8_286.mp3,So I'm going to log in.,0,0
data/test/8_287.mp3,Voila.,0,0
data/test/8_288.mp3,"And I'm also going to run the latest GStreamer, actually from yesterday.",0,0
data/test/8_289.mp3,"And I'm going to use it, what we call uninstalled.",0,0
data/test/8_290.mp3,"So I'm using gstbuild to build the integrity of GStreamer, to cross build the integrity of GStreamer for the platform.",0,0
data/test/8_291.mp3,"And this command, gstuninstalled.py will actually set up an environment so the plugin can be used in place without being spread out.",0,0
data/test/8_292.mp3,"It takes a little while because files are,",0,0
data/test/8_293.mp3,"There's a lot of path and the path are getting big, but it will get there and NFS is not helping of course Now the As a",0,0
data/test/8_294.mp3,"media player, because I don't have any graphical setup in there.",0,1
data/test/8_295.mp3,"I'm going to use GST play with KMS sync, and that's going to go on the video overlay plane.",0,0
data/test/8_296.mp3,But that plane is normally in the background.,0,0
data/test/8_297.mp3,It's an underlay on this device and on most modern devices.,0,0
data/test/8_298.mp3,But this hardware has this nice capability that you can change the Z order.,0,0
data/test/8_299.mp3,So I'm setting Z pass to two to bring it up in front so you can actually see the video.,0,0
data/test/8_300.mp3,"And in the video itself,",0,0
data/test/8_301.mp3,"It's coming, it's pre-rolling.",0,0
data/test/8_302.mp3,"I'm actually displaying, let me pause here, the demo that we had prepared for Embedded World 2020.",0,0
data/test/8_303.mp3,"On the left, that's the monitor of the streaming server, which provides streaming transcodes in various formats, SRT, REST, and HLS.",0,0
data/test/8_304.mp3,"I'm not going to go into these, that's not the goal of the day.",0,0
data/test/8_305.mp3,"And on that screen, it's actually an IMX 8M evaluation kit.",0,0
data/test/8_306.mp3,running the demo.,0,0
data/test/8_307.mp3,"And then in the back, this little device here is the Zodiac.",0,0
data/test/8_308.mp3,"It's the upcoming, actually, Zodiac entertainment system for planes that is under development.",0,0
data/test/8_309.mp3,And we decided to demo some touchscreen capabilities and some underlays capabilities that is made possible.,0,0
data/test/8_310.mp3,It's actually a mix of underlays and GPU rendering.,0,0
data/test/8_311.mp3,on this device with smooth hardware-accelerated decoding.,0,0
data/test/8_312.mp3,And that's it for the demo.,0,0
data/test/8_313.mp3,Hope you enjoyed.,0,0
data/test/8_314.mp3,"And on that, if you have any questions, you can place your question into the Inspo system.",0,0
data/test/8_315.mp3,and share with us.,0,0
data/test/8_316.mp3,"We will try to, I will try to insert as many as possible.",0,0
data/test/8_317.mp3,Thank you for watching.,0,0
data/test/8_318.mp3,Thanks for Collabora for making this presentation possible and enjoy your summer.,0,1
data/train/1_0.mp3,"Hello everyone, my name is André Almeida and I'm based in Brazil and I'm a kernel engineer at Collabora, an open source consultancy.",0,1
data/train/1_1.mp3,So today I want to share some tips and tricks from my kernel development workflow that I have in Arch Linux.,0,0
data/train/1_2.mp3,"And this is an overview of the things I'm going to show here, it's kind of a tutorial.",0,0
data/train/1_3.mp3,"And first of all,",0,0
data/train/1_4.mp3,I use Arch Linux for both professional and personal use.,0,0
data/train/1_5.mp3,"For professional use, I found very handy to have a lot of very up-to-date packages.",0,0
data/train/1_6.mp3,"And as part of Arch philosophy, they are very close to mainline, so maintainers rarely apply patch to it.",0,0
data/train/1_7.mp3,"And for instance, if I want to boot a custom kernel, I don't need to change anything in the user space, everything will be ready to run my custom kernel from my line.",0,0
data/train/1_8.mp3,And also in this tutorial I'll be showing how to use a virtual machine because booting your own custom kernel requires some time and it's very painful to reboot your machine just to check if your print is working.,0,0
data/train/1_9.mp3,And so also I found very useful to have a different rootfs,0,1
data/train/1_10.mp3,So I can do some experimental changes on all the stack and I do not risk breaking my system.,0,0
data/train/1_11.mp3,"But if you want to use the same rootfs of your installation on your testing, I recommend you checking the tool called cirtme that is a wrapper around QEMU.",0,1
data/train/1_12.mp3,And one more thing that I found very useful from Arch Linux is the keep it simple philosophy.,0,0
data/train/1_13.mp3,And on my workflow I try to apply this principle as well.,0,0
data/train/1_14.mp3,So for my workflow I just need two additional tools.,0,0
data/train/1_15.mp3,"that is the Arch install scripts, that will provide the same scripts that you use on an installation disk to install a new Arch Linux, and the QEMU that will provide the virtualization.",0,0
data/train/1_16.mp3,"First of all, we need somewhere to store our rootfs, and for this I create a file of 5GB.",0,0
data/train/1_17.mp3,"I use truncate because in that way I can have a spare file that will grow as need, it won't be using 5GB from storage.",0,1
data/train/1_18.mp3,"After that, I format this file to have the ext4 file system, and then I just mount this file in a directory.",0,1
data/train/1_19.mp3,"After that, we can use the pacstrap that is the same script that we use in an Arch Linux installation to create all the directories and install some basic software there.",0,1
data/train/1_20.mp3,"If your system is up to date, you can use the flag ""-c"".",0,0
data/train/1_21.mp3,"So, instead of downloading the package all again, you just use the cache from the whole system.",0,0
data/train/1_22.mp3,"And after that, your RootFS is complete in less than 2 minutes.",0,0
data/train/1_23.mp3,"Also this is useful, it may be useful as well to install an editor like Vim or in the DHCP client as well.",0,0
data/train/1_24.mp3,"And using pacstrap and the cache flag, you won't need to download anything from the internet.",0,1
data/train/1_25.mp3,So it's a very easy and fast setup.,0,0
data/train/1_26.mp3,"And since the rootfs is malted, we can easily copy our SSH key there.",0,1
data/train/1_27.mp3,And also we can use chroot to change the root password.,0,0
data/train/1_28.mp3,"And if you are always going to log in as root, you can change the systemd configuration, so you can always auto-login in the root user.",0,0
data/train/1_29.mp3,Those steps will help us in the future to make the use of the virtual machine easier.,0,0
data/train/1_30.mp3,"And now, for using QEMU, these are the flags that I use.",0,0
data/train/1_31.mp3,"The first flag is HDA, that is to tell QEMU where is my disk.",0,0
data/train/1_32.mp3,And then I use the kernel flag to specify the path of my compiled kernel.,0,0
data/train/1_33.mp3,"In this talk, I am not covering how to compile your own custom kernel.",0,0
data/train/1_34.mp3,"But if you want, you can also use this flag with your current installed kernel of your system that is probably located somewhere in the boot directory.",0,0
data/train/1_35.mp3,And also I use the append flag to use some kernel parameters.,0,0
data/train/1_36.mp3,"For instance, the root parameter tells the kernel where it can find the root, in which disk is the rootfs.",0,1
data/train/1_37.mp3,"So here is the first disk, the SDA.",0,0
data/train/1_38.mp3,We send also the parameter read-write.,0,0
data/train/1_39.mp3,because we want to change the rootfs and with console.tti.so you can tell to the kernel where it should display the output and the shell when it boots.,0,1
data/train/1_40.mp3,Some useful flags as well is the flag m so you can specify how much memory do you want to give to your guest,0,0
data/train/1_41.mp3,Enable KVM will make a huge difference on your performance.,0,0
data/train/1_42.mp3,And remember to enable virtualization on your BIOS menu on your motherboard.,0,0
data/train/1_43.mp3,"And also, I like to use the flag NoGraphic, so QEMU will just run as a console application like Vim.",0,1
data/train/1_44.mp3,"And also use the SMP, you can specify how much, how many",0,0
data/train/1_45.mp3,cores do you want to give to your guest.,0,0
data/train/1_46.mp3,"If you want to use networking inside your machine, for instance, if you want to use GitClone or use Pacman to get a new software, you can easily enable it by just starting the DHCP client that you installed earlier.",0,0
data/train/1_47.mp3,"Here, I'm using DHCP CD for that.",0,0
data/train/1_48.mp3,So copying and pasting files isn't a very efficient way to share some files with the guest.,0,0
data/train/1_49.mp3,So what I do is I create a shared folder.,0,0
data/train/1_50.mp3,"In order to do that, you need to be sure that your kernel has some modules enabled, like mainly modules that are related to the 9np sharing protocol.",0,0
data/train/1_51.mp3,"And after that, in the King of Flags, I will add two devices, a file system device and then a Virtio 9P device.",0,0
data/train/1_52.mp3,So you use this flag to choose which directory you want to share.,0,0
data/train/1_53.mp3,"In this example, I'm sharing a directory named files inside my home directory of the user.",0,0
data/train/1_54.mp3,and the name of the virtual device will be shared folder and then inside the guest's fstab file you just need to add this line for the shared folder device and specifying where do you want the multi point to be inside your guest.,0,1
data/train/1_55.mp3,During your testing you may be required to use some graphical applications,0,0
data/train/1_56.mp3,"And I know two ways of doing that, my favorite one is the first I'm going to show, that is the SSH Forge, but you can also use the Keen Display.",0,0
data/train/1_57.mp3,"So in order to use the SSH Forge, first you need to install the OpenSSD server on your guest and initiate the download.",0,0
data/train/1_58.mp3,You can find it on the OpenSSH package.,0,0
data/train/1_59.mp3,And then you change some configuration on the,0,0
data/train/1_60.mp3,SSH configuration file.,0,0
data/train/1_61.mp3,Namely you permit the root login and also you say yes for X11 forwarding.,0,0
data/train/1_62.mp3,"For the chemoflags you need a basic, to create a basic network card and here we forward the port, you need to forward some ports so you don't mess with the host ports.",0,0
data/train/1_63.mp3,Here I am forwarding the port 1337 to the port 22,0,0
data/train/1_64.mp3,"So, basically, this is the setup, and then if you run ssh-x root at localhost, and then you specify your port, and just by doing that on your guest machine, you will be able to run graphical applications.",0,1
data/train/1_65.mp3,Here's an example.,0,0
data/train/1_66.mp3,"On the left side, I have my host, the Quest machine.",0,0
data/train/1_67.mp3,"And then on the right side, I will use SSH.",0,0
data/train/1_68.mp3,"And then after doing that, I can open the XCLOCK graphical application.",0,1
data/train/1_69.mp3,"And now, if you want a more complete graphical solution, you can run a whole compositor inside your virtual machine.",0,0
data/train/1_70.mp3,"For that, the first thing you do is to remove the no-graphic-output option on QEMU flex.",0,1
data/train/1_71.mp3,"And then, after that, you need to install some kind of compositor.",0,0
data/train/1_72.mp3,"Here, I'm using Weston because it's very lightweight.",0,0
data/train/1_73.mp3,"So, I installed x the package of XWayland and Weston.",0,1
data/train/1_74.mp3,And then after that you need to configure your wisdom to run on XWayland And so you need to create this file on your home folder and say accelerate xwayland equals true Then you just run weston,0,1
data/train/1_75.mp3,on the command line and the Weston environment will appear.,0,0
data/train/1_76.mp3,You can use your mouse to open the terminal and inside there you can call the graphic application that you want.,0,0
data/train/1_77.mp3,"When you are done, you just hold CTRL, ALT and backspace and Weston will close.",0,0
data/train/1_78.mp3,And this is a very basic setup using QEMU display.,0,1
data/train/1_79.mp3,"Here you won't have support for clipboard, for sharing the same clipboard, or multi-monitor support.",0,0
data/train/1_80.mp3,"If you want to do that, I recommend you to use the FlipManager, that is a front-end for QEMU with LibreVert.",0,1
data/train/1_81.mp3,And then you can have a very nice graphical experience.,0,0
data/train/1_82.mp3,"Ok, and that's it, this is how I spawn new virtual machines if I need to do some testing and also sharing files with my virtual machine, running graphical applications and as you can see it requires almost no new program",0,0
data/train/1_83.mp3,"Everything is command line application, so it's very easy to create some bash scripts.",0,1
data/train/1_84.mp3,Here is the link for a git repository where I store my scripts.,0,0
data/train/1_85.mp3,"And also here is a link of our blog post at the Collabora website, where you can find more detailed explanation of my talk.",0,0
data/train/1_86.mp3,And thanks for watching and now I would like to hear if you also have some tips of kernel development workflow.,0,0
data/train/1_87.mp3,Thank you!,0,0
data/train/4_0.mp3,"Hello, everyone.",0,0
data/train/4_1.mp3,My name is George and I'm a senior software engineer at Collabora.,0,0
data/train/4_2.mp3,"Today, I am going to talk to you about video support in AGL, taking a look at the various use cases for having video in a car, looking at the requirements that these use cases have and presenting potential software solutions from the viewpoint of AGL.",0,0
data/train/4_3.mp3,Let's start by taking a look at the use cases.,0,0
data/train/4_4.mp3,"So in modern cars, the need for dealing with video is more and more growing.",0,0
data/train/4_5.mp3,And some use cases have to do with using cameras.,0,0
data/train/4_6.mp3,"A popular feature, for example, is to have dashboard cameras, cameras that record what is in front of the car in the street.",0,0
data/train/4_7.mp3,"Or another popular feature is to install cameras at the back of the car and use it for rear view display, showing to the driver what is behind the car, useful when going in reverse.",0,0
data/train/4_8.mp3,Another modern use case has to do with AI processing.,0,0
data/train/4_9.mp3,"So some cars install cameras to, for example, monitor the driver's condition.",0,0
data/train/4_10.mp3,Or another use case is to install cameras to monitor the surroundings of the car and implement autonomous driving.,0,0
data/train/4_11.mp3,Another use case has to do with displaying video.,0,0
data/train/4_12.mp3,So of course when capturing feed from the back of the car we need to display it somewhere for the driver to be able to see it.,0,0
data/train/4_13.mp3,"This is currently done, for example, with mirrors that have integrated display, rear view mirrors, or displays in the dashboard of the car.",0,0
data/train/4_14.mp3,"And then there is, of course, the use case of providing entertainment for the passengers.",0,0
data/train/4_15.mp3,"So, some cars install, for example, rear seat displays that rear passengers can use to display video content.",0,0
data/train/4_16.mp3,And then we have things that are going on in the background.,0,0
data/train/4_17.mp3,"So, for instance, recording video.",0,0
data/train/4_18.mp3,maybe from the dashboard camera.,0,0
data/train/4_19.mp3,That's the most common case to record the video from the dashboard camera.,0,0
data/train/4_20.mp3,Or another use case has to do with processing.,0,0
data/train/4_21.mp3,"As I said, some cars implement AI processing for autonomous driving or for monitoring the driver and maybe other things.",0,0
data/train/4_22.mp3,And another thing that,0,0
data/train/4_23.mp3,"is done with video is to stream it, stream it to the rear seats, for example, or stream it to the network or stream it from the network to get video content from an external source.",0,0
data/train/4_24.mp3,So let's take a look at the requirements.,0,0
data/train/4_25.mp3,"First of all, safety.",0,0
data/train/4_26.mp3,We cannot implement anything that is not safe for the passengers.,0,0
data/train/4_27.mp3,So that's the top priority.,0,0
data/train/4_28.mp3,Then a very important issue in the context of the car is,0,0
data/train/4_29.mp3,how to control all these video streams.,0,0
data/train/4_30.mp3,"Since we have many different components dealing with video, cameras, displays, processing nodes, and we also have streams going to or from the network, all of these need to be controlled centrally and they need to be secured so that nothing malicious can happen",0,0
data/train/4_31.mp3,No malicious application can take control of something or do something that is not intended.,0,0
data/train/4_32.mp3,And then we also need to deal with the fact that all processing must be done in real time.,0,0
data/train/4_33.mp3,We are,0,0
data/train/4_34.mp3,"capturing live video, we are displaying live video and we are processing live video.",0,0
data/train/4_35.mp3,"So anything we do, it must be able to be done in real time.",0,0
data/train/4_36.mp3,And then we also need to make sure that we leverage the hardware appropriately for efficiency and for safety.,0,0
data/train/4_37.mp3,We need to be able to use dedicated hardware for dedicated purposes.,0,0
data/train/4_38.mp3,And we need to be able to split the work across nodes in the car.,0,0
data/train/4_39.mp3,"Finally, when it comes to entertainment, we need to be able to deal with digital rights management.",0,0
data/train/4_40.mp3,We need to be able to use modules that decode DRM protected content in a safe way and respecting the DRM standards.,0,0
data/train/4_41.mp3,So where does AGL fit in this?,0,0
data/train/4_42.mp3,AGL is a software system that can be present in multiple places in the car.,0,0
data/train/4_43.mp3,It implements the operating system of the various components and it may be running in multiple CPUs and multiple nodes at the same time.,0,0
data/train/4_44.mp3,Implementing different things in each one of them.,0,0
data/train/4_45.mp3,So one of the things that it may implement is some central system management node,0,0
data/train/4_46.mp3,"It may implement the entertainment system, it may implement software that runs on dedicated displays like the rear view mirror or the rear seat displays.",0,0
data/train/4_47.mp3,It may implement,0,0
data/train/4_48.mp3,software that runs on the cameras.,0,0
data/train/4_49.mp3,"And it's actually a very common thing for network cameras, not car cameras, but network security cameras to be running Linux based systems.",0,0
data/train/4_50.mp3,And probably makes sense also for cameras running in a car.,0,0
data/train/4_51.mp3,"And AGL may also be used in processing software, in implementing the nodes that process data and provide analysis of the video feeds, or to implement recording and things like that.",0,0
data/train/4_52.mp3,So.,0,0
data/train/4_53.mp3,Let's assume that we want to implement such a system with AGL.,0,0
data/train/4_54.mp3,"Let's take a look from the perspective of the system running AGL and look at what the apps have available beneath them to deal with video input, output, and processing.",0,0
data/train/4_55.mp3,"On the input and output side,",0,0
data/train/4_56.mp3,"Well, right away, applications can access devices that are directly connected to the CPU they are running on using Video4Linux, which is the standard Linux kernel API for dealing with video devices.",0,1
data/train/4_57.mp3,"And nowadays, there is also another project called LibCamera, which",0,0
data/train/4_58.mp3,"is trying to bring modern camera features into the Linux, both in the kernel and in the user space, something that video for Linux is not able to deliver appropriately.",0,0
data/train/4_59.mp3,Then we have network streams.,0,0
data/train/4_60.mp3,So video content can be input or output from the in-car network or from the internet,0,0
data/train/4_61.mp3,"And yeah, we have the standard network APIs to deal with that, or proprietary APIs in the case of proprietary networks or proprietary devices that do not follow the standards and do not use Video4Linux, although that's not recommended.",0,1
data/train/4_62.mp3,"And then for processing, we may have software processing components that take video feeds from the kernel and process them and output them somewhere else.",0,0
data/train/4_63.mp3,Or we may have hardware video processing units that we access again through Video4Linux.,0,0
data/train/4_64.mp3,"Or we may have network components that we send the video to and we get some results back or we don't get results back, we just send it and something else happens there.",0,0
data/train/4_65.mp3,"And then for display, we have Wayland, the standard display API for displaying things in our local display.",0,0
data/train/4_66.mp3,"And then we may again be using the network, sending something for display to another node in the car.",0,0
data/train/4_67.mp3,Or we may be using hardware display overlays,0,0
data/train/4_68.mp3,which may be done through Wayland or through some other APIs.,0,0
data/train/4_69.mp3,"I've seen some devices using, for example, Video4Linux devices, for overlays, or proprietary APIs, although that's all not so recommended nowadays.",0,1
data/train/4_70.mp3,The standard approach is to integrate that with Wayland.,0,0
data/train/4_71.mp3,"As you can see, there's a lot going on in the system.",0,0
data/train/4_72.mp3,it becomes more and more complex when you start combining multiple notes in the car.,0,1
data/train/4_73.mp3,"So you may have an application that requires cooperation of multiple AGL and non-AGL systems streaming video across multiple points in the car, from the camera to a processing unit to a display, for example.",0,0
data/train/4_74.mp3,"So when it comes to this, it starts becoming quite complex, and the need is",0,0
data/train/4_75.mp3,to have a standard set of APIs and tools to deal with all of this.,0,0
data/train/4_76.mp3,"From the viewpoint of the application, the standard software to use for implementing multimedia software is GStreamer.",0,1
data/train/4_77.mp3,GStreamer is the de facto open source industry standard for building multimedia software.,0,1
data/train/4_78.mp3,"It comes with a wide range of plugins for all kinds of input, output, and processing of all kinds of media, audio, video, and others.",0,0
data/train/4_79.mp3,And it basically can bridge all of the APIs that I mentioned earlier.,0,0
data/train/4_80.mp3,"So it bridges Video4Linux, Sleep Camera, software processing components, Wayland,",0,1
data/train/4_81.mp3,"and proprietary APIs and many, many other things that you may need in order to get the work done.",0,0
data/train/4_82.mp3,So it basically makes the job easier for applications.,0,0
data/train/4_83.mp3,"It heavily lifts all the application level needs, leaving to the applications just to do just what they need to do and not deal with the",0,0
data/train/4_84.mp3,multimedia data.,0,0
data/train/4_85.mp3,"And not to mention that it's highly extensible and customizable so if something cannot be done at the moment it's possible to extend it, add some plugins and make it talk to your device or your software component",0,0
data/train/4_86.mp3,"And from the viewpoint of the system, where we may have multiple applications trying to get access to a single device or trying to share content between them, or where we have remote streams coming and going from the network, the solution for managing all of these streams is Pipewire.",0,0
data/train/4_87.mp3,"Pipewire can be described as a stream exchange framework that allows interconnecting applications and network nodes, allowing them to share devices and share streams in a secure way, and applying policy that secures what applications can and cannot do.",0,0
data/train/4_88.mp3,Pipewire allows isolating applications from each other and from devices.,0,0
data/train/4_89.mp3,"It was actually built with containers in mind, so it was built to be able to",0,0
data/train/4_90.mp3,to make applications access a device securely without actually having direct access to the device.,0,0
data/train/4_91.mp3,"The device may be visible from one container and the application in another container, and it gets secure access through the pipeware system.",0,0
data/train/4_92.mp3,"Or similarly, it can be done with applications in different containers, sharing a stream from one application to the other.",0,0
data/train/4_93.mp3,"And this allows actually implementing more smaller applications, smaller and self-contained applications that do a small task each.",0,0
data/train/4_94.mp3,"So for example, you may want to have a system that captures video from a camera and then displays it in the screen and records it.",0,0
data/train/4_95.mp3,"And these are three separate functions that can be in different applications and actually in different containers, sharing the stream through Pipewire.",0,0
data/train/4_96.mp3,Pipewire is also very efficient.,0,0
data/train/4_97.mp3,It has low-level real-time processing capabilities and it allows leveraging the hardware to its full extent.,0,0
data/train/4_98.mp3,by using hardware buffers.,0,0
data/train/4_99.mp3,So it can make use of hardware buffers to pass a stream from one device to another through a series of applications that do something with the stream without actually copying the data to the CPU memory if not necessary.,0,0
data/train/4_100.mp3,"Now, Pipewire, you already know that Pipewire is currently used to implement the audio system in AGL.",0,0
data/train/4_101.mp3,"Actually, both Pipewire and GStreamer are used in audio.",0,0
data/train/4_102.mp3,There are similarities with the audio system actually.,0,0
data/train/4_103.mp3,It's essentially the same system.,0,0
data/train/4_104.mp3,The principles are not different.,0,0
data/train/4_105.mp3,The only thing that differs is the kind of data that exists in the buffers.,0,0
data/train/4_106.mp3,"In one case it's audio, in the other case it's video.",0,0
data/train/4_107.mp3,Everything else stays the same.,0,0
data/train/4_108.mp3,"So input, processing, output in multiple streams, local streams, network streams, streams coming from the network, I mean from the internet or going to the internet, things like that.",0,0
data/train/4_109.mp3,"And applying policy to all of those streams, this is all the same as with audio.",0,0
data/train/4_110.mp3,So reusing the infrastructure that is currently in place for audio makes sense to implement a video system.,0,0
data/train/4_111.mp3,"But first, we need to define our goals.",0,0
data/train/4_112.mp3,Suppose we want to do an AGL demo with some video features.,0,0
data/train/4_113.mp3,Video is a very broad term.,0,0
data/train/4_114.mp3,There's a lot of things that we can do with video.,0,0
data/train/4_115.mp3,"So the very first thing we need to do is define our goals, define what exactly we want to show and we want to support as a community.",0,0
data/train/4_116.mp3,And also we need to narrow down the,0,0
data/train/4_117.mp3,"the scope, what the features exactly will be, and what the supported hardware will be, because it's very different to work, for example, with a desktop USB camera.",0,0
data/train/4_118.mp3,"It's very easy to work with in a demo, but it's very different than using an automotive-grade network camera.",0,0
data/train/4_119.mp3,"Next thing, we need to implement a demo application.",0,0
data/train/4_120.mp3,and add some features that are currently missing from Pipewire and Wireplumber.,0,0
data/train/4_121.mp3,Both Pipewire and Wireplumber have been designed for being able to deal with video data.,0,0
data/train/4_122.mp3,"And with all these use cases that I mentioned today, they have all been integrated in the design of Pipewire and Wireplumber.",0,0
data/train/4_123.mp3,"The thing is, of course, that not all of it is implemented.",0,0
data/train/4_124.mp3,We currently support video on the desktop.,0,0
data/train/4_125.mp3,"So on the desktop, we can do sharing of cameras with Video4Linux that is captured through Video4Linux from the system and then shared to applications.",0,1
data/train/4_126.mp3,"And we can also do sharing of video between applications, which is currently used for screencasting.",0,0
data/train/4_127.mp3,So the typical scenario is that the Wayland compositor that draws the screen captures the video from the screen and then uses Pipewire to send it to the application that implements the network streaming.,0,0
data/train/4_128.mp3,"Now,",0,0
data/train/4_129.mp3,"Finally, we need to ensure that we have all the necessary Gstreamer features integrated and anything else that may be missing from the Yocto build system and things like that.",0,0
data/train/4_130.mp3,So that was all from me today.,0,0
data/train/4_131.mp3,"Thank you very much for attending my talk and I hope to be able to see you all again soon, sometime later this year or next year.",0,0
data/train/4_132.mp3,Thank you very much.,0,0
data/train/3_0.mp3,"Hello, everyone.",0,0
data/train/3_1.mp3,So today I'm going to tell you the story of an open source network protocol and how we brought SRT from a proprietary software to an open source success.,0,0
data/train/3_2.mp3,So who am I?,0,0
data/train/3_3.mp3,My name is Olivier Crête.,0,1
data/train/3_4.mp3,"I'm the multi-media domain lead at Collabora, where I've worked since 2007.",0,1
data/train/3_5.mp3,"But I've also been an open source developer since 1999, first working on a GNOME and",0,0
data/train/3_6.mp3,"Since I've been an active developer of the GStreamer community, I'm one of the core maintainers, and this is something I've been doing for over a decade now.",0,1
data/train/3_7.mp3,What are we going to talk today?,0,0
data/train/3_8.mp3,Something called SRT.,0,0
data/train/3_9.mp3,"So SRT stands for Secure Reliable Transport, and it's a generic protocol to send streams reliably over the internet.",0,0
data/train/3_10.mp3,"It was designed to transport MPEG transport streams,",0,0
data/train/3_11.mp3,for with low latency but good quality and with encryption for security and it's really been designed for use by broadcasters.,0,0
data/train/3_12.mp3,So SRT is a protocol but it's also a library implementing it.,0,0
data/train/3_13.mp3,I would say it's first and foremost a library.,0,0
data/train/3_14.mp3,It was created as software,0,0
data/train/3_15.mp3,before actually being defined as a protocol in English.,0,0
data/train/3_16.mp3,"This library is now open source, and this is what we help bring to the community.",0,0
data/train/3_17.mp3,"It's multi-platform, Linux, Windows, macOS, Android, iOS, tvOS.",0,0
data/train/3_18.mp3,All of the major platforms are supported.,0,0
data/train/3_19.mp3,So where do we start?,0,0
data/train/3_20.mp3,SRT originally was developed by a company called HaiVision.,0,1
data/train/3_21.mp3,They developed it as a proprietary protocol.,0,0
data/train/3_22.mp3,it was a differentiating feature of their products compared to the competition.,0,0
data/train/3_23.mp3,And they had deployed it almost across their entire product line.,0,0
data/train/3_24.mp3,"So if you used a couple years ago, if you use HaiVision products, you could send SRT from one management to another, but nothing else, obviously, because it was proprietary to their company.",0,1
data/train/3_25.mp3,"So who are the players here, right?",0,0
data/train/3_26.mp3,The first player is Haivision.,0,1
data/train/3_27.mp3,"So Haivision created SRT, and they're a good company.",0,1
data/train/3_28.mp3,They have a very solid engineering team.,0,0
data/train/3_29.mp3,"But like most software companies,",0,0
data/train/3_30.mp3,"They're not really into open source, right?",0,0
data/train/3_31.mp3,They use a lot of open source.,0,0
data/train/3_32.mp3,"They have a lot of their products, which are actually running Linux inside and have a lot of open source software inside of them.",0,0
data/train/3_33.mp3,"But everything that they did themselves, they had the very traditional mindset that it has to bring like value.",0,0
data/train/3_34.mp3,"And, you know, the open source is not going to get any value, etc, etc.",0,0
data/train/3_35.mp3,So they didn't really know how to do open source.,0,0
data/train/3_36.mp3,"On the other hand, there's us.",0,0
data/train/3_37.mp3,We're Collabora.,0,1
data/train/3_38.mp3,We're an open source consultancy.,0,0
data/train/3_39.mp3,Everyone at Collabora is an open source developer.,0,0
data/train/3_40.mp3,"We all have open source expertise, and we've been doing multimedia almost since the beginning of the company.",0,0
data/train/3_41.mp3,"So we helped HaiVision make SRT into an open source project, an open source successful project.",0,1
data/train/3_42.mp3,"And I'm going to tell you this story, right?",0,0
data/train/3_43.mp3,How we and HaiVision together made SRT into a really successful open source project.,0,1
data/train/3_44.mp3,"So before we start the project, we have to go through a couple of steps, right?",0,0
data/train/3_45.mp3,"So the first step is asking ourselves, why are we doing this?",0,0
data/train/3_46.mp3,"For us, as open source people, we think this is the most self-evident thing in the world.",0,0
data/train/3_47.mp3,"If you do something, it's going to be open source.",0,0
data/train/3_48.mp3,"But for many companies, they need a justification.",0,0
data/train/3_49.mp3,It's not the default yet.,0,0
data/train/3_50.mp3,"And for HaiVision, the main reason they wanted to make SRT open source at first was to have adoption.",0,1
data/train/3_51.mp3,video over the internet to work and to work reliably and to work interoperably amongst all the devices that you can buy from different vendors to not have to have like so that their customers and all the users don't have to have like devices from one vendor that they can mix and match but that they would have interoperability and have good quality of transmission.,0,0
data/train/3_52.mp3,They also wanted to raise their profile so they wanted to raise the strength of the Haivision brand,0,1
data/train/3_53.mp3,"And they thought that by developing a protocol and a system that everyone would use, that would make their brand much more known.",0,0
data/train/3_54.mp3,"And they wanted to make the ecosystem more open, right?",0,0
data/train/3_55.mp3,So increase interoperability there.,0,0
data/train/3_56.mp3,"One of the things that you also have to ask yourself when you develop a new open source project, and what are non-goals, right?",0,0
data/train/3_57.mp3,What's not an actual goal here?,0,0
data/train/3_58.mp3,That's almost as important as knowing what your goals are.,0,0
data/train/3_59.mp3,"And in this case, one thing that was not a goal was to increase contributions.",0,0
data/train/3_60.mp3,They felt that they had the development in the end quite solidly.,0,0
data/train/3_61.mp3,So they were not trying to get like more developers for the product.,0,0
data/train/3_62.mp3,They were really trying to get people to actually use it.,0,0
data/train/3_63.mp3,"Then we looked, what else is there?",0,0
data/train/3_64.mp3,What's the competition?,0,0
data/train/3_65.mp3,Is there any open source alternative?,0,0
data/train/3_66.mp3,And we looked and we couldn't find anything else that was really at the feature set that the broadcast industry needed.,0,0
data/train/3_67.mp3,"There are things like WebRTC that are developed for low latency, but didn't have the kind of quality and the simplicity that they need for broadcast users.",0,0
data/train/3_68.mp3,But there were a number of proprietary solutions down there.,0,0
data/train/3_69.mp3,"Among them, Zixi and Aspera, which come as SDKs,",0,1
data/train/3_70.mp3,but their actual product is a service.,0,0
data/train/3_71.mp3,"So the SDK is free, like money free, but not open source.",0,0
data/train/3_72.mp3,"But to actually use it, you need to pay these companies for the service to transfer the streams.",0,0
data/train/3_73.mp3,"And then there were a bunch of vendor specialized protocols like HaiVision and SRT, but a number of their competitors had similar features and functionalities with different homemade protocols that were all incompatible with each other.",0,1
data/train/3_74.mp3,So there was really nothing out there that was like a direct competition.,0,0
data/train/3_75.mp3,"So as I said, almost everyone in the market had a similar solution.",0,0
data/train/3_76.mp3,"And in a way, SRT and all of the others kind of work the same.",0,0
data/train/3_77.mp3,The underlying principles are the same.,0,0
data/train/3_78.mp3,"It's retransmissions, maybe forward or recorrection.",0,0
data/train/3_79.mp3,There's like no great magic there.,0,0
data/train/3_80.mp3,So SRT's big differentiator that we saw was that it would be open source.,0,0
data/train/3_81.mp3,That means it's easier to integrate it.,0,0
data/train/3_82.mp3,"You don't have to ask for permission, but also you can use it for things that it was not originally designed for.",0,0
data/train/3_83.mp3,"Since it's open source, it will be open source.",0,0
data/train/3_84.mp3,"You can actually do whatever you want with it, use it for things that original developers did not think of, which is often much more difficult with proprietary software.",0,0
data/train/3_85.mp3,SRT is a network protocol.,0,0
data/train/3_86.mp3,"When people think network protocols and open, they think open standards.",0,0
data/train/3_87.mp3,"So we asked ourselves, maybe there's no software, but maybe there exists a standard out there that's open that we could just use instead of having to create a different new software.",0,0
data/train/3_88.mp3,"And for video transmission, a lot of the low latency protocols out there are based on RTP.",0,0
data/train/3_89.mp3,It's possible to do everything that SRT does with RTP-based protocols.,0,0
data/train/3_90.mp3,But there was no grouping of RTP specifications that people could agree on and that would just give the required functionalities for broadcast without bringing much more complexity.,0,0
data/train/3_91.mp3,"In many ways, we kind of concluded that RTP-based stacks were not there for what they needed.",0,0
data/train/3_92.mp3,"So the next question is, why publish an open source project, right?",0,0
data/train/3_93.mp3,"Why not just create a standard, get around there with other companies and say, hey, we're just going to write a document and everyone can implement it.",0,0
data/train/3_94.mp3,There's multiple reasons for that.,0,0
data/train/3_95.mp3,And one of this is to have basically something that is usable on day one.,0,0
data/train/3_96.mp3,"And by having a shared implementation that's open source, then everyone can cooperate on it.",0,0
data/train/3_97.mp3,"And it also means that you have good interoperability from day one, right?",0,0
data/train/3_98.mp3,"Because it's the same code, right?",0,0
data/train/3_99.mp3,So it will interoperate with itself.,0,0
data/train/3_100.mp3,"And also, it encourages people who want to enhance it to actually work together instead of, you know, if you make your own implementation, then there will be a lot of pressure from management to create value by having something a bit different from the center, a bit improved, that you can go around and say, hey, you can interoperate with anyone else.",0,0
data/train/3_101.mp3,"But if you use our product on both sides, it's going to be so much better.",0,0
data/train/3_102.mp3,"In that case, we wanted everyone to really have the highest level of interoperability, to not have like two grades, like open source grade and then the better proprietary grade.",0,0
data/train/3_103.mp3,That was kind of an empty goal here.,0,0
data/train/3_104.mp3,"Then it's a project, right?",0,0
data/train/3_105.mp3,"Open sourcing something, creating an open source project is a project in itself.",0,0
data/train/3_106.mp3,And a project needs a timeline.,0,0
data/train/3_107.mp3,Our timeline here was quite short at the beginning.,0,0
data/train/3_108.mp3,"So we were aiming to release SRT by the NAB conference in April, which is the big conference in the broadcast industry in the US.",0,0
data/train/3_109.mp3,And we started this project in February.,0,0
data/train/3_110.mp3,So we had only two months.,0,0
data/train/3_111.mp3,It was quite a short timeline.,0,0
data/train/3_112.mp3,"And then we gave ourselves some time after that, right?",0,0
data/train/3_113.mp3,"We said, after the initial launch, if we don't get some tractions within 18 months, then it's not going to work too bad.",0,0
data/train/3_114.mp3,"And the second deadline was after launch, if after three years, we would like have a checkpoint and say, has this been a success or a failure, right?",0,0
data/train/3_115.mp3,"If it has not been a success in three years, it's probably not going to succeed.",0,0
data/train/3_116.mp3,"But one of the other things that was very important is that we said, you know, this might not happen on day one.",0,0
data/train/3_117.mp3,You have to be able to be in it for the long run.,0,0
data/train/3_118.mp3,"If you want adoption, you have to let people know that, you know, you're in it and you're going to maintain it for years, right?",0,0
data/train/3_119.mp3,that it's not just going to be a thing that you throw over the wall.,0,0
data/train/3_120.mp3,"So for an open source project, one of the most important things to make it successful is to have a governance model.",0,0
data/train/3_121.mp3,So who are the stakeholders in this governance model?,0,0
data/train/3_122.mp3,"One of the important ones are the developer, right?",0,0
data/train/3_123.mp3,"As this is software, developers are really a key constituency.",0,0
data/train/3_124.mp3,"But since this is software that's really designed for business use, enterprise use, the management of these developers are also a key constituency.",0,0
data/train/3_125.mp3,Their bosses are very important too.,0,0
data/train/3_126.mp3,"And then we need to think also, who are the users?",0,0
data/train/3_127.mp3,"Since this is really a library,",0,0
data/train/3_128.mp3,"The users are actually other developers, right?",0,0
data/train/3_129.mp3,They're developers that write applications or products and that will use these libraries in their product.,0,0
data/train/3_130.mp3,"And these are mostly corporate developers, right?",0,0
data/train/3_131.mp3,These are not hobbyists.,0,0
data/train/3_132.mp3,That's our key target.,0,0
data/train/3_133.mp3,"So now that we know who the main stakeholders are, we also have to think what other roles are in this",0,0
data/train/3_134.mp3,"in this project, right?",0,0
data/train/3_135.mp3,"To create a successful project, you need many different things.",0,0
data/train/3_136.mp3,You need people who will write documentation.,0,0
data/train/3_137.mp3,"You will need to help the users actually use it, because remember, adoption was our goal, so we thought that helping users is a really, really important part.",0,0
data/train/3_138.mp3,"You need someone to set the direction, both the technical direction and the non-technical, more on the business side of the project.",0,0
data/train/3_139.mp3,"You need to do marketing, right, so that people actually know about this.",0,0
data/train/3_140.mp3,and we'll adopt it.,0,0
data/train/3_141.mp3,And then you need to write code at the end.,0,0
data/train/3_142.mp3,"Next question, really, is how much control are you ready to give up?",0,0
data/train/3_143.mp3,Open sourcing something always means that you're going to give up some control.,0,0
data/train/3_144.mp3,"And the amount of control that you give up, really, is balanced with what your other goals are.",0,0
data/train/3_145.mp3,"In this case, the goal was adoption.",0,0
data/train/3_146.mp3,And so we don't need to siege too much control.,0,0
data/train/3_147.mp3,because we don't actually require other developers to join or something like that.,0,0
data/train/3_148.mp3,We just want people to use it.,0,0
data/train/3_149.mp3,So we can really not have a model where we have complete external governance.,0,0
data/train/3_150.mp3,We can keep the governance very much where it was originally.,0,0
data/train/3_151.mp3,"So we need also a decision-making process, right?",0,0
data/train/3_152.mp3,Decision-making process in different projects vary a lot.,0,0
data/train/3_153.mp3,"both for technical and non-technical decisions, right?",0,0
data/train/3_154.mp3,It could be a board that can be elected or appointed.,0,0
data/train/3_155.mp3,"You could have like a one person deciding, like a dictator, a benevolent dictator, like Linus, or you can have something much more ad hoc, right?",0,0
data/train/3_156.mp3,"This is not a huge project, so maybe if something very structured is too heavy and you might want to have something much more ad hoc, something in between,",0,0
data/train/3_157.mp3,"And since this is really not that big of a project, maybe you don't even need a real structure, right?",0,0
data/train/3_158.mp3,You might really go with something very with the flow.,0,0
data/train/3_159.mp3,"Since it's open source and one of the things that kind of binds open source communities is the license, we thought that the choice of the right license was very important.",0,0
data/train/3_160.mp3,"So licenses can go, you know, from permissive licenses, MIT, BSD style, all the way to very strong copyleft licenses like the GPLv3 or AGPLv3.",0,0
data/train/3_161.mp3,or somewhere in between.,0,0
data/train/3_162.mp3,"One of our goal here was adoption, and one of the key places where we wanted it to be adopted was in mobile applications.",0,0
data/train/3_163.mp3,So it was very important that whatever license we choose would not be a problem for app store users.,0,0
data/train/3_164.mp3,But we also wanted to kind of discourage proprietary forks to have really interoperability at the highest level.,0,0
data/train/3_165.mp3,So we tried to find something that was able to satisfy both goals.,0,0
data/train/3_166.mp3,"And for this project, we ended up choosing the MPL because of its different clauses that really make it easy for both sides.",0,0
data/train/3_167.mp3,So now we've taken care of the people aspect and the governance aspect.,0,0
data/train/3_168.mp3,Now we need to take technical steps to actually make it a good open source project.,0,0
data/train/3_169.mp3,Many projects that operate and originate from the proprietary world are often developed in the idea that there's only like a very small group of people who actually matter and that it doesn't have to follow standards that everyone else can follow.,0,0
data/train/3_170.mp3,But it's important if you want to open up something that everything is clear and easy for use for everyone.,0,1
data/train/3_171.mp3,One of the first things that people do when they get an open source project is to try to compile it.,0,0
data/train/3_172.mp3,"Many projects that originate from the corporate world, sometimes you're just stuck at that step.",0,0
data/train/3_173.mp3,"What you really want is a build system that people already know, that is standardized, and that is high quality.",0,0
data/train/3_174.mp3,"There's many different good high quality open source build systems, things like CMake, AutoTools, Meson, and there's a couple more.",0,0
data/train/3_175.mp3,"I would not go with something exotic, really.",0,0
data/train/3_176.mp3,"You want something that is common for the language or platform that you're using, and that other people will know.",0,0
data/train/3_177.mp3,"In this case, it was already CMake, so we were lucky.",0,0
data/train/3_178.mp3,A lot of corporate projects I said have like,0,0
data/train/3_179.mp3,"really bad things, sometimes just random makefiles or maybe very complex makefiles that rely on a complex infrastructure that tie up with the company's internal build systems.",0,0
data/train/3_180.mp3,"And that's really, that's bad.",0,0
data/train/3_181.mp3,And what's even worse is just a bunch of shell scripts.,0,0
data/train/3_182.mp3,"So if you have that, you have to delete everything and restart with a standard one, right?",0,0
data/train/3_183.mp3,No one wants to see your internal build systems.,0,0
data/train/3_184.mp3,"Then, once you have a building, then you need a place for people to cooperate.",0,0
data/train/3_185.mp3,"Cooperation requires different tools, right?",0,0
data/train/3_186.mp3,"Issue tracking, you need the source code hosting, you print something like a wiki or somewhere where you can put text and documentation, build instruction, etc.",0,0
data/train/3_187.mp3,all these kind of things.,0,0
data/train/3_188.mp3,"These days, by far the best way to do it is to use one of the GitHub or GitLab, right?",0,0
data/train/3_189.mp3,They've really cornered the market.,0,0
data/train/3_190.mp3,My personal preference is GitLab because it's open source.,0,0
data/train/3_191.mp3,"But in this case, we went with GitHub because that's what they were already using.",0,0
data/train/3_192.mp3,Then we need a way for people to talk to each other.,0,0
data/train/3_193.mp3,"To really support users, I feel that you run both something like a mailing list, that is slower and more longer text, and a chat system, like RSC or Slack.",0,0
data/train/3_194.mp3,"In this case, we have Slack channels where people can go and discuss whatever is happening with SRT, get help with installing it, using it, developing it, etc.",0,0
data/train/3_195.mp3,All the developers are there.,0,0
data/train/3_196.mp3,So it's a really good way to actually communicate.,0,0
data/train/3_197.mp3,So how did we select these tools?,0,0
data/train/3_198.mp3,"One of the kind of important things that these have to be tools that are familiar both to the existing developers, so that they're not going to waste too much time with them, but also to potential contributors and potential users.",0,0
data/train/3_199.mp3,"So the advantage of using very standardized tools is that everyone already knows them, and you don't waste time learning them, and they don't become a bearer.",0,0
data/train/3_200.mp3,"So the goal really is to reduce the barrier to entry, and by using tools that are well-known and well-established, the project doesn't become about the build tools or about the configuration tools, but really about the project itself.",0,0
data/train/3_201.mp3,"The next step is that we need to market it, right?",0,0
data/train/3_202.mp3,"We have a good project, we have a good governance, we have good source code, now we need to let everyone else know about it.",0,0
data/train/3_203.mp3,"Since this is a library, an immediate transport library, the way that people actually use this is often that they will use it through something else, a bigger library, either something like FFmpeg or GStreamer, that will provide the encoding, the decoding, all of the other stuff that we need in a media pipeline.",0,0
data/train/3_204.mp3,So one of the first things that we did when we decided to make this open source was to figure out which are the important other libraries that they should integrate with and go upstream,0,0
data/train/3_205.mp3,"and send them patches, offering them integration with LibSRT.",0,0
data/train/3_206.mp3,"Since LibSRT had been open source by that point, it was much easier for them to accept integration patches.",0,0
data/train/3_207.mp3,So we quickly had it integrated in both FFmpeg and GStreamer.,0,0
data/train/3_208.mp3,"And another thing that we asked is, what do people use to test in your industry?",0,0
data/train/3_209.mp3,How do they test if a stream works?,0,0
data/train/3_210.mp3,What tool do they use?,0,0
data/train/3_211.mp3,"And they said, well, they're not special.",0,0
data/train/3_212.mp3,They just use VLC like everyone else.,0,0
data/train/3_213.mp3,"So one of the things that we did very early on was to submit patches to the VLC community to add support for SRT, so that you could just type SRT around in VLC and it just works.",0,0
data/train/3_214.mp3,"And all of these communities, VLC, Gstreamer, Ffmpeg, were very helpful, and we could get our patches integrated really quickly.",0,1
data/train/3_215.mp3,"I was surprised how easy it was, considering it's a completely new protocol.",0,0
data/train/3_216.mp3,"So very quickly, we had SRT support in all three.",0,0
data/train/3_217.mp3,"And a bit later, we also had it integrated in OBS Studio, which is a great way to create content, create a live stream, and send it to an SRT receiver.",0,0
data/train/3_218.mp3,"So now that we had it integrated, easy to use, sometimes as easy as just putting the UI in, then we had to create awareness.",0,0
data/train/3_219.mp3,So there's two parts of creating awareness. One is for open source developers.,0,1
data/train/3_220.mp3,"So part of it was to talk to developers of other relevant projects that we've already talked about and make them aware of SRT, what's its strengths, what's its weaknesses, what it's for, what it's not for, so that they can, you know, do marketing for us in a way.",0,0
data/train/3_221.mp3,And the other important group I wanted to talk to is business people.,0,0
data/train/3_222.mp3,"Since we're seeing that most of the target users here are corporations, they're people building products, we decided to create a business alliance.",0,0
data/train/3_223.mp3,"So that's an alliance of companies that use SRT, promote SRT, build products around SRT, and this has been a really important element of the effort.",0,0
data/train/3_224.mp3,"So, has it been a success?",0,0
data/train/3_225.mp3,"Well, the answer is yes, right?",0,0
data/train/3_226.mp3,"So, I've done the presentation similar to this one a couple of months ago, and I was seeing there were over 250 members in the alliance.",0,0
data/train/3_227.mp3,"Today, I was told there's over 400.",0,0
data/train/3_228.mp3,Last time I said there were 88 companies shipping products.,0,0
data/train/3_229.mp3,"Now there's 129, if I counted correctly on the website.",0,0
data/train/3_230.mp3,"And according to GitHub, there's 67 contributors.",0,0
data/train/3_231.mp3,"So even though the goal was really not to gather contributors, we gathered contributors anyway, because if you have something that people actually use, they will contribute to it.",0,0
data/train/3_232.mp3,"So that was really, really successful.",0,0
data/train/3_233.mp3,I was really impressed at how quickly this picked up.,0,0
data/train/3_234.mp3,"When we announced it, within a couple of weeks, companies were lining up to join the alliance.",0,0
data/train/3_235.mp3,They really brought something to their industry which was lacking.,0,0
data/train/3_236.mp3,There was really like a need for this.,0,0
data/train/3_237.mp3,"And immediately, we had a lot of updates.",0,0
data/train/3_238.mp3,"So that's been a really, really great success for HaiVision and also for open source.",0,1
data/train/3_239.mp3,So thank you.,0,0
data/train/3_240.mp3,"If you have any questions, you can ask me on Slack of the conference, or you can always reach me directly.",0,0
data/train/3_241.mp3,I'm all over the internet.,0,0
data/train/3_242.mp3,"So Google my name, and you will find me easily.",0,0
data/train/3_243.mp3,"So thank you very much, and have a good afternoon.",0,0
data/train/5_0.mp3,"Hello folks, and welcome to my OpenXR masterclass.",0,0
data/train/5_1.mp3,"The plan for the talk today is to spend a few moments introducing myself, introducing OpenXR, and looking at OpenXR as a standard in context, what it is and isn't.",0,0
data/train/5_2.mp3,Then we'll take a deep dive into OpenXR application structure and API usage.,0,0
data/train/5_3.mp3,And we should have time for question and answer at the end.,0,0
data/train/5_4.mp3,My name is Ryan Pavlik.,0,0
data/train/5_5.mp3,I've been working in the VR realm since around 2009.,0,0
data/train/5_6.mp3,I've been involved with the OpenXR Working Group since the first official meeting in 2017.,0,0
data/train/5_7.mp3,I was elected Specification Editor for the OpenXR Working Group in 2019.,0,0
data/train/5_8.mp3,"My job currently is as a Principal Software Engineer at Collabora, where I work on the XR team and work as a developer on Monado, which is our OpenXR runtime.",0,0
data/train/5_9.mp3,So what is OpenXR?,0,0
data/train/5_10.mp3,"Well, OpenXR is a royalty-free open standard that provides high-performance access to augmented reality and virtual reality, so AR and VR, or XR collectively, platforms and devices.",0,0
data/train/5_11.mp3,"The provisional release, 0.90, was released at the Game Developers Conference 2019.",0,0
data/train/5_12.mp3,"In order to publicly show progress and seek feedback, we released version 1.0 of the specification at SIGGRAPH in 2019.",0,0
data/train/5_13.mp3,The 1.0 release defines an interface between an engine or application and a runtime and the required behavior of a runtime.,0,0
data/train/5_14.mp3,It does not control the interaction of a runtime and underlying devices.,0,0
data/train/5_15.mp3,I'll get to that in a moment.,0,0
data/train/5_16.mp3,"Like many Khronos standards, conformance tests are a part of the package.",0,0
data/train/5_17.mp3,Runtime conformance tests and adopter program are forthcoming.,0,0
data/train/5_18.mp3,That's one of the main focuses of the working group at this time.,0,0
data/train/5_19.mp3,"As I mentioned, the 1.0 specification includes the interface to the application with the compatibility promise that comes with 1.0.",0,0
data/train/5_20.mp3,So now is the time to start building applications on top of OpenXR.,0,0
data/train/5_21.mp3,1.0.x patch releases are minor changes that fix spec bugs or add extensions.,0,0
data/train/5_22.mp3,These are typically released on Fridays.,0,0
data/train/5_23.mp3,My general rule of thumb is that if there's a specification change or extension changes that,0,0
data/train/5_24.mp3,"are in the Khronos private GitLab instance for a given week, I will typically cut a patch release for that week.",0,0
data/train/5_25.mp3,"So the time between patch releases can be variable, but I work to get whatever the working group has put together out as quickly as possible.",0,0
data/train/5_26.mp3,"Now, if you go to the Khronos website or look around at some articles, you might see mention of a different diagram that has a device layer, which would allow a single runtime to connect to multiple XR devices.",0,0
data/train/5_27.mp3,The diagram at the right is a more accurate description of the current 1.0 ecosystem.,0,0
data/train/5_28.mp3,There's no standardized interface between runtimes and XR devices.,0,0
data/train/5_29.mp3,"There's no device plugins, but runtimes may support one device or more than one.",0,0
data/train/5_30.mp3,"And importantly, the interface between an application and the runtime is standardized, so you can use your applications across multiple runtimes and thus multiple devices.",0,0
data/train/5_31.mp3,There's no public estimated time to have the,0,0
data/train/5_32.mp3,device layer as in the statement of work and the marketing material is ready.,0,0
data/train/5_33.mp3,"As I mentioned earlier, the main focus of the working group at this point is finishing up the conformance tests.",0,0
data/train/5_34.mp3,We're also very interested in promoting uptake and adoption of the new standard.,0,0
data/train/5_35.mp3,Kronos is a non-profit industry consortium that brings together,0,0
data/train/5_36.mp3,the major players in technology fields to put together independent open standards.,0,0
data/train/5_37.mp3,These standards started with OpenGL.,0,0
data/train/5_38.mp3,They took over for the AARB.,0,0
data/train/5_39.mp3,The collection of standards has now expanded widely.,0,0
data/train/5_40.mp3,A commonality between many of the standards is that extensions are a key part of the design.,0,0
data/train/5_41.mp3,There's a core API and then there are extensions that can be added at an independent pace and implemented by one or many vendors.,0,0
data/train/5_42.mp3,that allow new features or vendor-specific features to be lit up selectively on systems that can handle them without impacting the portability of software.,0,0
data/train/5_43.mp3,"Like all Khronos API standards, conforming runtimes that run the conformance test and pass it and complete the other requirements of the conformance and adoption program receive patent protection and trademark licenses per the IP framework",0,0
data/train/5_44.mp3,Take a look at these slides that is linked.,0,0
data/train/5_45.mp3,"I am not a lawyer, but this framework makes Khronos the place where the big players in industry in these very highly competitive tech fields can safely get together, talk about things and come up with standards that will work across all of them.",0,0
data/train/5_46.mp3,"Like other Khronos standards, OpenXR is royalty free.",0,0
data/train/5_47.mp3,"In terms of relatives of OpenXR, the conventions and style and even some of the nitty-gritty such as the tools used by the working group are strongly influenced by Vulkan.",0,0
data/train/5_48.mp3,"Vulkan is a low-level, high-performance rendering and computation API, primarily for use on GPUs.",0,0
data/train/5_49.mp3,We have a mostly shared toolchain for generating specifications.,0,0
data/train/5_50.mp3,We have similar development and release practices.,0,0
data/train/5_51.mp3,"Like Vulkan, we have a loader with support for API layers, which let you hook any function in the API in a controlled, understandable way.",0,0
data/train/5_52.mp3,"However, just because OpenXR takes a lot of its practices from Vulkan does not mean that it's exactly like Vulkan.",0,0
data/train/5_53.mp3,OpenXR is rendering API neutral.,0,0
data/train/5_54.mp3,"So despite the fact that there are some Khronos rendering APIs, OpenGL, OpenGL ES, Vulkan,",0,0
data/train/5_55.mp3,"There are also non-Khronos rendering APIs, the Direct3D family, that are also supported by OpenXR.",0,0
data/train/5_56.mp3,All graphics API support are in extensions.,0,0
data/train/5_57.mp3,"All these extensions are designed to work similarly, despite the fact they're working with different rendering APIs.",0,0
data/train/5_58.mp3,One major design difference between OpenXR and Vulkan is that OpenXR is a lower frequency API.,0,0
data/train/5_59.mp3,So you're not executing hundreds or thousands of OpenXR calls per frame.,0,0
data/train/5_60.mp3,You might have a handful of calls.,0,0
data/train/5_61.mp3,Eliminating all argument checking overhead is not necessarily required for performance in OpenXR.,0,0
data/train/5_62.mp3,"As a result, runtimes for OpenXR are required to detect nearly all invalid usage and return an error code.",0,0
data/train/5_63.mp3,"In Vulkan, there is valid usage that is only checked by the validation layers, and if you pass invalid usage, there may be undefined behavior or unspecified behavior by the driver.",0,0
data/train/5_64.mp3,"Whereas in OpenXR, we have a validation layer.",0,0
data/train/5_65.mp3,"It provides useful information, but most invalid usage also has an error code that would get returned, and that is required by the specification for the runtime to return.",0,0
data/train/5_66.mp3,"Of course, there is some risk of undefined behavior because it's a C API, but this minimal risk can be reduced by a language projection or wrapper that makes it more difficult to misuse pointers in a way that would break things.",0,0
data/train/5_67.mp3,"Additionally, OpenXR is a much smaller spec.",0,0
data/train/5_68.mp3,It's only about 300 pages in PDF format.,0,0
data/train/5_69.mp3,We've also learned some lessons from Vulkan.,0,1
data/train/5_70.mp3,We've talked with the folks on the Vulkan working group and asked them what lessons they wish they had learned.,0,1
data/train/5_71.mp3,"In our case, one of those is that the loader, which is responsible for finding the runtime and getting function pointers, our loader ships with applications and not the system or the driver on Windows.",0,0
data/train/5_72.mp3,"On Linux, it's tentatively system-wide because there are distribution-specific ways of controlling ownership of the loader.",0,0
data/train/5_73.mp3,"As of recording this on April 14th, here's the current availability of OpenXR runtimes.",0,0
data/train/5_74.mp3,"The Microsoft OpenXR runtime is available for both Windows MR HMDs, as well as the HoloLens 2.",0,0
data/train/5_75.mp3,"Additionally, the Windows MR runtime does work with the Windows MR simulator mode, so you don't need hardware in order to run that OpenXR runtime.",0,0
data/train/5_76.mp3,"Oculus has a runtime that they're prototyping in the public test channel, and an SDK for that desktop runtime is forthcoming, per their announcement at roughly what would have been GDC time 2020.",0,0
data/train/5_77.mp3,"And recently, the Oculus Mobile OpenXR SDK, so that would be for Quest primarily, is publicly available in a preview form.",0,0
data/train/5_78.mp3,"If you are using Linux, you can use the Monado Runtime, which is an open source project led by my team at Collabra.",0,0
data/train/5_79.mp3,It works on multiple different devices and is in active development.,0,0
data/train/5_80.mp3,"Note that because conformance tests are not yet finalized and published, and therefore there are no conformance results, these are all technically preview implementations, but these should be useful in order to get you started developing with OpenXR.",0,0
data/train/5_81.mp3,This is the structure of an OpenXR app.,0,0
data/train/5_82.mp3,We'll go into all of these in more detail.,0,0
data/train/5_83.mp3,"First, get started by configuring and creating your instance.",0,0
data/train/5_84.mp3,"Next, you find out where and how to run.",0,0
data/train/5_85.mp3,This involves looking up a system ID atom and using the view configuration type enum.,0,0
data/train/5_86.mp3,"Then, you set up your interaction.",0,0
data/train/5_87.mp3,"In OpenXR, this is done using action sets and actions.",0,0
data/train/5_88.mp3,"Finally, the last setup step is preparing the immersive experience by creating your session, attaching action sets, creating reference and action spaces, and creating your swap chain.",0,0
data/train/5_89.mp3,Then the frame loop handling input and events is the body of your application.,0,0
data/train/5_90.mp3,There are a number of object or handle types in OpenXR that are important.,0,0
data/train/5_91.mp3,These are the main handle types and,0,0
data/train/5_92.mp3,shows as well which handle types are their parent.,0,0
data/train/5_93.mp3,"In OpenXR, destroying a handle parent also destroys that handle.",0,0
data/train/5_94.mp3,"So if you destroy a session, that also destroys those associated spaces and swap chains.",0,0
data/train/5_95.mp3,"And if you destroy the instance, that destroys all of these handles, since they're all derived from the instance.",0,0
data/train/5_96.mp3,"In addition to handles, there are two additional types known as atoms.",0,0
data/train/5_97.mp3,They're not objects.,0,0
data/train/5_98.mp3,They don't have an explicit lifetime.,0,0
data/train/5_99.mp3,They're just coded numbers that represent some fixed thing in the runtime.,0,0
data/train/5_100.mp3,The one you'll work with the most is a path.,0,0
data/train/5_101.mp3,An xrPath is a number that corresponds within that instance to a string representing a semantic path.,0,0
data/train/5_102.mp3,"When you create an instance, you first need to choose which extensions you want, very similar to how Vulkan works.",0,0
data/train/5_103.mp3,"In order to make an OpenXR application, you need at least one extension enabled, and that's a graphics binding extension.",0,0
data/train/5_104.mp3,You can determine which extensions are all available on the system that you're using by using XR Enumerate Instance Extension properties.,0,0
data/train/5_105.mp3,"However, if you don't have any optional extension usage and you can either run with extensions you know how to use or not run at all, you can just proceed to create the instance and ask for the extensions you need.",0,0
data/train/5_106.mp3,"There's also a facility for API layers, as I mentioned earlier.",0,0
data/train/5_107.mp3,These can be configured outside of your application through environment variables or similar to make the loader automatically load them.,0,0
data/train/5_108.mp3,"However, if your application wants to load them, you can enumerate which ones are available before you create an instance.",0,0
data/train/5_109.mp3,"Similar to Vulkan, there's an application info struct that you should fill out with your application name and engine name and version so that runtimes can identify your application.",0,0
data/train/5_110.mp3,"Then finally, XR Create Instance takes that information and hands you an instance handle.",0,0
data/train/5_111.mp3,you use xr-git-system to find your desired form factor.,0,0
data/train/5_112.mp3,"OpenXR 1.0 natively supports, without extensions, stereo head-mounted displays, as well as handheld, mono, magic window-style augmented reality.",0,0
data/train/5_113.mp3,But not all runtimes will support both of these form factors of devices.,0,0
data/train/5_114.mp3,So part of the startup process,0,0
data/train/5_115.mp3,is asking if there is a system of the form factor you wish available.,0,0
data/train/5_116.mp3,"The form factor that you ask for might be available, in which case you'd get a system ID,",0,0
data/train/5_117.mp3,It might be never available if the device that you're using can't do the form factor that you ask for.,0,0
data/train/5_118.mp3,"Or it might be temporarily unavailable if it's perhaps not plugged in or if it needs to transition to a different mode in order to be used in that way, if you have a device that can be used in multiple fashions.",0,0
data/train/5_119.mp3,"Once you have a system, then you set up your view configuration.",0,0
data/train/5_120.mp3,"This is where mono, stereo,",0,0
data/train/5_121.mp3,or even more views come in.,0,0
data/train/5_122.mp3,"If you support more than one view configuration, you can use XR Enumerate view configurations to find out which ones the system you've chosen supports to make your determination of which one you're going to render using.",0,0
data/train/5_123.mp3,"No matter which view configuration you use, you will then call",0,0
data/train/5_124.mp3,enumerate view configuration views to get the correct number of views for your view configuration.,0,0
data/train/5_125.mp3,Each view configuration has a fixed number of views.,0,0
data/train/5_126.mp3,Mono has one.,0,0
data/train/5_127.mp3,Stereo has two.,0,0
data/train/5_128.mp3,"If you're using one of the vendor extensions, the XRVarioQuadViews, that has four, and so on.",0,1
data/train/5_129.mp3,These are well known in the specification.,0,0
data/train/5_130.mp3,"Now that you have an instance, you can get your interaction set up",0,0
data/train/5_131.mp3,your action set and actions.,0,0
data/train/5_132.mp3,"Action sets are a group of related actions for a context, environment, and so on.",0,0
data/train/5_133.mp3,"You might have an action set called Menu, or one called Gameplay, one called Driving.",0,0
data/train/5_134.mp3,"You can have one or more action sets active at a single time, so you don't need to have a Game with Car action set.",0,0
data/train/5_135.mp3,You can just have Game and then the additional actions in Car.,0,0
data/train/5_136.mp3,An action,0,0
data/train/5_137.mp3,is a semantic or meaningful bit of interaction.,0,0
data/train/5_138.mp3,It's something that you do.,0,0
data/train/5_139.mp3,OpenXR focuses on the actions that a user takes in your application instead of on the buttons and controllers that are used to perform those actions.,0,0
data/train/5_140.mp3,This is an important part of the hardware independence.,0,0
data/train/5_141.mp3,There are several different types of actions.,0,0
data/train/5_142.mp3,"Boolean,",0,0
data/train/5_143.mp3,essentially a button action.,0,0
data/train/5_144.mp3,It has either on or off.,0,0
data/train/5_145.mp3,There are float actions.,0,0
data/train/5_146.mp3,Floats are things like an analog trigger.,0,0
data/train/5_147.mp3,"Vector2 are two-dimensional floats, things like a thumbstick or trackpad.",0,0
data/train/5_148.mp3,A pose is a special kind of action.,0,0
data/train/5_149.mp3,"That's a tracked object, so frequently",0,0
data/train/5_150.mp3,"Haptic actions are an output action, allowing you to provide rumble feedback to the user.",0,0
data/train/5_151.mp3,All these actions are created using xrCreateAction.,0,1
data/train/5_152.mp3,"Once you've established which logical actions a user of your application will make,",0,0
data/train/5_153.mp3,you'd like to customize how they actually perform those actions for the hardware that you're used to and that you're testing on.,0,0
data/train/5_154.mp3,This is where interaction profiles and suggested bindings come in.,0,0
data/train/5_155.mp3,"For each controller type that you've tested, there will be an interaction profile.",0,0
data/train/5_156.mp3,"These are listed in the specification, and they cover a number of well-known devices.",0,0
data/train/5_157.mp3,Additional interaction profiles will be added through extensions.,0,0
data/train/5_158.mp3,"Then for each interaction profile, you submit pairs of actions and suggested bindings.",0,0
data/train/5_159.mp3,These are the logical part of the controller that you'd like to use to drive that action.,0,0
data/train/5_160.mp3,You can suggest multiple bindings per action in a call.,0,0
data/train/5_161.mp3,"For instance, both your left and right hands and your left and right controller could both trigger action grab object.",0,0
data/train/5_162.mp3,"The binding path that you'd like to suggest is an xrPathAtom, which represents a string like user/hand/right/input/select/click.",0,1
data/train/5_163.mp3,These are hierarchical strings.,0,0
data/train/5_164.mp3,Here you can see that we are referring to the select button on what's being held in the right hand and the click of that select button.,0,0
data/train/5_165.mp3,"For the last two components, there are naming conventions and standardized names that are detailed in the specification.",0,0
data/train/5_166.mp3,All these paths are listed in the interaction profile definitions in the specification.,0,0
data/train/5_167.mp3,"To make this a bit more concrete, I've gone through the sample HelloXR application that's in the OpenXR SDK source and compiled the actions and bindings that are used there.",0,0
data/train/5_168.mp3,The initialize actions member function is where these get set up if you want to look at the source code on your own later.,0,0
data/train/5_169.mp3,All these actions are in a single action set because the application is very simple.,0,0
data/train/5_170.mp3,And all of these actions are specified for both the left and right hands.,0,0
data/train/5_171.mp3,This uses the concept of sub action paths.,0,0
data/train/5_172.mp3,"You can ignore this for the most part until later, but as soon as you want to be able to perform an action with two hands,",0,0
data/train/5_173.mp3,"but know which one hand actually did it, that's how you use subaction paths.",0,0
data/train/5_174.mp3,"It's similar to the SteamVR input concept of restrict to device, if you're familiar with that at all.",0,0
data/train/5_175.mp3,So the four actions represent a variety of action types.,0,0
data/train/5_176.mp3,"We have grab object, hand pose, quit session, and vibrate hand.",0,0
data/train/5_177.mp3,"So after creating that action set and those four actions,",0,0
data/train/5_178.mp3,it's time to suggest bindings.,0,0
data/train/5_179.mp3,And there are a number of calls in HelloXR to suggest bindings.,0,0
data/train/5_180.mp3,I've picked a few of them for three different interaction profiles to illustrate some points.,0,0
data/train/5_181.mp3,This first one uses the interaction profile KHRSimpleController.,0,0
data/train/5_182.mp3,This is not corresponding to any particular specific piece of hardware.,0,0
data/train/5_183.mp3,It's a generic lowest common denominator sort of device that can be mapped to a wide variety of hardware.,0,0
data/train/5_184.mp3,There are a few things to notice here.,0,0
data/train/5_185.mp3,"Overall, as you'll see as a pattern, the suggested binding path for the interaction profile, if it's under user hand left, then it goes to the subaction path of user hand left.",0,0
data/train/5_186.mp3,and similarly for user hand right.,0,0
data/train/5_187.mp3,One point about the simple controller is that its select input is boolean.,0,0
data/train/5_188.mp3,It only has on or off.,0,0
data/train/5_189.mp3,It has a click.,0,0
data/train/5_190.mp3,"So we're binding grab object, which is a float input, to user hand left input select click, which is boolean.",0,0
data/train/5_191.mp3,This is fine.,0,0
data/train/5_192.mp3,The runtime will automatically convert that Boolean value to a float 1 or 0.,0,0
data/train/5_193.mp3,There are conversion rules that are described in the specification for these common simple cases.,0,0
data/train/5_194.mp3,The second example is the HTC Vive controller.,0,0
data/train/5_195.mp3,Here you can see that we've bound the grab object action to a different path.,0,0
data/train/5_196.mp3,"That's because the Vive controller has those grip or squeeze buttons on the side, rather than a button simply labeled Select.",0,0
data/train/5_197.mp3,"So the squeeze button, which is still a Boolean, like the simple controller, is now being suggested as our binding for Grab Object.",0,1
data/train/5_198.mp3,"Just as before, the Boolean will be converted to a float.",0,0
data/train/5_199.mp3,And the last example of the suggested bindings is the Oculus Touch controller.,0,0
data/train/5_200.mp3,Now there's a couple things here that are different.,0,0
data/train/5_201.mp3,The Oculus Touch controller has a float squeeze input.,0,0
data/train/5_202.mp3,It can say a floating value between 0 and 1 of how much you're squeezing.,0,0
data/train/5_203.mp3,"So here, the grab object action will get something that's not just limited to 0 or 1, but in that entire range.",0,0
data/train/5_204.mp3,"Additionally, only the left controller has a menu button.",0,0
data/train/5_205.mp3,"So in this case, we're only suggesting a binding for the left hand for quit session, which uses the menu button.",0,0
data/train/5_206.mp3,"User hand right, we're not suggesting a binding, and that's okay.",0,0
data/train/5_207.mp3,The next major handle to create is your session.,0,0
data/train/5_208.mp3,you'll first want to get your graphics binding ready.,0,0
data/train/5_209.mp3,"So depending on which graphics API you use, there will be a get something graphics requirements call that's specified by that extension.",0,0
data/train/5_210.mp3,You need to call that before calling create session.,0,0
data/train/5_211.mp3,"This provides useful information, how you configure your rendering in order to get the rendered content onto the display.",0,0
data/train/5_212.mp3,You then create a graphics binding struct.,0,0
data/train/5_213.mp3,"These are also specified by the graphics binding extensions, and they're all chained on via the next pointer on xr-session-create-info.",0,0
data/train/5_214.mp3,"I haven't talked about the next pointer too much, but similar to Vulkan, OpenXR structures contain a type field as well as a void pointer that allows you to chain additional structures on in a regular way.",0,0
data/train/5_215.mp3,"This is mostly used for extension functionality, but there are a few cases in the core specification where the next pointer is also used, and this is one of them.",0,0
data/train/5_216.mp3,"When you go to create a session with XR Create Session, that requires your system ID from earlier.",0,0
data/train/5_217.mp3,"And once you have that session, you then need to attach your action sets to it.",0,0
data/train/5_218.mp3,"To commit to the runtime saying, I'm all done setting up my actions,",0,0
data/train/5_219.mp3,and actionSets and suggestedBindings.,0,0
data/train/5_220.mp3,"I'm going to use them with this session, and I'm not going to change them anymore.",0,0
data/train/5_221.mp3,This does make your actions and actionSets immutable.,0,0
data/train/5_222.mp3,"You can't modify them after this point, and there's a special error code that you'd get if you tried to do that.",0,0
data/train/5_223.mp3,"If you happen to be writing an editor for a game engine, the solution for doing this, if you are editing your actions, is that each time you need to tear down the session, the actions and action sets, and then recreate them in order to modify them.",0,0
data/train/5_224.mp3,"This seems a bit like a pain, but there's an important reason for it.",0,0
data/train/5_225.mp3,There's a reason that the action setup is done all up front.,0,0
data/train/5_226.mp3,And it has to do with rebinding.,0,0
data/train/5_227.mp3,we want to be able to provide the user with the maximum ability to configure how they're interacting with their application right away.,0,0
data/train/5_228.mp3,"So when they launch your application and it turns out there's no suggested bindings for the hardware that they have, the runtime can pop up a UI that provides them the ability to map your specified actions to the hardware that they have available.",0,0
data/train/5_229.mp3,This happens behind the scenes and goes unnoticed by your application.,0,0
data/train/5_230.mp3,"If you were able to add actions and action sets later on during execution, not up front, it would then interrupt the flow of your application if rebinding needed to be done a second time.",0,0
data/train/5_231.mp3,"Additionally, if a runtime supports sharing bindings between users,",0,0
data/train/5_232.mp3,you'd be able to compose a binding that supports all actions only if action setup is all done at once.,0,0
data/train/5_233.mp3,"Otherwise, if there's an action or action set that's only used in the last scene or two of your game, for instance, then a community created in shared binding might very well be incomplete if that scene was not yet reached or was on a path that wasn't reached, making it less useful in general.",0,0
data/train/5_234.mp3,"To interact with tracked objects, you use XR space handles.",0,0
data/train/5_235.mp3,And there are multiple ways to get these handles.,0,0
data/train/5_236.mp3,Several spaces are known as reference spaces.,0,0
data/train/5_237.mp3,You access these using your XR session and an enum.,0,0
data/train/5_238.mp3,"Three of these are local space, view space, and stage space.",0,0
data/train/5_239.mp3,There are additional ones added in extensions.,0,0
data/train/5_240.mp3,Stage space can be considered a bounded standing area play environment.,0,0
data/train/5_241.mp3,Local space is seated.,0,0
data/train/5_242.mp3,"And view space is essentially head space, if you need to play something that's headlocked.",0,0
data/train/5_243.mp3,"To get an XR space from these enums, you use XRCreateReferenceSpace.",0,0
data/train/5_244.mp3,Another kind of space is an action space.,0,0
data/train/5_245.mp3,"To create these, you use your XR session and a pose action.",0,0
data/train/5_246.mp3,"The result is an XR space just the same as with create reference space, so they are both examined the same way.",0,0
data/train/5_247.mp3,"For both of these types of spaces, session is the parent handle.",0,0
data/train/5_248.mp3,"Additionally, for both of these space types, you can specify an additional fixed transform at handle creation time.",0,0
data/train/5_249.mp3,xrLocateSpace is the call used to find the transform from one space to another.,0,1
data/train/5_250.mp3,Note that you never just find the pose of a space.,0,0
data/train/5_251.mp3,You always find a space with respect to another space.,0,0
data/train/5_252.mp3,You don't track your hand.,0,0
data/train/5_253.mp3,You track your hand relative to local space or stage space.,0,0
data/train/5_254.mp3,"To render, you'll need to create a swap chain.",0,0
data/train/5_255.mp3,you'll obtain your graphics API specific formats through XR Enumerate Swap Chain formats.,0,0
data/train/5_256.mp3,You'll call xrCreateSwapchain one or more times.,0,1
data/train/5_257.mp3,"Once you've created a swap chain, you'll access the graphics API specific handles or references to the swap chain images using xrEnumerateSwapchain images.",0,1
data/train/5_258.mp3,This is a slightly unusual call.,0,0
data/train/5_259.mp3,You'll pass an array of extension defined structures.,0,0
data/train/5_260.mp3,You'll want to save the information that comes back from this call to use every frame.,0,0
data/train/5_261.mp3,It specifies in a graphics API specific way where to render your image to.,0,0
data/train/5_262.mp3,"Within the frame loop, there are three functions with frame in the name that control the lifecycle of a frame.",0,0
data/train/5_263.mp3,xrWaitFrame is a scheduling call.,0,1
data/train/5_264.mp3,It blocks until the runtime determines you can proceed with head pose dependent simulation and rendering.,0,0
data/train/5_265.mp3,"xrBeginFrame is executed by your application to mark the start of rendering, or GPU usage for that frame.",0,1
data/train/5_266.mp3,And xrEndFrame submits the frame for display.,0,1
data/train/5_267.mp3,"xrBeginFrame and EndFrame calls must be ordered as if they were single-threaded, although they may be called from any thread.",0,1
data/train/5_268.mp3,You'll populate the xrEndFrameInfo display time,0,1
data/train/5_269.mp3,using the output of xrWaitFrame.,0,1
data/train/5_270.mp3,"xrWaitFrame tells you when the next predicted display time is, and you'll use this in all your calculations and all your space locations.",0,1
data/train/5_271.mp3,"If your application is using pipelined or multi-threaded rendering, there are some more detailed timing requirements that are important to know.",0,0
data/train/5_272.mp3,You can have at most one simultaneous xrWaitFrame call being executed at a time.,0,1
data/train/5_273.mp3,And each XR wait frame must eventually be matched with a unique xrBeginFrame.,0,1
data/train/5_274.mp3,They come in pairs.,0,0
data/train/5_275.mp3,"Each wait frame has a begin frame, and every begin frame has a wait frame.",0,0
data/train/5_276.mp3,"Additionally, any xrWaitFrame call will block in the runtime until the previous frame's xrBeginFrame has been made.",0,1
data/train/5_277.mp3,"Between begin and end frame, once it's time to actually render, you'll need to use the swapchain that you created earlier.",0,1
data/train/5_278.mp3,"xrAcquireSwapchain image does not give you permission to write to the image, but it does get the index of the swap chain.",0,1
data/train/5_279.mp3,xrWaitSwapchainImage must be called before writing to that image.,0,1
data/train/5_280.mp3,It's typically called immediately after acquire.,0,0
data/train/5_281.mp3,"However, you may, as an optimization, look up or create your command buffers using just the index from acquireSwapChainImage before blocking on the compositor releasing the image for writing to your application.",0,0
data/train/5_282.mp3,xrReleaseSwapChainImage is what you call when you're all done rendering.,0,0
data/train/5_283.mp3,right before calling xrEndFrame.,0,1
data/train/5_284.mp3,xrEndFrame implicitly uses the most recently released swap chain image for displaying to the device.,0,1
data/train/5_285.mp3,"When you're doing your rendering, you need to render for the predicted display time and for the pose that the head is anticipated to be at at that time.",0,0
data/train/5_286.mp3,xrLocateViews is how you look up that information.,0,1
data/train/5_287.mp3,It works very similarly to xrLocateSpace.,0,1
data/train/5_288.mp3,"Now that we have an application that can render, we probably should look into getting input to make it interactive.",0,0
data/train/5_289.mp3,xrSyncActions should be called once per simulation frame in your application.,0,1
data/train/5_290.mp3,It specifies which action sets should be active for that frame and updates all non-pose input data in those active action sets.,0,0
data/train/5_291.mp3,"After you sync actions, then get the data.",0,0
data/train/5_292.mp3,Any action set that is attached but not specified in the most recent xrSyncActions call will have the actions return not active.,0,1
data/train/5_293.mp3,Actions additionally might not get data if your session is not focused for privacy and security purposes.,0,0
data/train/5_294.mp3,"To get action data from actions, you'll use xrGetActionState calls.",0,1
data/train/5_295.mp3,There's one for each type of action.,0,0
data/train/5_296.mp3,Pose actions are a little bit different.,0,0
data/train/5_297.mp3,"They continue updating all the time,",0,0
data/train/5_298.mp3,"not just at xrSyncActions time, because tracking is latency and time sensitive.",0,1
data/train/5_299.mp3,"To get the data from a pose action, you'll usually just create an xrSpace for it and then use xrLocateSpace.",0,1
data/train/5_300.mp3,"Only the active, inactive state of a pose action is controlled by xrSyncActions.",0,1
data/train/5_301.mp3,"Typically, you'll process most of your input either before you call xrWaitFrame and xrBeginFrame or after xrEndFrame.",0,1
data/train/5_302.mp3,There is a per instance event queue that contains a range of events.,0,0
data/train/5_303.mp3,"This queue must be polled on a regular basis, typically once a simulation frame is a good idea.",0,0
data/train/5_304.mp3,xrPollEvents requires an instance.,0,1
data/train/5_305.mp3,"However, many events only happen during a session.",0,0
data/train/5_306.mp3,"These events can describe changes to the active interaction profile, continuity of reference spaces and tracking, changes in the session state, and other things.",0,0
data/train/5_307.mp3,"you provide an xrEventDataBuffer to xrPollEvents, and the runtime populates it with an event of some other type.",0,1
data/train/5_308.mp3,You have to make sure you set the type to xrTypeEventDataBuffer.,0,1
data/train/5_309.mp3,"And then when you get it back from that call, check that type value and reinterpret that structure accordingly.",0,0
data/train/5_310.mp3,Thanks for your time.,0,0
data/train/5_311.mp3,Hopefully you found this introduction to OpenXR and exploration of the structure of an OpenXR application to be helpful.,0,0
data/train/5_312.mp3,I've put a number of resources on this slide that you can follow for additional information.,0,0
data/train/5_313.mp3,"If I'm not available for questions at the time that you're watching this,",0,0
data/train/5_314.mp3,please feel free to drop by one of the community locations for the OpenXR group and leave a note there with your question.,0,0
data/train/5_315.mp3,I or someone else in the community will be happy to respond.,0,0
data/train/7_0.mp3,"Hi, thanks for joining us at the Automotive Linux Summit 2021.",0,0
data/train/7_1.mp3,"We're here to talk today about how to build out sustainable platforms, and in particular how we can drive a wider adoption of",0,0
data/train/7_2.mp3,of testing QA and CI throughout upstream open source projects so we can really drive the adoption of open source and get what vendors actually distribute to users to be much much closer,0,0
data/train/7_3.mp3,to the actual projects themselves.,0,0
data/train/7_4.mp3,So my name's Daniel Stone.,0,0
data/train/7_5.mp3,"I'm the graphics lead at Calabra, covering projects such as Mesa, Wayland, Western, and the FreeDesktop.org ecosystem.",0,0
data/train/7_6.mp3,"Hello everyone, my name is Guillaume Tucker and I also work at Colabra.",0,0
data/train/7_7.mp3,"I've been leading the KernelCI project in general and also I've been working on it as part of Colabra for the past three, four years.",0,0
data/train/7_8.mp3,I'm currently also chair of the advisory board for the Linux Foundation project.,0,0
data/train/7_9.mp3,So today we're going to cover a few areas.,0,0
data/train/7_10.mp3,"In particular, we're going to start with the existing ecosystem that we have with upstream open source projects, which projects are interesting to us, the challenges we faced as we've driven heavily the adoption of these more rigorous testing and CI and QA procedures throughout them.",0,0
data/train/7_11.mp3,the results of those efforts as well.,0,0
data/train/7_12.mp3,"You know the testing frameworks we've been able to build out in each project, the results we've had from those, and you know what we've learned along the way really in terms of things like process, adoption, socializing, and then finally how we can build out from the slightly more siloed",0,0
data/train/7_13.mp3,testing frameworks that we have at the moment to having something a little bit more coherent and shared between all the different projects.,0,0
data/train/7_14.mp3,The main challenge we have is the sort of disconnect between the two different models.,0,0
data/train/7_15.mp3,"In a traditional product development model, the products are really worked on in almost a waterfall fashion where they're fully tested at each step along the way.",0,0
data/train/7_16.mp3,"Everyone has a clear idea of what the goals and the metrics and the acceptance criteria are, and there are various",0,0
data/train/7_17.mp3,sort of gating processes along that.,0,0
data/train/7_18.mp3,"If you compare to traditional open source projects, it's been very much a commons project with not necessarily a shared vision or a shared set of priorities or even the ability to break those kind of deadlocks and the disagreements and try and enforce some kind of priorities.",0,0
data/train/7_19.mp3,Testing of upstream work often fell into a bit of a gap where it wasn't really native to the projects themselves and the users didn't necessarily see the need for upstream testing because they already had all of their own testing on downstream branches and what they shipped and their own QA departments that they would almost take over.,0,0
data/train/7_20.mp3,But,0,0
data/train/7_21.mp3,with all of the cost falling on Novendo and none of the benefit being delivered to all of the other users of the upstream projects.,0,0
data/train/7_22.mp3,But we do believe it's possible to bridge this gap.,0,0
data/train/7_23.mp3,"So yeah, today we'll be talking about a lot of the work we've done throughout various projects to bring this more native testing and CI and",0,0
data/train/7_24.mp3,just take it into the process for all of these projects.,0,0
data/train/7_25.mp3,"So the projects we've been working with include the Linux kernel itself, Mesa, which is the de facto standard for open source graphics drivers and acceleration, Wayland and Western, the again de facto standard window and display system under Linux,",0,0
data/train/7_26.mp3,and GStreamer for multimedia support as well.,0,0
data/train/7_27.mp3,"So starting with a Linux kernel, we'll go through how the kernel development workflow typically works.",0,0
data/train/7_28.mp3,"So first of all, you have developers sending patches via mailing lists, then maintainers apply patches after some review on their own branches, on their own Git trees.",0,0
data/train/7_29.mp3,And then some of them might have a branch that they share to be tested with Linux Next or with various CI systems.,0,0
data/train/7_30.mp3,"and eventually the maintainer branch will get merged into another maintainer branch until it gets merged into the install of its tree, which could take up to three months.",0,0
data/train/7_31.mp3,There's a merge window every three months for merging all the new changes.,0,0
data/train/7_32.mp3,"So in the workflow I just explained, I didn't mention testing anywhere, so that depends on how each subsystem actually functions.",0,0
data/train/7_33.mp3,"Some subsystems will do all their testing directly when people submit some changes,",0,0
data/train/7_34.mp3,"Other subsystems rely on the maintainers to run their own tests, so they would have their own manual workflows, or maybe some automated workflows.",0,0
data/train/7_35.mp3,But none of that is really systemic.,0,0
data/train/7_36.mp3,So you have a collection of test systems available that will test a mainline kernel and a variety of Git branches available.,0,0
data/train/7_37.mp3,"So one of them is KernelCI, which has now become a project of the Linux Foundation, as it has been chosen as the main project for testing the upstream Linux kernel.",0,0
data/train/7_38.mp3,"So it's focusing on what we call post-merge testing, so it's after a patch has been applied to a branch.",0,0
data/train/7_39.mp3,"So it's monitoring a number of Git branches, and as soon as it detects a new revision, it will test it, build it, and send some reports.",0,0
data/train/7_40.mp3,We can see that gradually more and more subsystems and maintainers are starting to engage with KernelCI and rely on the results that it's producing.,0,0
data/train/7_41.mp3,"On this slide you can see a diagram, like a big picture diagram of how currently test-driven kernel development kind of looks like.",0,0
data/train/7_42.mp3,"So you have a crowd of people versus like the ecosystem, you have different types of developers, you have OEMs, you have also maintainers.",0,0
data/train/7_43.mp3,So they all contribute to the kernel source code itself via git branches.,0,0
data/train/7_44.mp3,They also contribute to some tests.,0,0
data/train/7_45.mp3,"So LTP, KSAL, TestK unit are the main examples for upstream oriented test suites.",0,0
data/train/7_46.mp3,And then KernelCI will build some kernels and also build the test suites and then run the tests against the kernels.,0,0
data/train/7_47.mp3,and share the results and then report the results via emails or a web dashboard to the developers and that's how the loop is closed.,0,0
data/train/7_48.mp3,"To understand a bit better what the developers actually need in order for Konocii to be more widely used, we've run a survey in 2020.",0,0
data/train/7_49.mp3,We called it the Community Survey.,0,0
data/train/7_50.mp3,"There's a blog post available on konocii.org website if you want to read the whole report, but here there's a small summary of the main takeaways from that survey.",0,0
data/train/7_51.mp3,"So ideally we would need to test patches before they get applied, so like pre-merge if you want to call it like this, because then you get really short feedback circuits.",0,0
data/train/7_52.mp3,"So when someone sends some patch on a mailing list, you could get a reply really quickly whether it's breaking anything or not.",0,0
data/train/7_53.mp3,That's really important based on the results from the survey.,0,0
data/train/7_54.mp3,"And then for things that are run post-merge, it seems like what makes a lot more sense is to run really long tests that maintainers don't have the time to run, or things that are difficult to run by hand.",0,0
data/train/7_55.mp3,especially say on stable kernels when it's normally like one release per week.,0,0
data/train/7_56.mp3,It should be okay to have like tests that take 24 hours for example.,0,0
data/train/7_57.mp3,And then the third thing is improving the web dashboard.,0,0
data/train/7_58.mp3,So we have currently one dashboard on kernalci.org.,0,0
data/train/7_59.mp3,It's been there for several years and it's showing the results but there's many things that could be done to really improve it so that more users would be using it.,0,0
data/train/7_60.mp3,And we're collecting user stories.,0,0
data/train/7_61.mp3,"Well, we're kind of collecting feedback, ideas and suggestions from anyone who would want to have, you know, what would be your ideal web dashboard.",0,0
data/train/7_62.mp3,And we're starting to derive from that a set of requirements to start really designing a better dashboard.,0,0
data/train/7_63.mp3,This is driven by the Linux Foundation KernelCI project at the moment.,0,0
data/train/7_64.mp3,We're hoping to see some concrete results in 2022.,0,0
data/train/7_65.mp3,"So KernelCI runs a number of, well it builds some kernels and then runs some tests, mostly functional tests.",0,0
data/train/7_66.mp3,Initially it was doing only boot testing to check whether a platform would boot at all.,0,0
data/train/7_67.mp3,"Now we've started running more and more functional tests, things like IGT to test DRMKMS as well as some GPUs as well now.",0,0
data/train/7_68.mp3,"and classic test suites like Linux Test Project, LTP, and KSelfTest and KUnit, which come with the kernel source tree itself.",0,0
data/train/7_69.mp3,So we're running about 15% of what LTP provides and KSelfTest provides.,0,0
data/train/7_70.mp3,"We're not really running KUnit yet, but that's coming soon.",0,0
data/train/7_71.mp3,And we've been working with the KUnit maintainers to get this enabled in KernelCI.,0,0
data/train/7_72.mp3,So that's what we call the native tests.,0,0
data/train/7_73.mp3,They are all orchestrated by KernelCI itself.,0,0
data/train/7_74.mp3,"Now, in addition to these tests, we can look at KernelCI from a functionality point of view.",0,0
data/train/7_75.mp3,So what does it do?,0,0
data/train/7_76.mp3,So first it monitors a number of trees.,0,0
data/train/7_77.mp3,"There's about 100 good branches that are monitored from individual maintainers, you know, subsystems, architecture subsystems, and then you have bigger, well, mainline and Linux Next are like integration branches.",0,0
data/train/7_78.mp3,"and stable, all the stable and long-term stable branches, as well as some branches for member companies of the project, like CIP, and we're starting to look at Chrome OS kernels as well.",0,0
data/train/7_79.mp3,And one really interesting feature of KernelCI is the ability to track regressions.,0,0
data/train/7_80.mp3,"When a test has been passing in previous revisions of a kernel, and one day it starts failing,",0,0
data/train/7_81.mp3,"For an individual specific test case, as soon as it starts failing, it's detected as a regression.",0,0
data/train/7_82.mp3,"And typically, automatically, there will be bisections started for that, which will try to find the commit between the last good revision and the first bad revision to understand which commit actually caused the problem.",0,0
data/train/7_83.mp3,"And this is particularly useful on Linux Next, where you have a lot of changes from one day to the next.",0,0
data/train/7_84.mp3,"And thanks to this, we're finding a lot of issues in reporting.",0,0
data/train/7_85.mp3,"We can report the issues directly to the developers, because if you know the author of the comment you can send,",0,0
data/train/7_86.mp3,the message to the author and related maintainers and people around the maintainers related to the code that was changed by the patch itself.,0,0
data/train/7_87.mp3,"Then another big aspect of KernelCI, which is a bit more recent, is kcidb.",0,0
data/train/7_88.mp3,So this is only a database that's meant to collect results from any CI system that's running kernel tests.,0,0
data/train/7_89.mp3,"So the native tests, like I explained in the previous slide, the native tests are collected there, but we're also collecting results from other test systems.",0,0
data/train/7_90.mp3,"And if you have your own test system, you can also, anybody can submit test results there.",0,0
data/train/7_91.mp3,"So the idea is to avoid, to reduce duplication.",0,0
data/train/7_92.mp3,"And in principle, a new web dashboard will be showing this information, which is like a superset of what you see right now on kernelci.org.",0,0
data/train/7_93.mp3,"By opposition to the native tests, you have like the non-kernel-ci tests, things that are run outside of kernel-ci, the tests that are not orchestrated directly by kernel-ci, such as 0day and syscaller, a fuzzing bot, and Red Hat's CKI, and several tools from Lenaro as well.",0,0
data/train/7_94.mp3,"There's Lenaro Kernel Functional Tests, LKFT,",0,0
data/train/7_95.mp3,"And TuckSuite, which is more like a service, everybody could subscribe to it to build kernels and also start to support running tests.",0,0
data/train/7_96.mp3,"And the result of all these, and a few more actually from ARM and Gen2 KernelCI and a few more, all these results are currently being contributed to KCI-DB.",0,0
data/train/7_97.mp3,"Actually, it's not all of syscaller, but some of them, because that's a huge dataset, but some of the syscaller results are being contributed to KCI-DB.",0,0
data/train/7_98.mp3,And that's growing.,0,0
data/train/7_99.mp3,There's a weekly report on the KernelCI mailing list you can see to have status of all the different contributors.,0,0
data/train/7_100.mp3,"Mesa's kind of an interesting contrast to this I think because it is, well it's the de facto standard for open source GPU drivers on Linux.",0,0
data/train/7_101.mp3,"So we're talking OpenGL, OpenGL ES, Vulkan, everything you need for both games, accelerated desktops, you name it.",0,0
data/train/7_102.mp3,It's much more limited in scope than the kernel.,0,0
data/train/7_103.mp3,"So of the drivers we have, we have eight different hardware vendors, obviously all with their own, you know, big generational or smaller generational bumps.",0,0
data/train/7_104.mp3,And then we also have layered and virtualized drivers in our software reference driver.,0,0
data/train/7_105.mp3,It's a much smaller development community in Mesa compared to the kernel.,0,0
data/train/7_106.mp3,And these teams are often not directly supported by the hardware vendor.,0,0
data/train/7_107.mp3,It runs the entire spectrum from the hardware vendor has teams of people directly working on Mesa and producing their driver as a first class output.,0,0
data/train/7_108.mp3,"a bunch in the middle where the vendor will assist and support the development team but the development is being done externally to the hardware vendor, right the way through to completely reverse engineered efforts where the vendor has no involvement at all.",0,0
data/train/7_109.mp3,So one challenge we've had is really in bringing Mesa up from this kind of scrappy underdog where you're happy that it works to now where we've gone from one driver that's been conformant for the past few years up to several drivers having gone through the official Khronos conformance testing.,0,0
data/train/7_110.mp3,And that's been something we've really needed to back up with some really extensive testing to make sure that we stay conformant.,0,0
data/train/7_111.mp3,It's a really sort of hard won battle and we don't want to be slipping back.,0,0
data/train/7_112.mp3,And we also don't want to lose the development velocity that we've been able to have within Mesa.,0,0
data/train/7_113.mp3,"And this can be quite difficult because as Mesa is relatively understaffed as a project compared to something like The Kernel, the development community can tend to naturally silo a little bit.",0,0
data/train/7_114.mp3,"even though people will work on the core of Mesa itself of course, often their first target is a particular driver and so their attention might be taken away by new hardware support or particular feature enablement or anything else which makes it difficult to have kind of a shared global overview of Mesa as a whole rather than your own driver world.",0,0
data/train/7_115.mp3,But luckily the one thing we have got that's been kind of a gift is Khronos has over the past few years made its conformance test suites publicly available.,0,0
data/train/7_116.mp3,"So it's no longer just Khronos members who can run the official OpenGL and Vulkan conformance test suites, but they're available to the whole public and we're able to run those in",0,0
data/train/7_117.mp3,"in public and distribute those now, which has really been a godsend.",0,0
data/train/7_118.mp3,"So having that large amount of API coverage for the official conformance testing is great, and running those, you know, that is the Khronos conformance process essentially, is running those.",0,0
data/train/7_119.mp3,So you know where your driver stands if you're able to run those.,0,0
data/train/7_120.mp3,"In addition to that, we also have other test suites such as Piglet, which are kind of built from the reverse direction.",0,0
data/train/7_121.mp3,"So the conformance test suites have been built out by the API designers in parallel with the API being designed, and it's really focused on that.",0,0
data/train/7_122.mp3,"whereas Piglet has just been incrementally built out by Mesa developers who will find a bug, realize that this could be particularly common or crippling or what-have-you, and then they'll put in a Piglet test for that to make sure that you don't regress.",0,0
data/train/7_123.mp3,"And yeah, it's possible to do this with both actual hardware GPU drivers, but also it's completely possible to just test the reference software driver we have, which has no",0,0
data/train/7_124.mp3,hardware dependencies but will just run on any CPU with an LLVM backend.,0,0
data/train/7_125.mp3,So doing that is a really nice little quiver in our bow I suppose to be able to test the core of Mesa without needing dedicated hardware.,0,0
data/train/7_126.mp3,"So the testing that we do have in Mesa, that covers",0,0
data/train/7_127.mp3,"several generations of all of AMD GPUs, the Mali GPUs, Broadcom's VideoCore in the Raspberry Pi, all of the Intel GPUs, the Qualcomm Adreno that comes in their Snapdragon SoCs, and also the Virosilicon or Vivante GPUs which tend to come in processors like NXP.",0,0
data/train/7_128.mp3,"And all of these have achieved, at least for some hardware generations or some API versions, official Khronos conformance.",0,0
data/train/7_129.mp3,"So again, we're very keen to make sure that we keep that and we don't regress backwards.",0,0
data/train/7_130.mp3,So we do quite extensive testing of those.,0,0
data/train/7_131.mp3,"And the interesting contrast to the kernel, I think, is that we have a",0,0
data/train/7_132.mp3,"slightly more traditional for open source I suppose, pre-merge testing process which is blocking.",0,0
data/train/7_133.mp3,"So when you submit a merge request and it's been reviewed and it's good to go, you assign it to a very cold and unfeeling bot who will go and run a ton of tests and merge if they all succeed or tell you that something went wrong if any of them failed.",0,0
data/train/7_134.mp3,"So in order to support that process without everything collapsing, we want every merge pipeline to turn around in 15 to perhaps 20 minutes in Extremis.",0,0
data/train/7_135.mp3,"But that has to cover running, you know, some generations of GPU will run over 300,000 individual tests for every MR.",0,0
data/train/7_136.mp3,between all the different various test suites.,0,0
data/train/7_137.mp3,So in order to do that we had to build out a custom test runner framework.,0,0
data/train/7_138.mp3,But it's not just,0,0
data/train/7_139.mp3,"conformance tests that we run, but we also have traces from real-life workloads, captures from games or desktop clients or any of these, where we take the GL and Vulkan command streams that they actually emit and we replay those and make sure that the output isn't changing.",0,0
data/train/7_140.mp3,"Or at least not changing in a way that's seen as bad, because OpenGL isn't pixel-precise, nor is Vulkan.",0,0
data/train/7_141.mp3,"So you might have minor differences here and there, and we have some tools which allow us to visualize the differences and see what the change is, to see if it's an acceptable change.",0,0
data/train/7_142.mp3,"But yeah, all of this has to come within this relatively short time window.",0,0
data/train/7_143.mp3,"And it's something that we have to get right, essentially, because rather than being a more advisory post-merge thing where code gets pushed out into the wild, and then later on you get an email telling you that it broke something, if a test fails, then your merge request won't get merged.",0,0
data/train/7_144.mp3,It turns out that having flaky tests which block people's MRs is a pretty good way to get developers to tell you what they really feel about your test suite.,0,0
data/train/7_145.mp3,"If we look at other projects, Wayland and Weston were very early adopters of CI and having GitLab on FreeDesktop.org, but for the longest time they didn't get too far beyond build testing.",0,0
data/train/7_146.mp3,That's because one of the challenges we have in Wayland is the lack of an official universal conformance test suite.,0,0
data/train/7_147.mp3,"So we have all of the tests on the server side inside Western that we've written for ourselves as we've developed it, but we don't have a similar target like we do with the Khronos APIs to be able to work towards and give us a yes-no answer.",0,0
data/train/7_148.mp3,"Even so, we're making use of... We actually test Western by starting up a new virtual machine with a clean known kernel and a virtual KMS driver which just simulates a display controller.",0,0
data/train/7_149.mp3,And that gets us a lot of what we want because we're able to exercise a lot of different paths within our backends and make sure that they run,0,0
data/train/7_150.mp3,About as well as you can when you're working with a virtual driver rather than a real hardware driver.,0,0
data/train/7_151.mp3,"But yeah, that's where we are now for Wayland and Western.",0,0
data/train/7_152.mp3,"The back-end testing, testing things like rendering correctness and internal consistency.",0,0
data/train/7_153.mp3,But these are really home-built tests.,0,0
data/train/7_154.mp3,"GStreamer on the other hand for multimedia, it's got a very well established set of tests which have almost always been there for both for its individual modules and also for end-to-end functional and integration testing.",0,0
data/train/7_155.mp3,So GSTvalidate is a suite which checks the modules and makes sure that they behave according to the GStreamer API contract.,0,0
data/train/7_156.mp3,So in isolation they look like they do what they should.,0,0
data/train/7_157.mp3,"And then Cerbro is a monster integration test suite, which does real end-to-end testing, putting through various workloads, again, that they've captured as they've gone on and places where they found bugs.",0,0
data/train/7_158.mp3,And then it's been added to the test suite to make sure that all of those corner cases work.,0,0
data/train/7_159.mp3,And that's been a part of GStreamer upstream for a good couple of years now.,0,0
data/train/7_160.mp3,"Again, concurrent with the move to GitLab on freedesktop.org.",0,0
data/train/7_161.mp3,But this is all happening as software-based testing.,0,0
data/train/7_162.mp3,So it will run in containers and virtual machines on general purpose hosts.,0,0
data/train/7_163.mp3,And we're not yet able to test how GStreamer behaves.,0,0
data/train/7_164.mp3,"again with different hardware drivers, say for video for Linux or also for sound or any of those other inflection points.",0,0
data/train/7_165.mp3,"Now we've looked at how the kernel is being tested upstream and how graphics and Wayland and GStreamer are being tested upstream, we can start thinking about general concepts around what does it take to move an open source project to being really test-driven.",0,0
data/train/7_166.mp3,"You can see, like we said at the beginning, commercial products, fully integrated products, are tested very thoroughly and they have control over their own universe, so there's no real barrier in terms of people adopting it because it's a team working on it, so they all basically",0,0
data/train/7_167.mp3,"adopt the workflow and the automated testing, because that's just the way they do it, and have complete freedom over how they do this.",0,0
data/train/7_168.mp3,"For an open source project, you have contributors from many different horizons, so they might all have different views about how to work.",0,0
data/train/7_169.mp3,"Also you could have in a large project like Linux kernel, different parts of the kernel will need different types of workflows.",0,0
data/train/7_170.mp3,"Some parts will be changing very quickly, other parts will need to be really stable.",0,0
data/train/7_171.mp3,"So in the same way that open source code is really coming from like built by the ground up, so people contribute code and that's how it happens.",0,0
data/train/7_172.mp3,Nobody's planning what's really going to happen for the Linux kernel in the next few years or even the next few months.,0,0
data/train/7_173.mp3,So it's in the same way that the changes are not really imposed.,0,0
data/train/7_174.mp3,"Of course, things are being designed, but nobody has a master plan and decides exactly how things are going to unfold.",0,0
data/train/7_175.mp3,So it's the same thing for testing.,0,0
data/train/7_176.mp3,"Basically, people send code and request for comments on the mailing list about code changes.",0,0
data/train/7_177.mp3,"For testing, people can provide tools and suggest ways of doing things.",0,0
data/train/7_178.mp3,"And as people see that there's value in it, and that it's something that they can adopt, then gradually it will be adopted.",0,0
data/train/7_179.mp3,"So basically, this is what you can see this happening already, like we've explained with KernelCI.",0,0
data/train/7_180.mp3,when some maintainers are starting to engage and look at the results.,0,0
data/train/7_181.mp3,"And maybe if Codencii doesn't work, they have their own, or if it doesn't provide the results that they're looking for, they have their own manual test and they can still carry on.",0,0
data/train/7_182.mp3,"Like for stable kernels, typically Codencii would be sending results for each stable kernel.",0,0
data/train/7_183.mp3,"So if the results are there and some problems were detected by KernelCI, something will get done about it.",0,0
data/train/7_184.mp3,Some people will try to fix them.,0,0
data/train/7_185.mp3,"But if for some reason KernelCI disappeared, the stable kernel will still be released.",0,0
data/train/7_186.mp3,It's just maybe some bugs will not be known and they'll be found later.,0,0
data/train/7_187.mp3,That's currently how things work.,0,0
data/train/7_188.mp3,"So maybe with time, it's a bit like a clutch mechanism, maybe after a while, if we all spin at the same speed, then we can really engage, and then the test system will be working hand in hand with the kernel.",0,0
data/train/7_189.mp3,"So this has already happened with Mesa-CI, like Daniel just explained.",0,0
data/train/7_190.mp3,"And of course, sometimes you have a few sparkles in a clutch system, so it's not always easy to get it completely right without any smoke.",0,0
data/train/7_191.mp3,coming out of it but that's it's really a price worth paying basically because now you know when a change comes in it has to pass the tests and that's really where you want to be.,0,0
data/train/7_192.mp3,"So like I've just explained, you have some tools available.",0,0
data/train/7_193.mp3,"So KernelSeer is one of them for the kernel, but also ZeroDay will be sending you emails, and SysBot will be doing this as well, fuzzing syscalls in the kernel to try to find corner cases that nobody else has found before.",0,0
data/train/7_194.mp3,So these are available and of course they send results by email and if people don't like the emails that happens sometimes it's like this report is not useful people will reply and then things will get adjusted and yeah for Missa and Wayland and GStreamer maybe it's a little bit easier to have things enforced it's a bit like maybe like a subsystem in the kernel if you have a small enough subsystem,0,0
data/train/7_195.mp3,"then it could operate in its own autonomy, basically, and then decide to accept a test or workflow, test-driven workflow.",0,0
data/train/7_196.mp3,So that's kind of the step-by-step process that we have to go through.,0,0
data/train/7_197.mp3,"Yes, Daniel?",0,0
data/train/7_198.mp3,I think that's a really good parallel.,0,0
data/train/7_199.mp3,"I mean, I always thought the problem with the kernel wasn't that it had no master plan, but that it had like hundreds of them at any given time, right?",0,0
data/train/7_200.mp3,"Whereas, yeah, just, I think having that smaller scope makes it much easier for us.",0,0
data/train/7_201.mp3,"So now we can see some numbers to have an idea of the dimension of what is being done on the kernel side, at least from kernel-CI point of view.",0,0
data/train/7_202.mp3,"I haven't put stats about bisections, but every week there's one, two or three bisections that lead to actual bug fixes, and that's growing.",0,0
data/train/7_203.mp3,"So this is, you know, some metric that will be producing some stats at some point about that.",0,0
data/train/7_204.mp3,"You can already see the number of tests being run on Linux Next, which has the biggest coverage.",0,0
data/train/7_205.mp3,"There's about 12,000 individual test cases run every day, because that's for every revision of Linux Next.",0,0
data/train/7_206.mp3,"And that is growing as we keep adding new tests and new platforms, and we have also new test labs joining that quickly increase the test coverage.",0,0
data/train/7_207.mp3,On the second graph you can see the KCIDB number of builds.,0,0
data/train/7_208.mp3,So this is all the builds from the native KernelCI builds.,0,0
data/train/7_209.mp3,But also here in this graph you will see builds submitted by LKFT and all the other submitters to KCIDB.,0,0
data/train/7_210.mp3,So TuckSuite and also CKI from Red Hat.,0,0
data/train/7_211.mp3,and also some builds from ARM.,0,0
data/train/7_212.mp3,"So this is, you know, it's gradually getting to the point where you see the actual number of people testing the upstream Linux kernel.",0,0
data/train/7_213.mp3,"Well, this is for all the revisions, so we get about 20,000 builds.",0,0
data/train/7_214.mp3,"So for each build you have maybe a thousand, two thousand tests.",0,0
data/train/7_215.mp3,"We don't have all the tests yet in KCIDB, but that gives you an idea of the size.",0,0
data/train/7_216.mp3,"And of course, maybe as we can start seeing results put together, maybe some duplication will be removed after a while if we all keep building the same kernels.",0,0
data/train/7_217.mp3,Maybe we can reuse each other's kernels.,0,0
data/train/7_218.mp3,"We'll see how that works, how that will work out over time.",0,0
data/train/7_219.mp3,"And similarly for Mesa, I mean, you can see some",0,0
data/train/7_220.mp3,"A nice shiny graph there, with I think a pretty interesting pattern in the number of tests versus the number of commits or the number of merge requests that were made to Mesa.",0,0
data/train/7_221.mp3,"It's definitely an iterative story, essentially of building out test coverage as wide as we can.",0,0
data/train/7_222.mp3,"For what that gives us, it turns out sometimes that's a bit overkill.",0,0
data/train/7_223.mp3,So one of the traditional patterns is that we'd introduce the first iteration of testing for a particular hardware generation.,0,0
data/train/7_224.mp3,"run, and we'd have a lot of those tests run just to shake it out and to get it completely stable and find out where all the issues are before we stepped it back.",0,0
data/train/7_225.mp3,"So, for example, if you submit a merge request which only modifies the AMD driver, then it's not going to run any of the tests on PanFrost for the ARM Mali or the Frodrino driver for Qualcomm.",0,0
data/train/7_226.mp3,because we know that there's going to be no impact.,0,0
data/train/7_227.mp3,"Whereas if you submit a job which touches core code, or submit a merge request which touches core code, you can see up to 155 jobs per merge request just touching a full extent of everything we can test.",0,0
data/train/7_228.mp3,"And yeah, they're not entirely correlated, these graphs, because they're somewhat independent.",0,0
data/train/7_229.mp3,We do do manual test runs outside of the merge request context.,0,0
data/train/7_230.mp3,"Sometimes you have core changes which are much more difficult and finicky, so they require a fair few passes through the automated testing before they can be merged, just because no one can have, you know, like 30 different generations of GPU available to them on their desk.",0,0
data/train/7_231.mp3,You can also see one particular spike which was one of the least fun months of my life when we had a lot of infrastructure issues on FreeDesktop.,0,0
data/train/7_232.mp3,Not really related to the test system but more about things like networking.,0,0
data/train/7_233.mp3,Weather tests were so unreliable that,0,0
data/train/7_234.mp3,We just had to keep running them over and over until they did eventually pass.,0,0
data/train/7_235.mp3,"That one was interesting, it definitely taught us some lessons about things like",0,0
data/train/7_236.mp3,make sure you have not only really good monitoring for false positives but something that's quite dynamic and really easy to modify so you can pick those up and you don't push the burden back to developers to deal with themselves.,0,0
data/train/7_237.mp3,One of the things we found out is that,0,0
data/train/7_238.mp3,beyond a certain point of unreliability.,0,0
data/train/7_239.mp3,"Some developers will just smash retry every single time a test fails, even if it's failing because their code doesn't compile.",0,0
data/train/7_240.mp3,"So there's definitely, you know, coming back to Guillaume's point about being iterative and building confidence, which KernelCI certainly does.",0,0
data/train/7_241.mp3,There's a lot of sort of shadow testing in the background that,0,0
data/train/7_242.mp3,that you don't see.,0,0
data/train/7_243.mp3,That's one thing we picked up from from Mesa as well is that it's really important to deliver the results as accurately as possible so people not only get confidence in it but they're also able to buy into it a bit more so you know testing becomes something that the whole community cares about rather than having developers and people who do test stuff which is never,0,0
data/train/7_244.mp3,a particularly nice dynamic to be in.,0,0
data/train/7_245.mp3,"So yeah, now we've talked about what we've been doing in our individual projects and a lot of the challenges we've had there, how we've resolved them, the ways that we have brought testing to those projects.",0,0
data/train/7_246.mp3,One really big thing that's coming up for us is bringing those all together and having them be more integrated and less siloed.,0,0
data/train/7_247.mp3,"So, for example, for all of our Mesa testing, which we do on hardware, we pin a really specific kernel version.",0,0
data/train/7_248.mp3,"It's the only way to make Mesa testing tractable, because otherwise, you know, we'd just be",0,0
data/train/7_249.mp3,subject to a million things which are outside of our control.,0,0
data/train/7_250.mp3,But it's still really useful to have.,0,0
data/train/7_251.mp3,"I mean, KernelCI can test all of the kernel aspects, but it would be really useful for maintainers to know that, you know, their changes broke actual running user space workloads like Mesa or like GStreamer for media to code, and being able to have that fast integrated feedback.",0,0
data/train/7_252.mp3,And this is true everywhere.,0,0
data/train/7_253.mp3,"Conversely, Western pins a version of Mesa and KernelCI pins known versions of user space components just to keep the whole stack tractable.",0,0
data/train/7_254.mp3,"So one thing we've been looking at and working on is being able to share our workloads, our definitions, and the ways we parameterize them as well.",0,0
data/train/7_255.mp3,So we can bring in more integrated testing and be able to at least,0,0
data/train/7_256.mp3,at least work on fragments of the tests.,0,0
data/train/7_257.mp3,"For example, we couldn't run the entire conformance test suites for every GPU for every kernel revision because there are just too many of them.",0,0
data/train/7_258.mp3,"But what we can do is run a smaller, more targeted subset and at least have a bit of confidence that things are roughly working as they should with new kernel versions.",0,0
data/train/7_259.mp3,And that's something that helps us all.,0,0
data/train/7_260.mp3,"It lets people know about regressions sooner, it makes sure that those regressions don't hit actual released kernels or Mesa versions or anything, but they're discovered before they can be found by users, so just cuts out that manual feedback loop.",0,0
data/train/7_261.mp3,"And one thing we've found with MESA is having that testing, even in Western with more limited testing there, it's let us move a lot more fearlessly.",0,0
data/train/7_262.mp3,We can be much less,0,0
data/train/7_263.mp3,cautious about making sure that we don't break things.,0,0
data/train/7_264.mp3,"There's a lot less manual testing which takes up the developer's time, but you can do your code review and be sure that something else is going to pick up the more visible aspects of correctness.",0,0
data/train/7_265.mp3,"And that would be really great if the kernel would be able to move quicker without having to worry too much about Mesa, and Mesa and Wayland didn't have to be terrified of upgrading the kernel because who knows what might break.",0,0
data/train/7_266.mp3,So that's something that we're looking forward to having much more integration with as time passes.,0,0
data/train/7_267.mp3,"And so even if you're not participating in upstream open source projects, this is still meaningful to you.",0,0
data/train/7_268.mp3,"Because as we were saying at the beginning, the upstream QA and CI has only really been meaningful to the upstream projects themselves, because there's often been such a distance between those projects and the vendors in terms of",0,0
data/train/7_269.mp3,"the time to deploy new versions, downstream customizations which get made, those often never find their way back to upstream because it's been so long and the code base has moved on anyway.",0,0
data/train/7_270.mp3,And this is a real problem when we think about,0,0
data/train/7_271.mp3,"not just things like Spectre and Meltdown, but the entire security landscape, you know, with such complex and rapidly moving software that you have to keep on top of it to ship something secure to people.",0,0
data/train/7_272.mp3,So this is a huge benefit because the amount of testing that we do in the upstream projects these days gives so much more assurance that,0,0
data/train/7_273.mp3,the vendors are able to pull in much newer versions of Upstream software much more quickly than they have done in the past.,0,0
data/train/7_274.mp3,But this is obviously only possible if you have a much smaller delta of changes that you've made to existing Upstream trees.,0,0
data/train/7_275.mp3,"So for the first time there's a real incentive for vendors to work with Upstream, both in terms of the changes they make and also in terms of helping us with the QA, the CI and the testing that we do.",0,0
data/train/7_276.mp3,"because everything done to upstream means you can ship better software to your customers faster, and it means that you can just have more and more assurance that what you're shipping is secure, it's validated, it's solid, and it will do what you need it to do.",0,0
data/train/7_277.mp3,So that's our quick summary of the landscape.,0,0
data/train/7_278.mp3,We'll have some more details available in a blog on collabra.com with a lot more details on,0,0
data/train/7_279.mp3,"how these upstream projects work, how to get involved and help out, especially with the testing angles.",0,0
data/train/7_280.mp3,But this is the thing that's here.,0,0
data/train/7_281.mp3,We're not talking about the old days where open source was a kind of wild west fun project.,0,0
data/train/7_282.mp3,and it was the vendors who brought some kind of rigor to these projects.,0,0
data/train/7_283.mp3,"It's now something that over time the open source projects have been able to embrace as part of their projects and their methodologies, and that's only going to increase.",0,0
data/train/7_284.mp3,"All of these efforts, they're open to contributors.",0,0
data/train/7_285.mp3,KernelCI is a Linux Foundation project.,0,0
data/train/7_286.mp3,"MesaCI is something primarily being worked on by Collabra, Google, Legalia, Red Hat, Valve, all companies who are just interested in the long-term health of Mesa.",0,0
data/train/7_287.mp3,"Similarly, Western, GStreamer, the testing infrastructure and development is shared between the entire community.",0,0
data/train/7_288.mp3,"The more we do this, the more you can benefit from what we do upstream.",0,0
data/train/7_289.mp3,So please come get involved.,0,0
data/train/7_290.mp3,Don't be afraid.,0,0
data/train/7_291.mp3,Help us out and we can ship better software to you so you can ship better software to your customers.,0,0
data/train/7_292.mp3,"And with that, thank you very much.",0,0
data/train/7_293.mp3,We'll be here to take any questions you might have.,0,0
data/train/7_294.mp3,"And if you're interested in getting in touch, our email addresses as well are available in the title slide.",0,0
data/train/7_295.mp3,So thank you.,0,0
data/train/6_0.mp3,"Hello everyone, thank you for joining this virtual talk here at the Live Embedded event.",0,0
data/train/6_1.mp3,"Today I'm here to talk about Pipeware, which is a new technology for Linux that is essentially a multimedia service.",0,0
data/train/6_2.mp3,"that has been in development for quite a long time, I would say more than five years and now it's mature enough and ready to be used for the automotive world and the embedded world",0,0
data/train/6_3.mp3,"So yeah, before moving on to the main topic of this talk and see how Piper works and how it can be used for the automotive and embedded world, I'd like to do a quick introduction to myself first.",0,0
data/train/6_4.mp3,"So as you can see, my name is Julian.",0,0
data/train/6_5.mp3,I am a Spanish multimedia software developer working at Collabora.,0,0
data/train/6_6.mp3,I joined the company quite recently.,0,0
data/train/6_7.mp3,I joined at the beginning of 2019.,0,0
data/train/6_8.mp3,"And since I joined the company, I've been part of the multimedia team, and I've been mostly working with Pipeware and distributor projects.",0,0
data/train/6_9.mp3,"So that being said, let's move on to the main topic, which is, what is Pipeware?",0,0
data/train/6_10.mp3,What is this new technology that is emerging and is gaining more and more popularity nowadays?,0,0
data/train/6_11.mp3,"Well, as I said at the beginning,",0,0
data/train/6_12.mp3,"Piper is essentially a fresh multimedia service for Linux that can handle any kind of multimedia devices, doesn't matter if it's video or audio.",0,0
data/train/6_13.mp3,It was originally meant to handle only video devices.,0,0
data/train/6_14.mp3,"In fact, its original name was Pulse Video.",0,0
data/train/6_15.mp3,"But over the years, it evolved, and now it was renamed to Piper, and now it's more of a generic multimedia framework that can handle both devices.",0,0
data/train/6_16.mp3,"And the reason for that is because it started addressing many issues, you know, previous audio.",0,0
data/train/6_17.mp3,services were having.,0,0
data/train/6_18.mp3,So at the end the developers they decided to just handle everything and at some point replace those old multimedia services.,0,0
data/train/6_19.mp3,"So basically with Piper, what you can do is applications, they can capture video from different video sources, such as cameras or even graphic sources.",0,0
data/train/6_20.mp3,"For example, if you want to capture your desktop with Wayland or Vulkan.",0,0
data/train/6_21.mp3,And you can also obviously do capturing and playback of audio.,0,0
data/train/6_22.mp3,in other devices.,0,0
data/train/6_23.mp3,"For example, you can capture audio from a microphone and you can do audio playback using a speaker or even my Bluetooth devices.",0,0
data/train/6_24.mp3,So applications can do all of that very easily without worrying about configuring devices and using low-level APIs such as Video4Linux when you want to capture video from cameras or Vulkan or Wayland complex APIs or,0,0
data/train/6_25.mp3,"You know, for audio, the also in Bluetooth, low-level and complex APIs.",0,0
data/train/6_26.mp3,Applications don't need to worry about that.,0,0
data/train/6_27.mp3,"The way it works, Piper is a daemon that runs the background and applications connect to the daemon and they basically tell them, hey Piper, I want to just capture buffers from this device or I want to play buffers on this device and that's it.",0,0
data/train/6_28.mp3,"They don't need to worry about checking if the device is being used, if it's not used, if they have permissions or anything like that.",0,0
data/train/6_29.mp3,All of that is handled automatically by Piper.,0,0
data/train/6_30.mp3,So why do we need Piper?,0,0
data/train/6_31.mp3,"I mean, we already have, you know, in one hand we have PulseAudio and we have Jack, so why do we need an extra one?",0,0
data/train/6_32.mp3,"Well, you know, so PulseAudio is like a generic audio device, you know,",0,0
data/train/6_33.mp3,"service that handles, you know, all of that in a generic way for you.",0,0
data/train/6_34.mp3,"And Jack, audio server, is more focused on professional and low latency audio processing.",0,0
data/train/6_35.mp3,But what if an application wants to do a little bit of both?,0,0
data/train/6_36.mp3,"You know, you can't.",0,0
data/train/6_37.mp3,"So, one of the problems Piper wants to solve is the unification of",0,0
data/train/6_38.mp3,"PulseAudio and Jack, because it wants to replace them, get rid of them, and have a system running only one multimedia framework.",0,0
data/train/6_39.mp3,"Simplifying a lot the Linux Multimedia Stack, because otherwise it's quite complex, because of all these different services.",0,0
data/train/6_40.mp3,"Now, another issue that Piper wants to solve is security.",0,0
data/train/6_41.mp3,"So, at the moment, you know, the current approaches, the",0,0
data/train/6_42.mp3,"the current multimedia frameworks, they don't handle containers properly, such as Flatpak or Wayland, because their permissions, basically, they rely on the video and audio user groups.",0,0
data/train/6_43.mp3,Piper doesn't rely on that.,0,0
data/train/6_44.mp3,"Piper fully supports containers properly, so it basically asks the container if he can access the device, and if he cannot access the device, it's going to basically tell the client his device cannot be accessed.",0,0
data/train/6_45.mp3,"For security, especially nowadays, Pipewire is much, much safer and better.",0,0
data/train/6_46.mp3,The third point that Pipewire wants to address is low latency.,0,0
data/train/6_47.mp3,"Pipewire is low latency and real-time capable, and it can handle very small buffer sizes of up to 32 samples, which is only one or two milliseconds of latency.",0,0
data/train/6_48.mp3,Not even Jack can do that.,0,0
data/train/6_49.mp3,"And last and last least, it's flexibility.",0,0
data/train/6_50.mp3,So Piper is very flexible because it exposes an API for users to write their own session manager and basically tell Piper how to behave based on different use cases and scenarios.,0,0
data/train/6_51.mp3,"So basically we have simplicity, security, performance, and flexibility.",0,0
data/train/6_52.mp3,"So if you have a look at the Linux multimedia stack, if we are running the PyPore daemon, we can see that there's something like that.",0,0
data/train/6_53.mp3,"So at the bottom, we have the kernel with all the different drivers.",0,0
data/train/6_54.mp3,"And on the top, we have the different applications, the different multimedia applications.",0,0
data/train/6_55.mp3,And the PyPore is like a middle layer in between those two layers.,0,0
data/train/6_56.mp3,where applications connect to it.,0,0
data/train/6_57.mp3,"And then Piper manages those connections and uses internally the kernel low-level APIs, multimedia APIs.",0,0
data/train/6_58.mp3,"And those connections, all of that is handled automatically by the session manager, which runs in a different process.",0,0
data/train/6_59.mp3,So there's at least three processes going on here.,0,0
data/train/6_60.mp3,"There's the application process, the PyCore daemon process, and the PyProcessingManual process.",0,0
data/train/6_61.mp3,And they all communicate each other via sockets.,0,0
data/train/6_62.mp3,"Using a protocol, you know, the protocol can be many different protocols can be used.",0,0
data/train/6_63.mp3,"There is a pipe, there is Piper has its own native protocol, but others can be used.",0,0
data/train/6_64.mp3,"You can use, for example, the Wayland protocol, or you can even implement your own protocol if you want.",0,0
data/train/6_65.mp3,"But yeah, so in this example, for example, you have a look at the song recorder on the top right corner.",0,0
data/train/6_66.mp3,"You can see that this linked with the green square, which is a node, the green processing element, which is, the green processing elements here are more like converters.",0,0
data/train/6_67.mp3,"You know, they do audio conversion, they do video conversion or audio mixing.",0,0
data/train/6_68.mp3,"all of that, and then we have the purple nodes that are sinks and sources that are connected to the device.",0,0
data/train/6_69.mp3,"So, for example, different applications could connect to the same node and the session manager decides whether he wants to keep the previous link and play both of them at the same time or just remove the previous one and only connect the new one.",0,0
data/train/6_70.mp3,"So, yeah, the session manager has control of everything.",0,0
data/train/6_71.mp3,"So if I want to use PipeWare on my system, do I have to update all my multimedia applications and use a new PipeWare API?",0,0
data/train/6_72.mp3,"Not necessarily, because the PipeWare project also provides compatibility APIs built on top of PipeWare.",0,0
data/train/6_73.mp3,"So for example, there is an ALSA.",0,0
data/train/6_74.mp3,"For ALS applications, there is a PiPore PCM plugin that does the bridge between the ALS API and internally connects to the PiPore daemon and exposes all these different PiPore nodes.",0,0
data/train/6_75.mp3,"For pulse or inject applications, the same approach is done by having replacement for libpulse.so and libjack.so.",0,0
data/train/6_76.mp3,"Applications don't need to be updated right away if you want to use Pipeware, because thanks to these compatibility APIs,",0,0
data/train/6_77.mp3,everything works fine.,0,0
data/train/6_78.mp3,"But eventually, in the future, it's nice for the applications to change and use the Piper API to remove more complexity in the multimeter stack.",0,0
data/train/6_79.mp3,"So, in terms of architecture and design, Piper basically follows the same design of most of open source projects.",0,0
data/train/6_80.mp3,"So, it's modular and it has plugins.",0,0
data/train/6_81.mp3,"So, basically a module in Piper is something, it's basically an API.",0,0
data/train/6_82.mp3,"So, it's, for example, you have a module for Bluetooth, you have a module for",0,0
data/train/6_83.mp3,"For video for Linux, you have a module for Wayland, you have a module for Vulkan, you have a module for all these different low-level APIs.",0,0
data/train/6_84.mp3,You have a module for Alzhe.,0,0
data/train/6_85.mp3,And then plugins are basically elements inside these modules that implement different functionalities.,0,0
data/train/6_86.mp3,"So, for example, you have elements which are nodes that implement audio mixing.",0,0
data/train/6_87.mp3,"You have also format conversion, like some video conversion or audio conversion.",0,0
data/train/6_88.mp3,Then you have also resampling.,0,0
data/train/6_89.mp3,"So you basically have, you can write plugins for Pipel that do any kind of different",0,0
data/train/6_90.mp3,media processing.,0,0
data/train/6_91.mp3,So it's very similar to GStreamer.,0,0
data/train/6_92.mp3,"You know, it's graph-based like GStreamer.",0,0
data/train/6_93.mp3,Think of nodes as GStreamer elements and ports as GStreamer pads.,0,0
data/train/6_94.mp3,And obviously links are objects in Piper.,0,0
data/train/6_95.mp3,"You know, it's not like GStreamer where, you know, you just link two elements in Piper.",0,0
data/train/6_96.mp3,You have to create the link and then you have to tell what are the input and output nodes,0,0
data/train/6_97.mp3,"Also, different to the streamer, Piper is multiprocess, as I said before, so the daemon is charged, it runs in the background and is charged to process most of the data.",0,0
data/train/6_98.mp3,"However, this is not...",0,0
data/train/6_99.mp3,"100% necessary if you have, for example, a slow node.",0,0
data/train/6_100.mp3,Clients have the ability to run nodes locally and avoid stalling the daemon in case a node is very slow.,0,0
data/train/6_101.mp3,"This is, for example, the case for Bluetooth nodes, which can be very slow, especially when connecting and disconnecting a new Bluetooth device.",0,0
data/train/6_102.mp3,"And so again, multiprocess and also the external session manager that configures all the links, nodes, these runs also into its own process.",0,0
data/train/6_103.mp3,"you know, communicating and they all communicating each other with sockets.",0,0
data/train/6_104.mp3,"Then, finally, the pipework, it's different from",0,0
data/train/6_105.mp3,the remaining open source project because it only depends on its simple plugin API library.,0,0
data/train/6_106.mp3,It doesn't depend on anything else.,0,0
data/train/6_107.mp3,It doesn't depend on JLib or any other famous open source library.,0,0
data/train/6_108.mp3,And it does that because it really wants to achieve low TPU usage and high performance.,0,0
data/train/6_109.mp3,"So this SPA library is extremely simple and lightweight, and it's used for generic, it's used as a generic purpose multimedia library.",0,0
data/train/6_110.mp3,"With that library, that library has basically helped us to do audio conversion, audio mixing, audio resampling, and it also provides some,",0,0
data/train/6_111.mp3,"structures, basic data structures such as hash tables or lists or arrays and all of that, and basic video helper functionality.",0,0
data/train/6_112.mp3,It's a mostly header-only C library with no dependencies.,0,0
data/train/6_113.mp3,"So thanks to that, the performance and efficiency of Piper is very impressive because it follows a static co-design approach.",0,0
data/train/6_114.mp3,There's hardly any mallocs.,0,0
data/train/6_115.mp3,"If you grab for malloc in the Piper project, you are not going to see a lot of them.",0,0
data/train/6_116.mp3,"And it also uses modern Linux APIs, memfd and dmabuf to zero copy buffers from device to memory.",0,0
data/train/6_117.mp3,So thanks to EventFD and TimerD for scheduling.,0,0
data/train/6_118.mp3,"So thanks to all of that, the CPU usage of Piper is impressive and it's low latency real-time capable.",0,0
data/train/6_119.mp3,"In fact, if you have a look at some graphs and we compare Piper with PulseAudio, we can see that in the following hardware, an Intel Core i7,",0,0
data/train/6_120.mp3,"We can see on the left chart, so we have on the bottom, the x-axis is basically the buffer size and the y-axis is the CPU percentage.",0,0
data/train/6_121.mp3,"So we can see that for buffers, for big buffers of",0,0
data/train/6_122.mp3,8192 samples.,0,0
data/train/6_123.mp3,"Piper and Jack, the performance, the CPU usage is mostly the same.",0,0
data/train/6_124.mp3,"Piper is 0.001% of CPU usage, while PulseAudio is 0.005%.",0,0
data/train/6_125.mp3,"However, if we reduce the buffer size up to 64 samples, we can see that the performance and the CPU usage",0,0
data/train/6_126.mp3,"with PulseAudio increases quite significantly, while Piper is only 0.03%.",0,0
data/train/6_127.mp3,"The graph on the right is the same, but it's an example of mixing two different files, mixing a 41.1 kHz file with a 48 kHz file.",0,0
data/train/6_128.mp3,"The performance is also very, very impressive.",0,0
data/train/6_129.mp3,"For buffers of 512 samples, which is about 10 milliseconds, the CPU usage for Piper is only 0.007% and for PulseAudio is 0.2%.",0,0
data/train/6_130.mp3,"If we compare Piper against Jack, the performance is mostly similar, especially for big buffers of 8000 samples.",0,0
data/train/6_131.mp3,"on the graph on the left, that it's the same.",0,0
data/train/6_132.mp3,"But again, if you reduce the buffer sizes to achieve a low latency, and you want to have a buffer size of 128 samples, which is about four milliseconds, the performance usage is lower than Jack.",0,0
data/train/6_133.mp3,"So in PipeRace, 0.017%.",0,0
data/train/6_134.mp3,whereas in Jack it's 0.6%.,0,0
data/train/6_135.mp3,"So yeah, as you reduce the buffer size, you can see that the performance, it's faster, it's better in Piper than Jack.",0,0
data/train/6_136.mp3,"Now, security, the way it works is the Session Manager grants permissions to your applications in Piper.",0,0
data/train/6_137.mp3,The Session Manager basically can decide,0,0
data/train/6_138.mp3,what application can have permissions to access a specific device or not.,0,0
data/train/6_139.mp3,And the Pipeware nodes can be only visible for some applications.,0,0
data/train/6_140.mp3,The session manager can make visible... Applications can see only part of the whole node graph if they want.,0,0
data/train/6_141.mp3,"Now, there's three kinds of permissions.",0,0
data/train/6_142.mp3,"There's read permissions, write permissions, and there's executable permissions.",0,0
data/train/6_143.mp3,The read permissions allows you to see the node and capture data from it.,0,0
data/train/6_144.mp3,The write permissions allows you to play buffers in a node.,0,0
data/train/6_145.mp3,And the execute permissions allows you to configure,0,0
data/train/6_146.mp3,basically it allows you to set up a format and all of that.,0,0
data/train/6_147.mp3,"The External Session Manager, Piper, it's not included in the Piper project.",0,0
data/train/6_148.mp3,It's an external project.,0,0
data/train/6_149.mp3,"It's not maintained by the Piper developers, but it's the one charged to create and configure the devices that emits then later the Piper nodes.",0,0
data/train/6_150.mp3,It's also the one charged to,0,0
data/train/6_151.mp3,"set up nodes, format, port, et cetera, create links based on its policy logic when a client connects, grant security and access control to clients, and it's also launched by the Piper demo startup.",0,0
data/train/6_152.mp3,"The current state of Piper is version 0.3.15, released in November 2020.",0,0
data/train/6_153.mp3,There were some major improvements in this release.,0,0
data/train/6_154.mp3,So one of the biggest improvements was that Piper reused the Alzacar profile code from PulseAudio.,0,0
data/train/6_155.mp3,"So now devices support all profiles, UCM and hardware mixes that PulseAudio implements.",0,0
data/train/6_156.mp3,So Piper basically,0,0
data/train/6_157.mp3,Right now the behavior is mostly the same as PulseAudio and PulseAudio can be entirely replaced right now.,0,0
data/train/6_158.mp3,Tools such as the PulseAudio Volume Control works with Piper.,0,0
data/train/6_159.mp3,Then there was a lot of improvements in Bluetooth.,0,0
data/train/6_160.mp3,So the HTTP profile and HSP profile work now with the basic codecs.,0,0
data/train/6_161.mp3,They work for most devices.,0,0
data/train/6_162.mp3,Support for MSBC codec is ongoing.,0,0
data/train/6_163.mp3,Most of the Jack application works in Piper.,0,0
data/train/6_164.mp3,The musical instrument digital interface works.,0,0
data/train/6_165.mp3,"Video capture from video-for-linear sources, they work very well.",0,0
data/train/6_166.mp3,And Wayland screencasting from Western GNOME Shell and Wayland Root is also supported.,0,0
data/train/6_167.mp3,Who started the project?,0,0
data/train/6_168.mp3,"The project is started by Wintimons, which is a well-known old distro developer and ex-maintainer.",0,0
data/train/6_169.mp3,It's sponsored by Red Hat.,0,0
data/train/6_170.mp3,It's embraced by Pulse Audio developers because it's seen as the next generation of Pulse Audio.,0,0
data/train/6_171.mp3,And it's welcomed by ALS and JAG developers.,0,0
data/train/6_172.mp3,Another interesting feature is that the license is MIT.,0,0
data/train/6_173.mp3,"Before moving on to the next part, which is explaining how Piper can be used for the automotive world,",0,0
data/train/6_174.mp3,I'd like to mention some contributions I have made in the project.,0,0
data/train/6_175.mp3,"In Piper, there is a tool called PiperDot that generates a dot graph showing all the Piper objects and links similar to the streamer.",0,0
data/train/6_176.mp3,which is very handy for debugging.,0,0
data/train/6_177.mp3,"And most of the Bluetooth support, I did a lot of Bluetooth support, so I fixed several HTTP issues in some devices.",0,0
data/train/6_178.mp3,"I have support for HTTP sources using the SBC codec, and I had support for HSP and HFP profile using the CVSD codec.",0,0
data/train/6_179.mp3,"Okay, so that was the first part of the talk.",0,0
data/train/6_180.mp3,And now I'm going to move on Piper in the automotive industry section.,0,0
data/train/6_181.mp3,So why Piper suits perfectly the automotive world?,0,0
data/train/6_182.mp3,The current problem is device handling in connected cars is complex because,0,0
data/train/6_183.mp3,"Cars, they have a lot of multimedia devices.",0,0
data/train/6_184.mp3,"Cars have a lot of cameras, they have a lot of speakers, and on top of that, all of them can work at the same time.",0,0
data/train/6_185.mp3,And also different streams can play audio at the same time.,0,0
data/train/6_186.mp3,"So for example, you can use",0,0
data/train/6_187.mp3,the navigation at the same time as listening to music.,0,0
data/train/6_188.mp3,"And you can even have, for example, your Bluetooth paired to the car while you are speaking when driving.",0,0
data/train/6_189.mp3,So all this audio needs to be handled properly.,0,0
data/train/6_190.mp3,"And some of you might want to just play, for example, the navigation on the front speakers of the car, but not on the back speakers of the car.",0,0
data/train/6_191.mp3,"or maybe you want to use the camera, the back camera when you are going backwards and not when you're going forward.",0,0
data/train/6_192.mp3,"So again, plenty of devices, plenty of speakers, plenty of streams.",0,0
data/train/6_193.mp3,How do we handle that properly?,0,0
data/train/6_194.mp3,It's very hard to do that with Pulse audio without hacking into it.,0,0
data/train/6_195.mp3,So the solution is Piper with a flexible external session manager.,0,0
data/train/6_196.mp3,"that allows you to do custom policy logic, custom hardware pipelines, hardware control abstraction and security.",0,0
data/train/6_197.mp3,"Now, since Pipework doesn't include a proper and extensible session manager, here at Collabora, we have decided to create the first",0,0
data/train/6_198.mp3,external and extensible session manager for Pipeware called Wipelumber.,0,0
data/train/6_199.mp3,"We decided to do this because we also had a client, we had an automotive Linux client who wanted to adopt Pipeware as the core of their audio system into their system.",0,0
data/train/6_200.mp3,and we had to basically develop a session manager for them.,0,0
data/train/6_201.mp3,"So it was already focused on embedded only, but, you know, a lot of work has been done, and now it's a generic and fully-featured session manager for both embedded and desktop.",0,0
data/train/6_202.mp3,"Another thing to note is that YPrime is based on GObject to support writing bindings in other languages, such as Rust, Python, and Lua.",0,0
data/train/6_203.mp3,because at some point we want users to have an even higher API to basically control Piper.,0,0
data/train/6_204.mp3,"We want users to control Piper using, for example, a Python script.",0,0
data/train/6_205.mp3,"So, basically, WebNumber, since it's a higher-level API, it introduces three new objects.",0,0
data/train/6_206.mp3,"So, it introduces the concept of an endpoint.",0,0
data/train/6_207.mp3,"So, an endpoint is basically a set of nodes that follows a similar specific logic.",0,0
data/train/6_208.mp3,"This is very useful for devices that expose a lot of nodes, but a lot of them need to be treated in the same way.",0,0
data/train/6_209.mp3,"So, for example, you could have a Bluetooth endpoint that has one node for the HTTP profile and one for the HSP profile.",0,0
data/train/6_210.mp3,"And applications, when they connect to it, they don't need to worry about switching different profiles in the Bluetooth device.",0,0
data/train/6_211.mp3,they just need to connect to the specific endpoint stream.,0,0
data/train/6_212.mp3,And this is where the endpoint stream comes in.,0,0
data/train/6_213.mp3,An endpoint stream is essentially a connection point for an endpoint.,0,0
data/train/6_214.mp3,It's like a port for a node.,0,0
data/train/6_215.mp3,"It's like a port for endpoints, sorry.",0,0
data/train/6_216.mp3,"And finally, we have also the concept of sessions, which is a set of endpoints.",0,0
data/train/6_217.mp3,And this is also important because it makes it easy to grant permissions to just a group of endpoints.,0,0
data/train/6_218.mp3,It's not instead of just one by one.,0,0
data/train/6_219.mp3,"So at the moment, YPlumber creates a video session and an audio session.",0,0
data/train/6_220.mp3,And it basically assigns a session to an endpoint.,0,0
data/train/6_221.mp3,"So in this graph, we can see an example of two software DSP endpoints.",0,0
data/train/6_222.mp3,"This is, for example, when running WebRamble in a laptop.",0,0
data/train/6_223.mp3,"So in a laptop, we have the same, we use the same audio device for both music and notification.",0,0
data/train/6_224.mp3,So the endpoint basically wraps,0,0
data/train/6_225.mp3,"the same node and adds two conversions for different volume controls, one for music and one for notifications.",0,0
data/train/6_226.mp3,"And the media player basically always uses the music stream from that band point, whereas, for example, the desktop manager could use a notification point to notify the user when a new email comes in.",0,0
data/train/6_227.mp3,"However, you know, in a car, you know, we might have a different hardware device for,",0,0
data/train/6_228.mp3,for the notifications.,0,0
data/train/6_229.mp3,We might have different hardware devices depending on the stream.,0,0
data/train/6_230.mp3,We might have a hardware device for navigation and one for notifications.,0,0
data/train/6_231.mp3,"So in this case, the endpoint would wrap those two nodes into one endpoint and would link the music stream with the",0,0
data/train/6_232.mp3,the Alsosub device and the notification with the proper notification Alsosub device.,0,0
data/train/6_233.mp3,"But basically, it hides the complexity of dealing with these different nodes and the policy logic would be the same for both desktop and embedded and automotive.",0,0
data/train/6_234.mp3,"So the design of wirepromver, it's essentially a library.",0,0
data/train/6_235.mp3,So wireprom is essentially a library that allows you to write in a much easier way other pipe or session managers.,0,0
data/train/6_236.mp3,And it also provides an executable that basically executes load modules written using that wirepromver library that have all the different functionality.,0,0
data/train/6_237.mp3,"So users can just use the library to write their own PyProcessor manual, or they can use the already existing modules to do PyPro logic.",0,0
data/train/6_238.mp3,"An example of YPrime modules is the monitor module, which basically monitor devices and creates nodes when enabled.",0,0
data/train/6_239.mp3,We have also the YPromo client permission modules that grant permissions to clients when connected.,0,0
data/train/6_240.mp3,We have the configuration endpoint module that basically creates endpoints based on configuration files.,0,0
data/train/6_241.mp3,And we have the config policy module that basically is the one charged to create links between endpoints based on configuration files.,0,0
data/train/6_242.mp3,But users can decide whether they want to load these modules and implement their own modules.,0,0
data/train/6_243.mp3,"In the future, we plan to add bindings in order to have a higher-level API, as I said before, to avoid using, obviously, the low-level Piper API and objects.",0,0
data/train/6_244.mp3,"And we also want to, because at the moment",0,0
data/train/6_245.mp3,"the modules are reading configuration files, but we would like them to read also scripting files such as Lua to have more flexibility when writing policy logic or endpoint creation logic.",0,0
data/train/6_246.mp3,The current status of wireplumber is version 0.3.0.,0,0
data/train/6_247.mp3,"The first version was 0.1.0, which was released last year in July, and it was used in AGL Happy Hollywood 8.0 branch.",0,0
data/train/6_248.mp3,"Then version 0.2 was released last December 2019, and it was used both in AGL Happy Hollywood and Ichi Icefish.",0,0
data/train/6_249.mp3,"Version 0.3 was released in June this year, which was the first release with support for desktop.",0,0
data/train/6_250.mp3,"And we probably are going to do a release at the end of this year or beginning next year with API improvements, with scripting bindings.",0,0
data/train/6_251.mp3,"And we want also to stabilize the API because it's always, at the moment, it's always changing because we are trying to figure out the best cases.",0,0
data/train/6_252.mp3,"So again, future release will support bindings, improve the API.",0,0
data/train/6_253.mp3,It will improve also the documentation and it will add more unit tests and examples so that people can contribute to it.,0,0
data/train/6_254.mp3,So who started this project?,0,0
data/train/6_255.mp3,The owner of the project is George.,0,0
data/train/6_256.mp3,He's working at Collaborative.,0,0
data/train/6_257.mp3,The project Wireplumber is sponsored by Collabra.,0,0
data/train/6_258.mp3,It's welcomed by Piper developers.,0,0
data/train/6_259.mp3,"You've got the Git repository and documentation there if you want to know, and the license is the same as Piper, it's MIT.",0,0
data/train/6_260.mp3,And that's it for this talk.,0,0
data/train/6_261.mp3,I'm going to show you now a demonstration so you can have a better idea of how all of this works.,0,0
data/train/6_262.mp3,It's a demonstration I pre-recorded.,0,0
data/train/6_263.mp3,It's going to basically show the users of both Piper and YPrimer projects.,0,0
data/train/6_264.mp3,"OK, so welcome back.",0,0
data/train/6_265.mp3,"So yeah, in this demonstration what I want to show you is how to use PyPore and Yplumber on your desktop, which can be quite interesting for some of you if you want to play a little bit with this technology and also have",0,0
data/train/6_266.mp3,"you know, a better feeling of how an audio server works.",0,0
data/train/6_267.mp3,"So, as you can see here, I have on my left terminal the Pipewire project already configured and built, and the same on the right terminal with RightPlumber.",0,0
data/train/6_268.mp3,"So I'm going to basically run first Pipewire here on the left, and then RightPlumber.",0,0
data/train/6_269.mp3,"But before doing that, I want to open a couple more terminals,",0,0
data/train/6_270.mp3,because I'm going to use these terminals to run the client.,0,0
data/train/6_271.mp3,"Now, by default, if I just run an audio client here, such as MPlayer, it's going to connect to the default audio server of my distro, which is PulseAudio, and we don't want to do that.",0,0
data/train/6_272.mp3,We want them to connect to Pipewire.,0,0
data/train/6_273.mp3,"We are going to run make shell that basically sets a bunch of environment variables, such as the path, which allows you to use the PyPort tools you just already built, or the LD library path, which points to the build directory of the PyPort we just built and we are going to run.",0,0
data/train/6_274.mp3,"So MakeShell allows us to run clients within this shell, and they will automatically connect to Piper, which makes it very easy to test Piper.",0,0
data/train/6_275.mp3,"So I'm going to open up a bunch more tabs because we're going to use several clients, and we're going to run MakeShell on all of them.",0,0
data/train/6_276.mp3,I think five should be enough.,0,0
data/train/6_277.mp3,"So yeah, now, once everything is ready, we are going to run Pipeware with make run, and we are going to run Pipelumber with the log enabled, so you can see that it's basically doing some stuff.",0,0
data/train/6_278.mp3,"Now, you're going to also see some warning messages, such as device being busy.",0,0
data/train/6_279.mp3,"And this is because I'm recording using my microphone, so that device is used by the screen recorder.",0,0
data/train/6_280.mp3,"But it should be fine for what we are going to do, so don't worry too much about that.",0,0
data/train/6_281.mp3,"So everything is running, this is a log of Piper, and now we are going to try to play some audio.",0,0
data/train/6_282.mp3,"for example, this one.",0,0
data/train/6_283.mp3,"Now, MPlayer, by default, uses the PulseAudio API.",0,0
data/train/6_284.mp3,"So when I run this, what it's going to do is it's going to use the libPulse compatibility API of Pipeware.",0,0
data/train/6_285.mp3,"And that library, internally, it's going to tell Pipeware that a new client comes in.",0,0
data/train/6_286.mp3,And it's going to notify the session manager.,0,0
data/train/6_287.mp3,And the session manager is going to basically create the nodes and link the nodes based on the custom policy.,0,0
data/train/6_288.mp3,So I run it and you can hear that music is playing.,0,0
data/train/6_289.mp3,We can also see some warnings of the PulseAudio compatibility API library.,0,0
data/train/6_290.mp3,"Not all features are implemented yet, but we can hear music.",0,0
data/train/6_291.mp3,Now I'm gonna use the pipeware dot tool to generate a dot graph similar to GStreamer and we can see that,0,0
data/train/6_292.mp3,"you know, the nodes are basically connected.",0,0
data/train/6_293.mp3,"It's very easy to use, you just do piper.",0,0
data/train/6_294.mp3,"and then the name of the file where you want the graph to be written and then we can view the graph with tools such as x. So yeah, we can see this here, that backnumber linked the different nodes.",0,0
data/train/6_295.mp3,So the green squares here are,0,0
data/train/6_296.mp3,nodes the red square are the output port and the purple squares are the input ports and the blue squares are actually the links created by the wired number so this also playback node is actually the end player client,0,0
data/train/6_297.mp3,"that has two channels, the left channel and the right channel and is connected to a converter and that converter is connected to the default ALSA node which is my speakers on my laptop we can actually view more information if we run it with the detail",0,0
data/train/6_298.mp3,option and we can see more properties.,0,0
data/train/6_299.mp3,It makes the graph much bigger.,0,0
data/train/6_300.mp3,We can see here for example that Mplayer is this node with this ID and we can see that the also device that it's using is the hardware 0.,0,0
data/train/6_301.mp3,"So yeah, we can now do more cool stuff.",0,0
data/train/6_302.mp3,"For example, we can use the Pulse Audio Volume Control.",0,0
data/train/6_303.mp3,And we can see that it's monitoring all the audio being played on my laptop.,0,0
data/train/6_304.mp3,"And we can also change the volume, for example.",0,0
data/train/6_305.mp3,We can see also some warnings here because not all the compatibility APIs are implemented yet.,0,0
data/train/6_306.mp3,"But yeah, it's working nicely.",0,0
data/train/6_307.mp3,"And we can see then now here, if we run the Pipeware tool,",0,0
data/train/6_308.mp3,that it's created more links.,0,0
data/train/6_309.mp3,"Now all the input nodes, they have a monitor port and basically the Pulse Audio Volume Control uses those monitor ports and creates these nodes to actually monitor the audio coming out.",0,0
data/train/6_310.mp3,So that's why we see this here.,0,0
data/train/6_311.mp3,"So yeah, now we can do one more thing, which is running Carla.",0,0
data/train/6_312.mp3,Carla is an audio plugin host.,0,0
data/train/6_313.mp3,"And here in the patch bay section, we can see all the stuff, all the audio stuff that is connected.",0,0
data/train/6_314.mp3,so mplayer is this also playback node and we can see that two channels are connected we can disconnect the left channel for example and now only the right channel is playing on my speaker so if we run the tool again we can see that for example only the right channel is connected,0,0
data/train/6_315.mp3,and for example I can even connect the left channel to the right speaker and we can see here that both channels are connected to the right channel of the audio converter,0,0
data/train/6_316.mp3,We can leave that as it is.,0,0
data/train/6_317.mp3,And it's back to normal.,0,0
data/train/6_318.mp3,"So yeah, that's all for this demonstration.",0,0
data/train/6_319.mp3,I hope you enjoyed.,0,0
data/train/6_320.mp3,Thanks for watching and see you soon.,0,0
data/train/6_321.mp3,And that's it.,0,0
data/train/6_322.mp3,Thank you for watching and please let me know if you have any questions.,0,0
data/train/6_323.mp3,I will be very happy to reply as many as I can.,0,0
